{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MiniGrid FlatObsWrapper with stable-baselines3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, RGBImgObsWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    return wrap_env(eval_env)\n",
    "\n",
    "def monitor_eval_env(env_name, log_dir=None, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    eval_env = stable_baselines3.common.monitor.Monitor(eval_env, log_dir)\n",
    "    return eval_env\n",
    "\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2)\n",
    "\n",
    "# By default, we use a DummyVecEnv as it is usually faster (cf doc)\n",
    "num_cpu = 16  # Number of processes to use\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "env_id ='MiniGrid-UnlockPickup-v0'\n",
    "\n",
    "env_id = env_id\n",
    "\n",
    "seed = 2\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, wrapper_class=FlatObsWrapper, seed=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "obs = vec_env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in vec_env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_RMSprop\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0007 # for RMSProp\n",
    "#learning_rate = 0.0001 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.99\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"RMSprop\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.RMSprop}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_RMSprop_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2208 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1992        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775392 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.8        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1936        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009170571 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.411      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1915        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821949 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.35       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.00312     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0.0432      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1906        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423651 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.796      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1894        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506161 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.356      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1891        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847523 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0825     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728865 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0224    |\n",
      "|    n_updates            | 28         |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0.0306   |\n",
      "| time/              |          |\n",
      "|    fps             | 1432     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0217      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1471        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008345105 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509145 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.00824    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1530        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833168 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011894008 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.00117     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0262      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1555        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369951 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0275      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006303926 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 0.00428     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0.0328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008685214 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.302      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 0.000902    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152548 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 0.00695     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0.0429   |\n",
      "| time/              |          |\n",
      "|    fps             | 1407     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694764 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 0.00536     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 342          |\n",
      "|    ep_rew_mean          | 0.0557       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1447         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079638995 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    value_loss           | 0.00264      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140928 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | 0.0526       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1478         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073334756 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -0.401       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0317      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 0.000852     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0.0639      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065939 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0.0715      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201875 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 0.00528     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1519        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007159561 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.217      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 0.00442     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005685283 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 0.0793   |\n",
      "| time/              |          |\n",
      "|    fps             | 1406     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1417        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780833 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -3.37       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 0.000863    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009687388 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 0.00285     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | 0.0959       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079590175 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -1.07        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.03        |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    value_loss           | 0.000648     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | 0.103        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1448         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076495185 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 0.00456      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1456        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157565 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 324          |\n",
      "|    ep_rew_mean          | 0.114        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1466         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072516864 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0312      |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1472        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127866 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.00855     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011218775 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 0.104    |\n",
      "| time/              |          |\n",
      "|    fps             | 1398     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 0.129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1404        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269294 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | 0.127        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084593985 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012237323 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 0.00467     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 0.153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348253 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012431674 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.00785     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010065392 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.00354     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1447        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010351133 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 0.00171     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149271935 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00913     |\n",
      "|    value_loss           | 0.00255      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 0.179    |\n",
      "| time/              |          |\n",
      "|    fps             | 1371     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1378        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976298 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 283        |\n",
      "|    ep_rew_mean          | 0.234      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1385       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961323 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 164        |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011408685 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 0.289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810373 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00774     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | 0.312        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1404         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100941975 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0388      |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.0207       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 0.317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011928789 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00972789 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0168    |\n",
      "|    n_updates            | 184        |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    value_loss           | 0.00799    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 0.321    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 0.324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700807 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 0.349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821334 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00832     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066237 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00972    |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905958 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009255871 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 0.00979     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448459 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 204        |\n",
      "|    ep_rew_mean          | 0.453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849258 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 212        |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 324.80 +/- 105.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 325         |\n",
      "|    mean_reward          | 0.098       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729654 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 0.477    |\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 0.586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007263053 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 0.617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008733772 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444921 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008191827 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506599 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 0.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737902 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00675    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010061242 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007413777 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00787    |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 0.635    |\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 0.627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660727 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890765 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 136          |\n",
      "|    ep_rew_mean          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1381         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070074527 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0147      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 0.0213       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707212 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00994    |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009518158 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 0.724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010742119 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | 0.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646955 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00842    |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 325.40 +/- 103.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 325          |\n",
      "|    mean_reward          | 0.0965       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080566835 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0174      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 0.0214       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.4     |\n",
      "|    ep_rew_mean     | 0.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 1373     |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 88.1       |\n",
      "|    ep_rew_mean          | 0.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1379       |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00765628 |\n",
      "|    clip_fraction        | 0.0884     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0177    |\n",
      "|    n_updates            | 284        |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.2        |\n",
      "|    ep_rew_mean          | 0.776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780284 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00767     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.6        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663681 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00783    |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.882       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013481904 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876687 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.5        |\n",
      "|    ep_rew_mean          | 0.897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135613 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 0.911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099381 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.80 +/- 168.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011758837 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00115     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.3     |\n",
      "|    ep_rew_mean     | 0.905    |\n",
      "| time/              |          |\n",
      "|    fps             | 1380     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012846921 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0028     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 44         |\n",
      "|    ep_rew_mean          | 0.888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1389       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287708 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.941     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00807   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 0.0306     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36         |\n",
      "|    ep_rew_mean          | 0.909      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1392       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825456 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00843   |\n",
      "|    n_updates            | 324        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.5        |\n",
      "|    ep_rew_mean          | 0.909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011439201 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00876     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.924       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1401        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343361 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494961 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 292.20 +/- 135.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 292        |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 176000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075115 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0157    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | 0.919    |\n",
      "| time/              |          |\n",
      "|    fps             | 1385     |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.2        |\n",
      "|    ep_rew_mean          | 0.903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388014 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | 0.917        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117297955 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.75        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.00559     |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 0.0393       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.7       |\n",
      "|    ep_rew_mean          | 0.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711984 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.819     |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 352        |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 0.908        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125203915 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.000254     |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 0.0286       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.4       |\n",
      "|    ep_rew_mean          | 0.929      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1400       |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035146 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.747     |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.011     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00645   |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.3        |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597158 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 0.00873     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1405        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008591977 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.00818     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.90 +/- 168.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.575        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134988995 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 0.00493      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | 0.948    |\n",
      "| time/              |          |\n",
      "|    fps             | 1397     |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | 0.949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736785 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782128 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.00227     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.7        |\n",
      "|    ep_rew_mean          | 0.951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887598 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.00189     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 0.952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497131 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00427    |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.00661     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.5        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014433542 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279782 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.0026      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.7        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1415        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017481608 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    value_loss           | 0.00291     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 47.30 +/- 104.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.3        |\n",
      "|    mean_reward          | 0.872       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343712 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | 0.000173    |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | 0.941    |\n",
      "| time/              |          |\n",
      "|    fps             | 1413     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1416        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034888618 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    value_loss           | 0.00968     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | 0.939      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1418       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667555 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.396     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.000579  |\n",
      "|    n_updates            | 412        |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    value_loss           | 0.00822    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 0.957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1420        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814387 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | 0.000265    |\n",
      "|    value_loss           | 0.00525     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1423        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014388864 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015875302 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 0.00267     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011128774 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00659    |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16          |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010601694 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.00373     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 14.60 +/- 3.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 14.6        |\n",
      "|    mean_reward          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361956 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00797     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.96  is above the threshold 0.92\n",
      "Final time_steps: 224000\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 1\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.9431000000000002 +/- 0.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters (Adam test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_Adam\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 0.0007 # for RMSProp\n",
    "learning_rate = 2.5e-4 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.95\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"Adam\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.Adam}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "#eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_Adam_1\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009163605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 0.00391      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318327 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.847       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.000398     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185322 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 8.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 0.0113       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014565822 |\n",
      "|    clip_fraction        | 0.000122     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 0.000839     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009096736 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351728 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 8.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905658 |\n",
      "|    clip_fraction        | 0.00916     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 0.000456    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713062 |\n",
      "|    clip_fraction        | 0.00134      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0373      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 4.64e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 1425     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059436574 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.343       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.79e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.0401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065736375 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -2.63        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 0.000366     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853437 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0855      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005402373 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057163346 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403262 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163347 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0224      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.0115       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005009041 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.4         |\n",
      "|    ep_rew_mean          | 0.783        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051049516 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 316          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 0.0118       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.39\n",
      "Episode length: 290.20 +/- 139.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 290          |\n",
      "|    mean_reward          | 0.195        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037892307 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.8         |\n",
      "|    ep_rew_mean          | 0.872        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058894404 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 0.00802      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.70 +/- 168.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581107 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045598135 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 0.00502      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.80 +/- 168.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.576        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026045418 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 404          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.77 +/- 0.38\n",
      "Episode length: 84.80 +/- 137.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.8        |\n",
      "|    mean_reward          | 0.768       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044501 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.000693    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | 0.951    |\n",
      "| time/              |          |\n",
      "|    fps             | 1518     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.95 +/- 0.01\n",
      "Episode length: 18.20 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 18.2         |\n",
      "|    mean_reward          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360986 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00171     |\n",
      "|    n_updates            | 468          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.8         |\n",
      "|    ep_rew_mean          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015850707 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0105      |\n",
      "|    n_updates            | 476          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 0.000545     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.70 +/- 2.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 17.7        |\n",
      "|    mean_reward          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480293 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.1         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017767319 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00837     |\n",
      "|    n_updates            | 516          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.30 +/- 4.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.3         |\n",
      "|    mean_reward          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011759921 |\n",
      "|    clip_fraction        | 0.00647      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00445     |\n",
      "|    n_updates            | 528          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.000333     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002253478 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.50 +/- 3.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.5         |\n",
      "|    mean_reward          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018115845 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00447     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 15.80 +/- 4.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 15.8         |\n",
      "|    mean_reward          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 304000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031136516 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00181     |\n",
      "|    n_updates            | 592          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850601 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0942     |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000274    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.70 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.7         |\n",
      "|    mean_reward          | 0.966        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032337075 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00715     |\n",
      "|    n_updates            | 624          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.8       |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1617       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252318 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 636        |\n",
      "|    policy_gradient_loss | 0.0043     |\n",
      "|    value_loss           | 0.000885   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.30 +/- 2.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.3        |\n",
      "|    mean_reward          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951071 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00663    |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.2         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1638         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010997921 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0889      |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 676          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.000206     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.10 +/- 3.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.1         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035515958 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00552     |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 2.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652107 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 716          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.6     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 1655     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 3.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971462 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0586      |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00444      |\n",
      "|    n_updates            | 748          |\n",
      "|    policy_gradient_loss | 0.00379      |\n",
      "|    value_loss           | 0.000147     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0612      |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.96 +/- 0.00\n",
      "Episode length: 14.10 +/- 1.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 14.1         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022809508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00753     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1687        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018788 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 0.000139    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 13.20 +/- 1.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.2        |\n",
      "|    mean_reward          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668287 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.046      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.2         |\n",
      "|    ep_rew_mean          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787798 |\n",
      "|    clip_fraction        | 0.00671      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0015      |\n",
      "|    n_updates            | 836          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.30 +/- 2.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.3         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 432000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017914244 |\n",
      "|    clip_fraction        | 0.00696      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.00 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13          |\n",
      "|    mean_reward          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641758 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.9         |\n",
      "|    ep_rew_mean          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1702         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038081002 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 876          |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 0.000284     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 11.70 +/- 2.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.7        |\n",
      "|    mean_reward          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 464000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944987 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 904         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 0.000124    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.6        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470194 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0457     |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 49.10 +/- 103.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 49.1         |\n",
      "|    mean_reward          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037453393 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0396      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0074      |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746727 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 956         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.60 +/- 2.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.6       |\n",
      "|    mean_reward          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 496000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03600844 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 968        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.000397   |\n",
      "----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 10\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.96745 +/- 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
