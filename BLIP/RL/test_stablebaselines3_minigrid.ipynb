{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MiniGrid FlatObsWrapper with stable-baselines3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, RGBImgObsWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    return wrap_env(eval_env)\n",
    "\n",
    "def monitor_eval_env(env_name, log_dir=None, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    eval_env = stable_baselines3.common.monitor.Monitor(eval_env, log_dir)\n",
    "    return eval_env\n",
    "\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "set_random_seed(2)\n",
    "\n",
    "# By default, we use a DummyVecEnv as it is usually faster (cf doc)\n",
    "num_cpu = 16  # Number of processes to use\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "env_id = 'MiniGrid-DoorKeyLava-6x6-v0'\n",
    "\n",
    "env_id = env_id\n",
    "\n",
    "seed = 2\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, wrapper_class=FlatObsWrapper, seed=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "obs = vec_env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in vec_env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_RMSprop\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0007 # for RMSProp\n",
    "#learning_rate = 0.0001 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.99\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"RMSprop\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.RMSprop}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_RMSprop_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2208 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1992        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775392 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.8        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1936        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009170571 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.411      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1915        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821949 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.35       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.00312     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0.0432      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1906        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423651 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.796      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1894        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506161 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.356      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1891        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847523 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0825     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728865 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0224    |\n",
      "|    n_updates            | 28         |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0.0306   |\n",
      "| time/              |          |\n",
      "|    fps             | 1432     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0217      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1471        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008345105 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509145 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.00824    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1530        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833168 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011894008 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.00117     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0262      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1555        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369951 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0275      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006303926 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 0.00428     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0.0328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008685214 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.302      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 0.000902    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152548 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 0.00695     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0.0429   |\n",
      "| time/              |          |\n",
      "|    fps             | 1407     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694764 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 0.00536     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 342          |\n",
      "|    ep_rew_mean          | 0.0557       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1447         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079638995 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    value_loss           | 0.00264      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140928 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | 0.0526       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1478         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073334756 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -0.401       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0317      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 0.000852     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0.0639      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065939 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0.0715      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201875 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 0.00528     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1519        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007159561 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.217      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 0.00442     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005685283 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 0.0793   |\n",
      "| time/              |          |\n",
      "|    fps             | 1406     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1417        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780833 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -3.37       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 0.000863    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009687388 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 0.00285     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | 0.0959       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079590175 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -1.07        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.03        |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    value_loss           | 0.000648     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | 0.103        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1448         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076495185 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 0.00456      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1456        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157565 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 324          |\n",
      "|    ep_rew_mean          | 0.114        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1466         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072516864 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0312      |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1472        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127866 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.00855     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011218775 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 0.104    |\n",
      "| time/              |          |\n",
      "|    fps             | 1398     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 0.129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1404        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269294 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | 0.127        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084593985 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012237323 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 0.00467     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 0.153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348253 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012431674 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.00785     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010065392 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.00354     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1447        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010351133 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 0.00171     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149271935 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00913     |\n",
      "|    value_loss           | 0.00255      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 0.179    |\n",
      "| time/              |          |\n",
      "|    fps             | 1371     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1378        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976298 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 283        |\n",
      "|    ep_rew_mean          | 0.234      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1385       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961323 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 164        |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011408685 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 0.289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810373 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00774     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | 0.312        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1404         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100941975 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0388      |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.0207       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 0.317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011928789 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00972789 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0168    |\n",
      "|    n_updates            | 184        |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    value_loss           | 0.00799    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 0.321    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 0.324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700807 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 0.349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821334 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00832     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066237 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00972    |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905958 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009255871 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 0.00979     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448459 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 204        |\n",
      "|    ep_rew_mean          | 0.453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849258 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 212        |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 324.80 +/- 105.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 325         |\n",
      "|    mean_reward          | 0.098       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729654 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 0.477    |\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 0.586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007263053 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 0.617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008733772 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444921 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008191827 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506599 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 0.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737902 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00675    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010061242 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007413777 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00787    |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 0.635    |\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 0.627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660727 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890765 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 136          |\n",
      "|    ep_rew_mean          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1381         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070074527 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0147      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 0.0213       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707212 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00994    |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009518158 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 0.724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010742119 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | 0.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646955 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00842    |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 325.40 +/- 103.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 325          |\n",
      "|    mean_reward          | 0.0965       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080566835 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0174      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 0.0214       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.4     |\n",
      "|    ep_rew_mean     | 0.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 1373     |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 88.1       |\n",
      "|    ep_rew_mean          | 0.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1379       |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00765628 |\n",
      "|    clip_fraction        | 0.0884     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0177    |\n",
      "|    n_updates            | 284        |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.2        |\n",
      "|    ep_rew_mean          | 0.776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780284 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00767     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.6        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663681 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00783    |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.882       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013481904 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876687 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.5        |\n",
      "|    ep_rew_mean          | 0.897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135613 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 0.911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099381 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.80 +/- 168.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011758837 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00115     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.3     |\n",
      "|    ep_rew_mean     | 0.905    |\n",
      "| time/              |          |\n",
      "|    fps             | 1380     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012846921 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0028     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 44         |\n",
      "|    ep_rew_mean          | 0.888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1389       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287708 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.941     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00807   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 0.0306     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36         |\n",
      "|    ep_rew_mean          | 0.909      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1392       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825456 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00843   |\n",
      "|    n_updates            | 324        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.5        |\n",
      "|    ep_rew_mean          | 0.909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011439201 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00876     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.924       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1401        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343361 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494961 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 292.20 +/- 135.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 292        |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 176000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075115 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0157    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | 0.919    |\n",
      "| time/              |          |\n",
      "|    fps             | 1385     |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.2        |\n",
      "|    ep_rew_mean          | 0.903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388014 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | 0.917        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117297955 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.75        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.00559     |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 0.0393       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.7       |\n",
      "|    ep_rew_mean          | 0.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711984 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.819     |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 352        |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 0.908        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125203915 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.000254     |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 0.0286       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.4       |\n",
      "|    ep_rew_mean          | 0.929      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1400       |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035146 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.747     |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.011     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00645   |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.3        |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597158 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 0.00873     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1405        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008591977 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.00818     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.90 +/- 168.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.575        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134988995 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 0.00493      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | 0.948    |\n",
      "| time/              |          |\n",
      "|    fps             | 1397     |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | 0.949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736785 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782128 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.00227     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.7        |\n",
      "|    ep_rew_mean          | 0.951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887598 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.00189     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 0.952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497131 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00427    |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.00661     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.5        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014433542 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279782 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.0026      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.7        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1415        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017481608 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    value_loss           | 0.00291     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 47.30 +/- 104.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.3        |\n",
      "|    mean_reward          | 0.872       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343712 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | 0.000173    |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | 0.941    |\n",
      "| time/              |          |\n",
      "|    fps             | 1413     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1416        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034888618 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    value_loss           | 0.00968     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | 0.939      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1418       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667555 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.396     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.000579  |\n",
      "|    n_updates            | 412        |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    value_loss           | 0.00822    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 0.957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1420        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814387 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | 0.000265    |\n",
      "|    value_loss           | 0.00525     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1423        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014388864 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015875302 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 0.00267     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011128774 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00659    |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16          |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010601694 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.00373     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 14.60 +/- 3.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 14.6        |\n",
      "|    mean_reward          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361956 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00797     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.96  is above the threshold 0.92\n",
      "Final time_steps: 224000\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 1\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.9431000000000002 +/- 0.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters (Adam test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_Adam\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 0.0007 # for RMSProp\n",
    "learning_rate = 2.5e-4 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.95\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"Adam\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.Adam}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "#eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_Adam_1\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009163605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 0.00391      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318327 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.847       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.000398     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185322 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 8.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 0.0113       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014565822 |\n",
      "|    clip_fraction        | 0.000122     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 0.000839     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009096736 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351728 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 8.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905658 |\n",
      "|    clip_fraction        | 0.00916     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 0.000456    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713062 |\n",
      "|    clip_fraction        | 0.00134      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0373      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 4.64e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 1425     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059436574 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.343       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.79e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.0401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065736375 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -2.63        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 0.000366     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853437 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0855      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005402373 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057163346 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403262 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163347 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0224      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.0115       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005009041 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.4         |\n",
      "|    ep_rew_mean          | 0.783        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051049516 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 316          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 0.0118       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.39\n",
      "Episode length: 290.20 +/- 139.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 290          |\n",
      "|    mean_reward          | 0.195        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037892307 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.8         |\n",
      "|    ep_rew_mean          | 0.872        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058894404 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 0.00802      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.70 +/- 168.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581107 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045598135 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 0.00502      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.80 +/- 168.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.576        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026045418 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 404          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.77 +/- 0.38\n",
      "Episode length: 84.80 +/- 137.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.8        |\n",
      "|    mean_reward          | 0.768       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044501 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.000693    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | 0.951    |\n",
      "| time/              |          |\n",
      "|    fps             | 1518     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.95 +/- 0.01\n",
      "Episode length: 18.20 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 18.2         |\n",
      "|    mean_reward          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360986 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00171     |\n",
      "|    n_updates            | 468          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.8         |\n",
      "|    ep_rew_mean          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015850707 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0105      |\n",
      "|    n_updates            | 476          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 0.000545     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.70 +/- 2.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 17.7        |\n",
      "|    mean_reward          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480293 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.1         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017767319 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00837     |\n",
      "|    n_updates            | 516          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.30 +/- 4.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.3         |\n",
      "|    mean_reward          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011759921 |\n",
      "|    clip_fraction        | 0.00647      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00445     |\n",
      "|    n_updates            | 528          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.000333     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002253478 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.50 +/- 3.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.5         |\n",
      "|    mean_reward          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018115845 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00447     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 15.80 +/- 4.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 15.8         |\n",
      "|    mean_reward          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 304000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031136516 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00181     |\n",
      "|    n_updates            | 592          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850601 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0942     |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000274    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.70 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.7         |\n",
      "|    mean_reward          | 0.966        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032337075 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00715     |\n",
      "|    n_updates            | 624          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.8       |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1617       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252318 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 636        |\n",
      "|    policy_gradient_loss | 0.0043     |\n",
      "|    value_loss           | 0.000885   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.30 +/- 2.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.3        |\n",
      "|    mean_reward          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951071 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00663    |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.2         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1638         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010997921 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0889      |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 676          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.000206     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.10 +/- 3.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.1         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035515958 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00552     |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 2.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652107 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 716          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.6     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 1655     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 3.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971462 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0586      |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00444      |\n",
      "|    n_updates            | 748          |\n",
      "|    policy_gradient_loss | 0.00379      |\n",
      "|    value_loss           | 0.000147     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0612      |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.96 +/- 0.00\n",
      "Episode length: 14.10 +/- 1.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 14.1         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022809508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00753     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1687        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018788 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 0.000139    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 13.20 +/- 1.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.2        |\n",
      "|    mean_reward          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668287 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.046      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.2         |\n",
      "|    ep_rew_mean          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787798 |\n",
      "|    clip_fraction        | 0.00671      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0015      |\n",
      "|    n_updates            | 836          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.30 +/- 2.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.3         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 432000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017914244 |\n",
      "|    clip_fraction        | 0.00696      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.00 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13          |\n",
      "|    mean_reward          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641758 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.9         |\n",
      "|    ep_rew_mean          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1702         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038081002 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 876          |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 0.000284     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 11.70 +/- 2.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.7        |\n",
      "|    mean_reward          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 464000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944987 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 904         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 0.000124    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.6        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470194 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0457     |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 49.10 +/- 103.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 49.1         |\n",
      "|    mean_reward          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037453393 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0396      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0074      |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746727 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 956         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.60 +/- 2.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.6       |\n",
      "|    mean_reward          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 496000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03600844 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 968        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.000397   |\n",
      "----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 10\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.96745 +/- 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
