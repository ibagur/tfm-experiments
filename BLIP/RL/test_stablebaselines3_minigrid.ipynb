{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MiniGrid FlatObsWrapper with stable-baselines3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, RGBImgObsWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    return wrap_env(eval_env)\n",
    "\n",
    "def monitor_eval_env(env_name, log_dir=None, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    eval_env = stable_baselines3.common.monitor.Monitor(eval_env, log_dir)\n",
    "    return eval_env\n",
    "\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2)\n",
    "\n",
    "# By default, we use a DummyVecEnv as it is usually faster (cf doc)\n",
    "num_cpu = 16  # Number of processes to use\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "\n",
    "env_id = env_id\n",
    "\n",
    "seed = 2\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, wrapper_class=FlatObsWrapper, seed=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "obs = vec_env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in vec_env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_RMSprop\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0007 # for RMSProp\n",
    "#learning_rate = 0.0001 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.99\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"RMSprop\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.RMSprop}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_RMSprop_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2208 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1992        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775392 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.8        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1936        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009170571 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.411      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1915        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821949 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.35       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.00312     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0.0432      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1906        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423651 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.796      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1894        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506161 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.356      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1891        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847523 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0825     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728865 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0224    |\n",
      "|    n_updates            | 28         |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0.0306   |\n",
      "| time/              |          |\n",
      "|    fps             | 1432     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0217      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1471        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008345105 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509145 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.00824    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1530        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833168 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011894008 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.00117     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0262      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1555        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369951 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0275      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006303926 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 0.00428     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0.0328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008685214 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.302      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 0.000902    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152548 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 0.00695     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0.0429   |\n",
      "| time/              |          |\n",
      "|    fps             | 1407     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694764 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 0.00536     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 342          |\n",
      "|    ep_rew_mean          | 0.0557       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1447         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079638995 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    value_loss           | 0.00264      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140928 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | 0.0526       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1478         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073334756 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -0.401       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0317      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 0.000852     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0.0639      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065939 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0.0715      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201875 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 0.00528     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1519        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007159561 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.217      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 0.00442     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005685283 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 0.0793   |\n",
      "| time/              |          |\n",
      "|    fps             | 1406     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1417        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780833 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -3.37       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 0.000863    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009687388 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 0.00285     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | 0.0959       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079590175 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -1.07        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.03        |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    value_loss           | 0.000648     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | 0.103        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1448         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076495185 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 0.00456      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1456        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157565 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 324          |\n",
      "|    ep_rew_mean          | 0.114        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1466         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072516864 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0312      |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1472        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127866 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.00855     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011218775 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 0.104    |\n",
      "| time/              |          |\n",
      "|    fps             | 1398     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 0.129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1404        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269294 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | 0.127        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084593985 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012237323 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 0.00467     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 0.153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348253 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012431674 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.00785     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010065392 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.00354     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1447        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010351133 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 0.00171     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149271935 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00913     |\n",
      "|    value_loss           | 0.00255      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 0.179    |\n",
      "| time/              |          |\n",
      "|    fps             | 1371     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1378        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976298 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 283        |\n",
      "|    ep_rew_mean          | 0.234      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1385       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961323 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 164        |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011408685 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 0.289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810373 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00774     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | 0.312        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1404         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100941975 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0388      |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.0207       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 0.317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011928789 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00972789 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0168    |\n",
      "|    n_updates            | 184        |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    value_loss           | 0.00799    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 0.321    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 0.324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700807 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 0.349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821334 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00832     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066237 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00972    |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905958 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009255871 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 0.00979     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448459 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 204        |\n",
      "|    ep_rew_mean          | 0.453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849258 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 212        |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 324.80 +/- 105.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 325         |\n",
      "|    mean_reward          | 0.098       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729654 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 0.477    |\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 0.586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007263053 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 0.617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008733772 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444921 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008191827 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506599 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 0.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737902 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00675    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010061242 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007413777 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00787    |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 0.635    |\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 0.627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660727 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890765 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 136          |\n",
      "|    ep_rew_mean          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1381         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070074527 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0147      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 0.0213       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707212 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00994    |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009518158 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 0.724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010742119 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | 0.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646955 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00842    |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 325.40 +/- 103.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 325          |\n",
      "|    mean_reward          | 0.0965       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080566835 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0174      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 0.0214       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.4     |\n",
      "|    ep_rew_mean     | 0.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 1373     |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 88.1       |\n",
      "|    ep_rew_mean          | 0.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1379       |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00765628 |\n",
      "|    clip_fraction        | 0.0884     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0177    |\n",
      "|    n_updates            | 284        |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.2        |\n",
      "|    ep_rew_mean          | 0.776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780284 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00767     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.6        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663681 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00783    |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.882       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013481904 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876687 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.5        |\n",
      "|    ep_rew_mean          | 0.897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135613 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 0.911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099381 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.80 +/- 168.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011758837 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00115     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.3     |\n",
      "|    ep_rew_mean     | 0.905    |\n",
      "| time/              |          |\n",
      "|    fps             | 1380     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012846921 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0028     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 44         |\n",
      "|    ep_rew_mean          | 0.888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1389       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287708 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.941     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00807   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 0.0306     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36         |\n",
      "|    ep_rew_mean          | 0.909      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1392       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825456 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00843   |\n",
      "|    n_updates            | 324        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.5        |\n",
      "|    ep_rew_mean          | 0.909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011439201 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00876     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.924       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1401        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343361 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494961 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 292.20 +/- 135.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 292        |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 176000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075115 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0157    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | 0.919    |\n",
      "| time/              |          |\n",
      "|    fps             | 1385     |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.2        |\n",
      "|    ep_rew_mean          | 0.903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388014 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | 0.917        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117297955 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.75        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.00559     |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 0.0393       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.7       |\n",
      "|    ep_rew_mean          | 0.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711984 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.819     |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 352        |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 0.908        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125203915 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.000254     |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 0.0286       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.4       |\n",
      "|    ep_rew_mean          | 0.929      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1400       |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035146 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.747     |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.011     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00645   |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.3        |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597158 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 0.00873     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1405        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008591977 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.00818     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.90 +/- 168.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.575        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134988995 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 0.00493      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | 0.948    |\n",
      "| time/              |          |\n",
      "|    fps             | 1397     |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | 0.949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736785 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782128 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.00227     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.7        |\n",
      "|    ep_rew_mean          | 0.951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887598 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.00189     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 0.952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497131 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00427    |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.00661     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.5        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014433542 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279782 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.0026      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.7        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1415        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017481608 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    value_loss           | 0.00291     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 47.30 +/- 104.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.3        |\n",
      "|    mean_reward          | 0.872       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343712 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | 0.000173    |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | 0.941    |\n",
      "| time/              |          |\n",
      "|    fps             | 1413     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1416        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034888618 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    value_loss           | 0.00968     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | 0.939      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1418       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667555 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.396     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.000579  |\n",
      "|    n_updates            | 412        |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    value_loss           | 0.00822    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 0.957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1420        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814387 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | 0.000265    |\n",
      "|    value_loss           | 0.00525     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1423        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014388864 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015875302 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 0.00267     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011128774 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00659    |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16          |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010601694 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.00373     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 14.60 +/- 3.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 14.6        |\n",
      "|    mean_reward          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361956 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00797     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.96  is above the threshold 0.92\n",
      "Final time_steps: 224000\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 1\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.9431000000000002 +/- 0.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters (Adam test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_Adam\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 0.0007 # for RMSProp\n",
    "learning_rate = 2.5e-4 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.95\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"Adam\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.Adam}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "#eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_Adam_1\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009163605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 0.00391      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318327 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.847       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.000398     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185322 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 8.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 0.0113       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014565822 |\n",
      "|    clip_fraction        | 0.000122     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 0.000839     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009096736 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351728 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 8.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905658 |\n",
      "|    clip_fraction        | 0.00916     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 0.000456    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713062 |\n",
      "|    clip_fraction        | 0.00134      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0373      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 4.64e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 1425     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059436574 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.343       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.79e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.0401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065736375 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -2.63        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 0.000366     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853437 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0855      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005402373 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057163346 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403262 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163347 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0224      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.0115       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005009041 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.4         |\n",
      "|    ep_rew_mean          | 0.783        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051049516 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 316          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 0.0118       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.39\n",
      "Episode length: 290.20 +/- 139.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 290          |\n",
      "|    mean_reward          | 0.195        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037892307 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.8         |\n",
      "|    ep_rew_mean          | 0.872        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058894404 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 0.00802      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.70 +/- 168.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581107 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045598135 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 0.00502      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.80 +/- 168.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.576        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026045418 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 404          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.77 +/- 0.38\n",
      "Episode length: 84.80 +/- 137.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.8        |\n",
      "|    mean_reward          | 0.768       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044501 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.000693    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | 0.951    |\n",
      "| time/              |          |\n",
      "|    fps             | 1518     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.95 +/- 0.01\n",
      "Episode length: 18.20 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 18.2         |\n",
      "|    mean_reward          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360986 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00171     |\n",
      "|    n_updates            | 468          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.8         |\n",
      "|    ep_rew_mean          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015850707 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0105      |\n",
      "|    n_updates            | 476          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 0.000545     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.70 +/- 2.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 17.7        |\n",
      "|    mean_reward          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480293 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.1         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017767319 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00837     |\n",
      "|    n_updates            | 516          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.30 +/- 4.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.3         |\n",
      "|    mean_reward          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011759921 |\n",
      "|    clip_fraction        | 0.00647      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00445     |\n",
      "|    n_updates            | 528          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.000333     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002253478 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.50 +/- 3.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.5         |\n",
      "|    mean_reward          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018115845 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00447     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 15.80 +/- 4.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 15.8         |\n",
      "|    mean_reward          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 304000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031136516 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00181     |\n",
      "|    n_updates            | 592          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850601 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0942     |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000274    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.70 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.7         |\n",
      "|    mean_reward          | 0.966        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032337075 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00715     |\n",
      "|    n_updates            | 624          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.8       |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1617       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252318 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 636        |\n",
      "|    policy_gradient_loss | 0.0043     |\n",
      "|    value_loss           | 0.000885   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.30 +/- 2.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.3        |\n",
      "|    mean_reward          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951071 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00663    |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.2         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1638         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010997921 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0889      |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 676          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.000206     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.10 +/- 3.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.1         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035515958 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00552     |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 2.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652107 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 716          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.6     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 1655     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 3.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971462 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0586      |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00444      |\n",
      "|    n_updates            | 748          |\n",
      "|    policy_gradient_loss | 0.00379      |\n",
      "|    value_loss           | 0.000147     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0612      |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.96 +/- 0.00\n",
      "Episode length: 14.10 +/- 1.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 14.1         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022809508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00753     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1687        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018788 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 0.000139    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 13.20 +/- 1.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.2        |\n",
      "|    mean_reward          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668287 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.046      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.2         |\n",
      "|    ep_rew_mean          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787798 |\n",
      "|    clip_fraction        | 0.00671      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0015      |\n",
      "|    n_updates            | 836          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.30 +/- 2.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.3         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 432000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017914244 |\n",
      "|    clip_fraction        | 0.00696      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.00 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13          |\n",
      "|    mean_reward          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641758 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.9         |\n",
      "|    ep_rew_mean          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1702         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038081002 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 876          |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 0.000284     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 11.70 +/- 2.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.7        |\n",
      "|    mean_reward          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 464000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944987 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 904         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 0.000124    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.6        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470194 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0457     |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 49.10 +/- 103.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 49.1         |\n",
      "|    mean_reward          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037453393 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0396      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0074      |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746727 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 956         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.60 +/- 2.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.6       |\n",
      "|    mean_reward          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 496000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03600844 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 968        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.000397   |\n",
      "----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 10\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.96745 +/- 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAFkCAYAAAAEzAHUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmoUlEQVR4nO3df1RUdf4/8OfwYwZQBhwQhtFRwUwthfyRs3y3XA02wf2QFdum0Ulbj1ar9gm2zeV88udnz8GybT0V6dlzStdPmuXnU7i5J/coJqQhKcq6q8aKoagwqBAMP2SAmfv94+LUxG+Z4c575vk4556Ye9/3zmtu9Ozynvd9X5UkSRKIiMjj+SldABER9Q8Dm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEIoFdm5uLsaNG4egoCCYTCZ8/fXXSpVCRCQERQL7o48+QlZWFtatW4dTp04hISEB8+bNw/Xr15Uoh4hICColJn8ymUy4//778c477wAA7HY7jEYjVq1ahd///vd97m+321FVVYXQ0FCoVCp3l0tE5DaSJKGxsREGgwF+fr1fQwcMUU0ObW1tKCkpQXZ2tmOdn58fkpOTUVRU1O0+VqsVVqvV8fratWu455573F4rEdFQuXLlCkaPHt1rmyEP7Js3b8JmsyE6OtppfXR0NL755ptu98nJycGGDRu6rF+4cCHUarVb6iQiGgptbW3Ys2cPQkND+2w75IF9J7Kzs5GVleV4bbFYYDQaoVarGdhE5BX607075IEdGRkJf39/1NTUOK2vqamBXq/vdh+NRgONRjMU5REReawhHyWiVqsxY8YM5OfnO9bZ7Xbk5+cjMTFxqMshIhKGIl0iWVlZWLx4MWbOnIlZs2Zhy5YtaG5uxrPPPqtEOUREQlAksJ988kncuHEDa9euhdlsxn333YcDBw50+SKSiIi+p9iXjitXrsTKlSuVensiIuFwLhEiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkG4PLBzcnJw//33IzQ0FFFRUXj00UdRVlbm1GbOnDlQqVROy/PPP+/qUoiIvIrLA7ugoAArVqzA8ePHcfDgQbS3t+Phhx9Gc3OzU7tly5ahurrasbz++uuuLoWIyKsEuPqABw4ccHq9Y8cOREVFoaSkBLNnz3asDwkJgV6vd/XbExF5Lbf3YTc0NAAAdDqd0/pdu3YhMjISU6ZMQXZ2NlpaWno8htVqhcVicVqIiHyNy6+wf8hut+Oll17CT3/6U0yZMsWx/qmnnsLYsWNhMBhw5swZrF69GmVlZfjkk0+6PU5OTg42bNjgzlKJiDyeSpIkyV0Hf+GFF/D555/j6NGjGD16dI/tDh8+jKSkJJSXl2P8+PFdtlutVlitVsdri8UCo9GIZ555Bmq12i21ExENhba2NuzcuRMNDQ3QarW9tnXbFfbKlSuxf/9+FBYW9hrWAGAymQCgx8DWaDTQaDRuqZOISBQuD2xJkrBq1Sp8+umnOHLkCGJjY/vcp7S0FAAQExPj6nKIiLyGywN7xYoV2L17N/bt24fQ0FCYzWYAQFhYGIKDg3Hx4kXs3r0b8+fPR0REBM6cOYPMzEzMnj0b8fHxri6HiMhruDywt27dCkC+OeaHtm/fjiVLlkCtVuPQoUPYsmULmpubYTQakZ6ejldffdXVpRAReRW3dIn0xmg0oqCgwNVvS0Tk9TiXCBGRIBjYRESCYGATEQmCgU1EJAi33ppO/We329HS0tLnl7aeLiAgAEFBQbh16xZsNpvS5QyKSqVCSEgI/Py857rGm37PgoODlS5jyDGwPURLSwv27duHjo4OpUsZlNjYWDz44IM4duwYqqqqlC5nUIKCgrBgwQIEBQUpXYrLeNPv2Q9n//QVDGwPIUkSOjo60N7ernQpg3I7CLzhs/j7+wt/Jfpj3vZ75mu85289IiIvx8AmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhKEywN7/fr1UKlUTsukSZMc21tbW7FixQpERERg+PDhSE9PR01NjavLICLyOm65wr733ntRXV3tWI4ePerYlpmZic8++wx79+5FQUEBqqqq8Pjjj7ujDCIirxLgloMGBECv13dZ39DQgPfeew+7d+/GQw89BADYvn07Jk+ejOPHj+MnP/mJO8ohIvIKbrnCvnDhAgwGA+Li4pCRkYHKykoAQElJCdrb25GcnOxoO2nSJIwZMwZFRUU9Hs9qtcJisTgtRES+xuWBbTKZsGPHDhw4cABbt25FRUUFHnzwQTQ2NsJsNkOtViM8PNxpn+joaJjN5h6PmZOTg7CwMMdiNBpdXTYRkcdzeZdIamqq4+f4+HiYTCaMHTsWH3/8MYKDg+/omNnZ2cjKynK8tlgsDG0i8jluH9YXHh6Ou+++G+Xl5dDr9Whra0N9fb1Tm5qamm77vG/TaDTQarVOCxGRr3F7YDc1NeHixYuIiYnBjBkzEBgYiPz8fMf2srIyVFZWIjEx0d2lEBEJzeVdIi+//DLS0tIwduxYVFVVYd26dfD398eiRYsQFhaGpUuXIisrCzqdDlqtFqtWrUJiYiJHiBAR9cHlgX316lUsWrQItbW1GDlyJB544AEcP34cI0eOBAD86U9/gp+fH9LT02G1WjFv3jy8++67ri6DiMjruDyw9+zZ0+v2oKAg5ObmIjc319VvTUTk1TiXCBGRIBjYRESCYGATEQmCgU1EJAgGNhGRIBjYRESCYGATEQmCgU1EJAgGNhGRIBjYRESCYGATEQmCgU1EJAgGNhGRIBjYRESCcPn0qnRnAgICMG7cONhsNqVLGZTo6GgAQExMDDQajcLVDE5IiD9mzryKkBDvuK4pL4/GrVve9XvmaxjYHiIoKAizZ89WugyXUKlUSEhIULqMQdNqW7F06f8hNLRV6VJcYtu2h1BXF+s1v2e+iIHtIW7duoVjx46ho6ND6VIGJSYmBgkJCTh58iRu3rypdDmDEhlpx3/9V5vSZbiUN/2e3XfffUqXMeQY2B7CZrOhqqoK7e3tSpcyKLe7QW7evIlr164pXM3gtLcDdrv8syQBdXXyOlGoVEBEBBDwg//Kve33zNcwsIn6QZKAPXuAy5eVrqT/AgOB//xPICpK6UrIVRjYJIzhw+UrxnvuASZNAiIjnbc3NQENDcClS0BZGXD9OtDY6Lr3t9nkRRQqlfw/GvIeDGzyeCqV/Gd9ZCQwYQKQmiovd931fRtJkgP62jXg2DF5H7sdaGkRK2SJesPAJo8XFydfVS9fDowbB4weDYSEdG0XEQGEh8vtk5KAb7+VuwRu3HDtlTaRUhjY5LFUKkCjAWJjgcREYOJEIDoaCA2Vt/24bUCAvGg0gL8/oFYDDz0EnD4NlJQo8xmIXMk77gggr+TnB+h0wE9+Ajz9tHx1rdV2DevuhIbK7detA+bPd3elREODgU0ea/hw4D/+A5gxQ+6/9vcf2P7+/nI3SUICkJYGhIW5p06iocIuEfJYGg0wbRowZgwQHOy8rakJuHVLHhstSfJV98iRQFCQ3FalkpfgYCAmBoiPB06ckEeREImKV9jksUJDgUWL5CvkHyssBN59V+4umT4duP9+4H/+Bzh1qmvbsWOB5GT5eEQi4xU2eazbXyR21xVy6hRw6JA8+sNmk/u7CwqAjg7gpz91bqvVyqGtVg9N3UTuwsAmIf3jH8DRo9+/ttuBr76Su0R+LDRU7l5hYJPoXN4lMm7cOKhUqi7LihUrAABz5szpsu355593dRlERF7H5VfYJ06ccJpr91//+hd+/vOf44knnnCsW7ZsGTZu3Oh4HdLdXRBEvRg/Hpg6FTh7Vu4OUavluyDHjevatrVV/rJR8AnqiFwf2CNHjnR6vWnTJowfPx4/+9nPHOtCQkKg1+td/dbkQxYsAIxG4OWX5UmOdDrgiSe6/4Kyrg64eBGwWoe+TiJXcmsfdltbGz744ANkZWVB9YO7HXbt2oUPPvgAer0eaWlpWLNmTa9X2VarFdYf/NdmsVjcWTZ5iOZm4G9/k6+kJ0923nb7rkejUf5yUq2W5xbpbqx1VZXcv93UNDR1E7mLWwM7Ly8P9fX1WLJkiWPdU089hbFjx8JgMODMmTNYvXo1ysrK8Mknn/R4nJycHGzYsMGdpZIHam2VR4OMGCF3d/j7f3+Xo04nL3FxPe8vSfIIkhs3gPPn5eMRicytgf3ee+8hNTUVBoPBsW758uWOn6dOnYqYmBgkJSXh4sWLGD9+fLfHyc7ORlZWluO1xWKB0Wh0X+HkERob5Tmog4LkyZ+iouTuj/6y2YCaGuDrr4Fdu9iHTeJzW2BfvnwZhw4d6vXKGQBMJhMAoLy8vMfA1mg0PvuECV9mt8v9z0VFcpfHU0/JdzOGhPQ9n0hLC/Ddd8AHH8j7M6zJG7gtsLdv346oqCj84he/6LVdaWkpAPkZbUQ/ZLfLV9lFRcCFC/JdjWq1PKbaz09eutvHZgPq6+Wnw7z/vnyVTeQN3BLYdrsd27dvx+LFixHwgwfKXbx4Ebt378b8+fMRERGBM2fOIDMzE7Nnz0Z8fLw7SiEv0Nwsj/D43e+Au+8G5s0D5szpfgjf5cvARx8BX3wB/Pvf8heOvLomb+GWwD506BAqKyvx61//2mm9Wq3GoUOHsGXLFjQ3N8NoNCI9PR2vvvqqO8ogL2G3A21t8gMJrFZ5Fr8pU7oP7IYGoLgYOHcOuHp1yEslciu3BPbDDz8MqZuHyRmNRhQUFLjjLckH1NfLy9mzwMMPAzNndm1z4waQlzfEhRENEc4lQqSwkBD5y9SpU+Whiv1RWgqcOePWssgDMbCJFKZWy8+inDgR+MEI2F5VV7u1JPJQnA+biEgQvMImUlhrK3D9unyDj1bbv30uXXJrSeShGNjk0Xqaw7q7Mdiiam2VuzjYzUF9YWCTxzIagf/9367PcwTk5zwS+RoGNnksjQa4915g2DClKyHyDF70hyURkXfjFTZ5LLMZ+PWv5Qfx/tiLLwKd84YR+QwGNnmspibg44+73/boowxs8j3sEiEiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEBzWRx4rKgr47//ufj6R++8f+nqIlMbAJo+l1QIZGbw1neg2dokQEQmCV9jkserrga1b5Umg+uubb9xWDpHiGNjksW7eBH73O6WrIPIc7BIhIhIEr7CJ+ikmBlCplK6i/wICgMBApasgV2JgE/WDSgX88peAJCldycCI9D8Y6hsDm6gfbgcfA5CUJHRgBwQEIKC72e0FFBgYiOHDh6O9vV3pUgYlJCQEAQEBCAkJwfDhw5UuZ1CGDZMfkNvSonQlrmGzBUKlUiEoKAj+/v5KlzMo6p6ezuzlhE67u+66C0FBQUqX4RKSJOGee+5RuoxB8/f3R2BgIGJjY2G325UuZ1BUKuDzz73nqrqysgYhIY1YsGABJNH6dn5E9P/h3CmhA9vf399rrrA7OjrQ0NAgfMiFhIRAp9OhubkZra2tSpczKP7+/ggKivaacLDZatHR0YHLly8L/3um1WoxatQopcsYct6Rdl6gvb0d33zzDWw2m9KlDIper4dOp0NlZSVqa2uVLmdQ1Go1IiMjvSawAcBqteL48ePCd73FxcX5ZGAPeBx2YWEh0tLSYDAYoFKpkJeX57RdkiSsXbsWMTExCA4ORnJyMi5cuODUpq6uDhkZGdBqtQgPD8fSpUvR1NQ0qA9CROTtBhzYzc3NSEhIQG5ubrfbX3/9dbz11lvYtm0biouLMWzYMMybN8/pz+OMjAycPXsWBw8exP79+1FYWIjly5ff+acgIvIBA+4SSU1NRWpqarfbJEnCli1b8Oqrr2LBggUAgJ07dyI6Ohp5eXlYuHAhzp8/jwMHDuDEiROYOXMmAODtt9/G/Pnz8cYbb8BgMAzi4xAReS+X9mFXVFTAbDYjOTnZsS4sLAwmkwlFRUVYuHAhioqKEB4e7ghrAEhOToafnx+Ki4vx2GOPdTmu1WqF1Wp1vLZYLK4sWwgaAP8PQCSAiCF+75udSxEAax9tich9XBrYZrMZABAdHe20Pjo62rHNbDYjKirKuYiAAOh0OkebH8vJycGGDRtcWapwAgFMBnAXgAlD/N7/BlAO4AQY2ERKEmLyp+zsbDQ0NDiWK1euKF3SkLMCKABwoa+GbvBvAIVgWBMpzaWBrdfrAQA1NTVO62tqahzb9Ho9rl+/7rS9o6MDdXV1jjY/ptFooNVqnRZfYwNwA0AtgPrO1+7W0fletZ3vLfbIXSLxuTSwY2NjodfrkZ+f71hnsVhQXFyMxMREAEBiYiLq6+tRUlLiaHP48GHY7XaYTCZXluNV7ACuA6gGYAYwFKNo2zvfq7rzvRnYRMoacB92U1MTysvLHa8rKipQWloKnU6HMWPG4KWXXsIf/vAHTJgwAbGxsVizZg0MBgMeffRRAMDkyZORkpKCZcuWYdu2bWhvb8fKlSuxcOFCjhDph5sA/gUgGoC7b8q/BeCfkK+wiUh5Aw7skydPYu7cuY7XWVlZAIDFixdjx44deOWVV9Dc3Izly5ejvr4eDzzwAA4cOOA058euXbuwcuVKJCUlwc/PD+np6Xjrrbdc8HG8XyOASgBtQ/BebZ3v1TgE70VEfRtwYM+ZM6fXiWNUKhU2btyIjRs39thGp9Nh9+7dA31rAnAVcjfFAshX2e7UBOBLDE1/ORH1jXOJCMgOebSICkBs5z9dSQLwbed7iD2nG5F3EWJYHzmTAFwG4M7BjZWd78HAJvIcDGwBSQC+gXvHZF8AUAYGNpEnYWAL6jvIozca4NovINs6j3mz8z2IyHMwsAVVC3l8dDXk4Xeu0gKgqvO4HM5H5FkY2AJrAHAM8k0trlID4CsAvje9FpHnY2ALrBXyF4MNkG8jH0x/s9R5DAuAS+C8IUSeiIEtsCYA/wBwDXLQDjawLZDHeZ8B0Dzo6ojI1RjYgpMgT8xUicHN9WGDfLV+AxwZQuSpGNhe4CbkK+PB3JFo7zwGv2gk8lwMbC9wDsBRyH3Qd6q98xjnXVIREbkDA9sLtECet/om5H7tgWrE9+OuW1xXFhG5GAPbC1ghjxT5N+RheQNV07lvAzg6hMiTMbC9RBuArwFU3MG+30J+XuNQPBSBiO4cA9tL2CDfoViH/o/Jvj32uhby0EBOo0rk2RjYXsIGeWhfNeT+7P58AXn7mY3VkGf+4yPAiDwbA9vL1EIeNdLaj7a3OtvWubUiInIVBraX+Q7y1Kv9mRDqVmfbencWREQuw8D2MjcAlKJ/w/OaAZyGPKSPiDwfA9vL3J7P2gw5iLv78vH27ew1kOcPGYoH+hLR4DGwvUw75Bth/one71o819mmERzORyQKBrYXkiCPx+5pTPYPt3OiJyJxMLC9VG3nYoXz+Gob5C6Q29uJSBwBShdA7lENIAjywwj0AMI71zdC7t++1PlPIhIHr7C9lAR52N4lOE8I1di5rhXsDiESDQPbi1khh3Mj5HC+/VSZS+jfjTVE5FnYJeLF6gEcATAaQHTnuvLOda580joRDQ0GthezQ745pg7yuGtAvhOSz2skEhMD2wdU4/sx2dVKFkJEg8LA9gHf4vv5QjjRE5G4BvylY2FhIdLS0mAwGKBSqZCXl+fY1t7ejtWrV2Pq1KkYNmwYDAYDnnnmGVRVVTkdY9y4cVCpVE7Lpk2bBv1hqHvfQX7A7tXOn4lITAMO7ObmZiQkJCA3N7fLtpaWFpw6dQpr1qzBqVOn8Mknn6CsrAyPPPJIl7YbN25EdXW1Y1m1atWdfQLq0y3IV9j14JeNRCIbcJdIamoqUlNTu90WFhaGgwcPOq175513MGvWLFRWVmLMmDGO9aGhodDr9QN9eyIin+X2cdgNDQ1QqVQIDw93Wr9p0yZERERg2rRp2Lx5Mzo6en5GitVqhcVicVqIiHyNW790bG1txerVq7Fo0SJotVrH+hdffBHTp0+HTqfDV199hezsbFRXV+PNN9/s9jg5OTnYsGGDO0slIvJ4bgvs9vZ2/OpXv4IkSdi6davTtqysLMfP8fHxUKvVeO6555CTkwONRtPlWNnZ2U77WCwWGI1Gd5VOROSR3BLYt8P68uXLOHz4sNPVdXdMJhM6Ojpw6dIlTJw4sct2jUbTbZATEfkSlwf27bC+cOECvvjiC0RERPS5T2lpKfz8/BAVFeXqcoShVqsxZcoUSJLYUzIFBQUBAOLi4jBq1CiFqxkcPz8/BAR4z60K//z5P3Eu7Bw6nuiQb4MVWTXkJ3D4mAH/NjY1NaG8vNzxuqKiAqWlpdDpdIiJicEvf/lLnDp1Cvv374fNZoPZLE/iqdPpoFarUVRUhOLiYsydOxehoaEoKipCZmYmnn76aYwYMcJ1n0wwKpWqz79ERODv7w8ACAkJcYS3yFQqldIluMz1uOu4OuGq0mW4RjEY2P1x8uRJzJ071/H6dt/y4sWLsX79evz1r38FANx3331O+33xxReYM2cONBoN9uzZg/Xr18NqtSI2NhaZmZlOfdS+yGq1ori4GDabre/GHiw6Ohr33nsvzp07h7o6se+rVKvVMJlMUKvVSpdCBOAOAnvOnDm9/tne15/006dPx/Hjxwf6tj7BZrMJH9h2u93xT9E/i+j1k/fhfNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIJgYBMRCYKBTUQkCAY2EZEgGNhERIIYcGAXFhYiLS0NBoMBKpUKeXl5TtuXLFkClUrltKSkpDi1qaurQ0ZGBrRaLcLDw7F06VI0NTUN6oMQEXm7AQd2c3MzEhISkJub22OblJQUVFdXO5YPP/zQaXtGRgbOnj2LgwcPYv/+/SgsLMTy5csHXj0RkQ8JGOgOqampSE1N7bWNRqOBXq/vdtv58+dx4MABnDhxAjNnzgQAvP3225g/fz7eeOMNGAyGgZZEROQT3NKHfeTIEURFRWHixIl44YUXUFtb69hWVFSE8PBwR1gDQHJyMvz8/FBcXNzt8axWKywWi9NCRORrXB7YKSkp2LlzJ/Lz8/Haa6+hoKAAqampsNlsAACz2YyoqCinfQICAqDT6WA2m7s9Zk5ODsLCwhyL0Wh0ddlERB5vwF0ifVm4cKHj56lTpyI+Ph7jx4/HkSNHkJSUdEfHzM7ORlZWluO1xWJhaBORz3H7sL64uDhERkaivLwcAKDX63H9+nWnNh0dHairq+ux31uj0UCr1TotRES+xu2BffXqVdTW1iImJgYAkJiYiPr6epSUlDjaHD58GHa7HSaTyd3lEBEJa8BdIk1NTY6rZQCoqKhAaWkpdDoddDodNmzYgPT0dOj1ely8eBGvvPIK7rrrLsybNw8AMHnyZKSkpGDZsmXYtm0b2tvbsXLlSixcuJAjRIiIejHgK+yTJ09i2rRpmDZtGgAgKysL06ZNw9q1a+Hv748zZ87gkUcewd13342lS5dixowZ+PLLL6HRaBzH2LVrFyZNmoSkpCTMnz8fDzzwAP785z+77lMREXmhAV9hz5kzB5Ik9bj973//e5/H0Ol02L1790DfmojIp3EuESIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhKEyyd/ojvj7++P6Oho2O12pUsZlPDwcADAiBEjEBgYqGwxgxQQEAA/P++5pom+GI247+KULsMlor+NVroERTCwPYRarcaUKVOULsNl4uK8Ixi8yZRDU2Bs4CyXIvOeywciIi/HwCYiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEAxsIiJBMLCJiATBwCYiEgQDm4hIEAxsIiJBDDiwCwsLkZaWBoPBAJVKhby8PKftKpWq22Xz5s2ONuPGjeuyfdOmTYP+MERE3mzAgd3c3IyEhATk5uZ2u726utppef/996FSqZCenu7UbuPGjU7tVq1adWefgIjIRwQMdIfU1FSkpqb2uF2v1zu93rdvH+bOnYu4uDin9aGhoV3aEhFRz9zah11TU4O//e1vWLp0aZdtmzZtQkREBKZNm4bNmzejo6Ojx+NYrVZYLBanhYjI1wz4Cnsg/vKXvyA0NBSPP/640/oXX3wR06dPh06nw1dffYXs7GxUV1fjzTff7PY4OTk52LBhgztLJSLyeG4N7Pfffx8ZGRkICgpyWp+VleX4OT4+Hmq1Gs899xxycnKg0Wi6HCc7O9tpH4vFAqPR6L7CiYg8kNsC+8svv0RZWRk++uijPtuaTCZ0dHTg0qVLmDhxYpftGo2m2yAnIvIlbuvDfu+99zBjxgwkJCT02ba0tBR+fn6IiopyVzlERMIb8BV2U1MTysvLHa8rKipQWloKnU6HMWPGAJC7LPbu3Ys//vGPXfYvKipCcXEx5s6di9DQUBQVFSEzMxNPP/00RowYMYiPQkTk3QYc2CdPnsTcuXMdr2/3LS9evBg7duwAAOzZsweSJGHRokVd9tdoNNizZw/Wr18Pq9WK2NhYZGZmOvVRExFRVypJkiSlixgoi8WCsLAwvPbaawgODla6HCIhXL58GQ0NDUqXQT/S1taGnTt3oqGhAVqttte2nEuEiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEwsImIBMHAJiISBAObiEgQDGwiIkEM+JmOnuD2U81aW1sVroRIHFarFW1tbUqXQT9y+99Jf57WKOQzHa9evQqj0ah0GURELnPlyhWMHj261zZCBrbdbkdZWRnuueceXLlypc8HV1JXFosFRqOR5+8O8fwNHs+hTJIkNDY2wmAwwM+v915qIbtE/Pz8MGrUKACAVqv16X/Zg8XzNzg8f4PHcwiEhYX1qx2/dCQiEgQDm4hIEMIGtkajwbp166DRaJQuRUg8f4PD8zd4PIcDJ+SXjkREvkjYK2wiIl/DwCYiEgQDm4hIEAxsIiJBCBnYubm5GDduHIKCgmAymfD1118rXZJHWr9+PVQqldMyadIkx/bW1lasWLECERERGD58ONLT01FTU6NgxcorLCxEWloaDAYDVCoV8vLynLZLkoS1a9ciJiYGwcHBSE5OxoULF5za1NXVISMjA1qtFuHh4Vi6dCmampqG8FMop6/zt2TJki6/kykpKU5tfPn89UW4wP7oo4+QlZWFdevW4dSpU0hISMC8efNw/fp1pUvzSPfeey+qq6sdy9GjRx3bMjMz8dlnn2Hv3r0oKChAVVUVHn/8cQWrVV5zczMSEhKQm5vb7fbXX38db731FrZt24bi4mIMGzYM8+bNc5qILCMjA2fPnsXBgwexf/9+FBYWYvny5UP1ERTV1/kDgJSUFKffyQ8//NBpuy+fvz5Jgpk1a5a0YsUKx2ubzSYZDAYpJydHwao807p166SEhIRut9XX10uBgYHS3r17HevOnz8vAZCKioqGqELPBkD69NNPHa/tdruk1+ulzZs3O9bV19dLGo1G+vDDDyVJkqRz585JAKQTJ0442nz++eeSSqWSrl27NmS1e4Ifnz9JkqTFixdLCxYs6HEfnr/eCXWF3dbWhpKSEiQnJzvW+fn5ITk5GUVFRQpW5rkuXLgAg8GAuLg4ZGRkoLKyEgBQUlKC9vZ2p3M5adIkjBkzhueyBxUVFTCbzU7nLCwsDCaTyXHOioqKEB4ejpkzZzraJCcnw8/PD8XFxUNesyc6cuQIoqKiMHHiRLzwwguora11bOP5651QgX3z5k3YbDZER0c7rY+OjobZbFaoKs9lMpmwY8cOHDhwAFu3bkVFRQUefPBBNDY2wmw2Q61WIzw83Gkfnsue3T4vvf3+mc1mREVFOW0PCAiATqfjeYXcHbJz507k5+fjtddeQ0FBAVJTU2Gz2QDw/PVFyNn6qH9SU1MdP8fHx8NkMmHs2LH4+OOPERwcrGBl5KsWLlzo+Hnq1KmIj4/H+PHjceTIESQlJSlYmRiEusKOjIyEv79/l5EMNTU10Ov1ClUljvDwcNx9990oLy+HXq9HW1sb6uvrndrwXPbs9nnp7fdPr9d3+QK8o6MDdXV1PK/diIuLQ2RkJMrLywHw/PVFqMBWq9WYMWMG8vPzHevsdjvy8/ORmJioYGViaGpqwsWLFxETE4MZM2YgMDDQ6VyWlZWhsrKS57IHsbGx0Ov1TufMYrGguLjYcc4SExNRX1+PkpISR5vDhw/DbrfDZDINec2e7urVq6itrUVMTAwAnr8+Kf2t50Dt2bNH0mg00o4dO6Rz585Jy5cvl8LDwyWz2ax0aR7nt7/9rXTkyBGpoqJCOnbsmJScnCxFRkZK169flyRJkp5//nlpzJgx0uHDh6WTJ09KiYmJUmJiosJVK6uxsVE6ffq0dPr0aQmA9Oabb0qnT5+WLl++LEmSJG3atEkKDw+X9u3bJ505c0ZasGCBFBsbK926dctxjJSUFGnatGlScXGxdPToUWnChAnSokWLlPpIQ6q389fY2Ci9/PLLUlFRkVRRUSEdOnRImj59ujRhwgSptbXVcQxfPn99ES6wJUmS3n77bWnMmDGSWq2WZs2aJR0/flzpkjzSk08+KcXExEhqtVoaNWqU9OSTT0rl5eWO7bdu3ZJ+85vfSCNGjJBCQkKkxx57TKqurlawYuV98cUXEoAuy+LFiyVJkof2rVmzRoqOjpY0Go2UlJQklZWVOR2jtrZWWrRokTR8+HBJq9VKzz77rNTY2KjApxl6vZ2/lpYW6eGHH5ZGjhwpBQYGSmPHjpWWLVvW5WLLl89fXzi9KhGRIITqwyYi8mUMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhIEA5uISBAMbCIiQTCwiYgEwcAmIhLE/wdcZbO7tustzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
