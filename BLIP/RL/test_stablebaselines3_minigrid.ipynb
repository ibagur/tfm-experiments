{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MiniGrid FlatObsWrapper with stable-baselines3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, RGBImgObsWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    return wrap_env(eval_env)\n",
    "\n",
    "def monitor_eval_env(env_name, log_dir=None, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    eval_env = stable_baselines3.common.monitor.Monitor(eval_env, log_dir)\n",
    "    return eval_env\n",
    "\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2)\n",
    "\n",
    "# By default, we use a DummyVecEnv as it is usually faster (cf doc)\n",
    "num_cpu = 16  # Number of processes to use\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-DoorKeyLava-6x6-v0'\n",
    "\n",
    "env_id = env_id\n",
    "\n",
    "seed = 2\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, wrapper_class=FlatObsWrapper, seed=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "obs = vec_env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in vec_env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKeyLava-6x6-v0_PPO_RMSprop\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0007 # for RMSProp\n",
    "#learning_rate = 0.0001 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.99\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"RMSprop\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.RMSprop}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKeyLava-6x6-v0_PPO_RMSprop_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.6     |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2167     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.5        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1951        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010956054 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -3.88       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00669    |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.553       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.4        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1885        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764853 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -1.38       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0268     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00581     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 83.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1865        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010580789 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.362      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.00179     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.5        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1847        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435622 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.273      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.00212     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | 0.0071      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1847        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012195164 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.395      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.00178     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 0.0071      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1847        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338869 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0252     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0338     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.00562     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00904821 |\n",
      "|    clip_fraction        | 0.0934     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.84      |\n",
      "|    explained_variance   | -0.265     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0361    |\n",
      "|    n_updates            | 28         |\n",
      "|    policy_gradient_loss | -0.00719   |\n",
      "|    value_loss           | 0.0019     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | 0.0071   |\n",
      "| time/              |          |\n",
      "|    fps             | 1393     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 0.0071      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1431        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498132 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.168      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0379     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1466        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005752398 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.216      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1490        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009532645 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    value_loss           | 0.00249     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1509        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013013003 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.362      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0539     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000995    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 202         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1525        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959276 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.117      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.037      |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1543        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008132821 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.187      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0308     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 229         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1556        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009197317 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.158      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    value_loss           | 0.000823    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008837152 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.0389     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0431     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    value_loss           | 0.00111     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 240      |\n",
      "|    ep_rew_mean     | 0.0105   |\n",
      "| time/              |          |\n",
      "|    fps             | 1392     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 245          |\n",
      "|    ep_rew_mean          | 0.0105       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1412         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060298196 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | -0.0528      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0346      |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 0.00102      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 256         |\n",
      "|    ep_rew_mean          | 0.0105      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011563264 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.171      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 68          |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.000939    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 266         |\n",
      "|    ep_rew_mean          | 0.00343     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228043 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.124      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    value_loss           | 0.000766    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 267         |\n",
      "|    ep_rew_mean          | 0.00343     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1458        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008411603 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.206      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 0.00343     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1470        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010797586 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.0486     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0463     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 9.9e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 0.00343     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1484        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011540432 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -0.0224     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.000952    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 291        |\n",
      "|    ep_rew_mean          | 0.00343    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00969292 |\n",
      "|    clip_fraction        | 0.0826     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -0.362     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0274    |\n",
      "|    n_updates            | 88         |\n",
      "|    policy_gradient_loss | -0.00981   |\n",
      "|    value_loss           | 0.000736   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959757 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -0.0212     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0456     |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    value_loss           | 0.000615    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 298      |\n",
      "|    ep_rew_mean     | 0.00665  |\n",
      "| time/              |          |\n",
      "|    fps             | 1394     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 0.00665     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010116698 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.0332      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 0.00186     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 303        |\n",
      "|    ep_rew_mean          | 0.00323    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1419       |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00784948 |\n",
      "|    clip_fraction        | 0.0607     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -0.972     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0151    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00883   |\n",
      "|    value_loss           | 0.000309   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 306         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1432        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008656388 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.00218    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 104         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.00077     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 309         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1439        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009991726 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.0369     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0324     |\n",
      "|    n_updates            | 108         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 0.000619    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 309         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008737507 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.133      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.000797    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 315         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1452        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009063059 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    value_loss           | 0.000638    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 316        |\n",
      "|    ep_rew_mean          | 0.00323    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1460       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01055537 |\n",
      "|    clip_fraction        | 0.0985     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.73      |\n",
      "|    explained_variance   | -0.212     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0336    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 0.00061    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009556841 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.187      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000671    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | 0.00323  |\n",
      "| time/              |          |\n",
      "|    fps             | 1382     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011329947 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -0.000128   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000976    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 326         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012184693 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.465      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.000192    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009004815 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0324     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    value_loss           | 0.000801    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | 0.00323      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1409         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071585216 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | -0.0737      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0257      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 0.000451     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 326         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006737291 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -0.0335     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    value_loss           | 0.000579    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | 0.00323     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1417        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008289249 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 0.000593    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 334        |\n",
      "|    ep_rew_mean          | 0.00323    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1423       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00933912 |\n",
      "|    clip_fraction        | 0.0959     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.73      |\n",
      "|    explained_variance   | -0.037     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 152        |\n",
      "|    policy_gradient_loss | -0.00668   |\n",
      "|    value_loss           | 0.000317   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010271493 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0583     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    value_loss           | 0.00088     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 334      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1358     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1366        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009910114 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 0.00044     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1372        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011584993 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.027      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 164         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 0.00036     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010465862 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.0283     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.000755    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 340        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1387       |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077681 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | -0.00831   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0364    |\n",
      "|    n_updates            | 172        |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    value_loss           | 0.000551   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009750827 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -0.0228     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 0.000329    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009900792 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0062     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 0.000512    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 96000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010048741 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -0.1        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0404     |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 0.000438    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1360        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010570247 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.0694     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.00049     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008554116 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.0425     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 8.91e-05    |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 0.00065     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290017 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.104      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 7.49e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 342        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1381       |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 75         |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01105484 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | -0.0854    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0298    |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 0.000794   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008950453 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.114      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0359     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 4.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1394        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915527 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -0.197      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0311     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.000486    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007846142 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    value_loss           | 9.22e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009212935 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 6.92e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0217     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 0.000753    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1361     |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1366        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067784 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -0.032      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 4.04e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 343        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1369       |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 116736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00855184 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.57      |\n",
      "|    explained_variance   | -0.164     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0329    |\n",
      "|    n_updates            | 224        |\n",
      "|    policy_gradient_loss | -0.00632   |\n",
      "|    value_loss           | 0.000582   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006505863 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.0304      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007161441 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 0.000797    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1376        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986136 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -0.0544     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    value_loss           | 1.33e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1377        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011727709 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -0.0333     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.000512    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1378        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009166161 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0138     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 4.03e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009440961 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.0217     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0393     |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    value_loss           | 0.000805    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 339      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1340     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1344        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009929955 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -0.0277     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0257     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 1.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554744 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.000525    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0239     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    value_loss           | 0.000287    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1353        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010786528 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -0.0057     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    value_loss           | 0.000395    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 343        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1357       |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182682 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.76      |\n",
      "|    explained_variance   | 0.00422    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0181    |\n",
      "|    n_updates            | 264        |\n",
      "|    policy_gradient_loss | -0.0094    |\n",
      "|    value_loss           | 0.000265   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122812595 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | -0.0312      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0308      |\n",
      "|    n_updates            | 268          |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    value_loss           | 0.000457     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1366        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008625356 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    value_loss           | 0.000268    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1370        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009665068 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0187     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000753    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 144000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011921263 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.107      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0311     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 3.19e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1341     |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125207 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -0.00904    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 284         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    value_loss           | 0.000465    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 346          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112745855 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | -0.00381     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0301      |\n",
      "|    n_updates            | 288          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009400653 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.000325    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0344     |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 0.000207    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1360        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011059102 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.00256    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    value_loss           | 0.000536    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1364        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833919 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -0.00166    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0343     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 0.000224    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012784688 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -0.00463    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    value_loss           | 0.000685    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 347          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1371         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110866595 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.00875      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0285      |\n",
      "|    n_updates            | 308          |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    value_loss           | 0.000102     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011332233 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0014     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000452    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 349      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1340     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 120      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1343        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008997668 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.000942    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.00032     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008981667 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.0125     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000238    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011679573 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.00732     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.021      |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000464    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007490764 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.00085     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 0.000332    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 342        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1353       |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01002454 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | -0.00838   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00979   |\n",
      "|    n_updates            | 332        |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    value_loss           | 0.000577   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976666 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.00699     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    value_loss           | 9.74e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007769914 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.000193    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 0.000482    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 338      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1326     |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1329        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008985724 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.0024     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    value_loss           | 0.000311    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006836436 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.000135   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 348         |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    value_loss           | 0.000131    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1336        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008349818 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.000944    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 352         |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    value_loss           | 0.000758    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006680929 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.0043      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 356         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    value_loss           | 2.57e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 344        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1343       |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00750191 |\n",
      "|    clip_fraction        | 0.0892     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | -0.0163    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00841   |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    value_loss           | 0.000447   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1347         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071222465 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00322      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0237      |\n",
      "|    n_updates            | 364          |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    value_loss           | 6.15e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327682 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.00124     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 0.00081     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088602705 |\n",
      "|    clip_fraction        | 0.0912       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -0.00127     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.012       |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    value_loss           | 2.59e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1330     |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008481519 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -0.0287     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 0.000313    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 349        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1336       |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01016889 |\n",
      "|    clip_fraction        | 0.0908     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | -0.00143   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00943   |\n",
      "|    value_loss           | 0.000316   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1338        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008583711 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.000673    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0406     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 0.000276    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1341        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007643447 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.00154    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 0.000403    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1343        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005221839 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0026     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    value_loss           | 0.000376    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 349          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1345         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081537645 |\n",
      "|    clip_fraction        | 0.0887       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.000522     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 348        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1346       |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 153        |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00978762 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | -0.00435   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0299    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00948   |\n",
      "|    value_loss           | 0.000803   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011089518 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.001       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 3.3e-05     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1321     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008857716 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.00209     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0206     |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    value_loss           | 0.000419    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 353        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1326       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 160        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00867716 |\n",
      "|    clip_fraction        | 0.0748     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | -0.00449   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0181    |\n",
      "|    n_updates            | 412        |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    value_loss           | 0.000168   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008079762 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.000177   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 0.00039     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 351        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1331       |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888907 |\n",
      "|    clip_fraction        | 0.0868     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | 0.000171   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0281    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00899   |\n",
      "|    value_loss           | 0.000332   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 351          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063827476 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.00587      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.00587     |\n",
      "|    n_updates            | 424          |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 0.000406     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011491812 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.00603    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0242     |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000142    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011845736 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.0027     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 0.000597    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007925333 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -0.0079     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0328     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 0.000237    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 349      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1321     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1325        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009839578 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -0.00177    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    value_loss           | 0.000745    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008923195 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.00185    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 444         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 0.000103    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1331        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009829016 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0217     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 448         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.000458    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009794399 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.0024     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 452         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1336        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009341022 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.00105     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0409     |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000327    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1338        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010248633 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.00136    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.000298    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010489655 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.00304     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 464         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.000399    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010399913 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -0.00179    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 468         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000351    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 343      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1319     |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 183      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 339        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1321       |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01205102 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | -0.0208    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0242    |\n",
      "|    n_updates            | 472        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 0.000281   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224113 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.00299    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.05       |\n",
      "|    n_updates            | 476         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.000744    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098625 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.00323     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 4.89e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 338          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1326         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112168975 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | -0.0298      |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0222      |\n",
      "|    n_updates            | 484          |\n",
      "|    policy_gradient_loss | -0.00969     |\n",
      "|    value_loss           | 0.000426     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008793803 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.000559   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 488         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000304    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 335        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1330       |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 190        |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01132069 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.000319   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0255    |\n",
      "|    n_updates            | 492        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    value_loss           | 0.00018    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999924 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 1.38e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.000466    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 337      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222912 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000384    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011204559 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.00251    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 504         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.000291    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008084182 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.000473    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0372     |\n",
      "|    n_updates            | 508         |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 0.000612    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009256378 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.00416    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 512         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 3.1e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 336        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1326       |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 200        |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01108771 |\n",
      "|    clip_fraction        | 0.0962     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -0.0171    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 516        |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    value_loss           | 0.000479   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009305169 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.000279    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.031      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 5.54e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1331        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010868723 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.00122    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 524         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.000761    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 272000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009715065 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.00126    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0433     |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    value_loss           | 1.64e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 133      |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 272384   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177609 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.000786   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 532         |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    value_loss           | 0.000335    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007668748 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.00052     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0342     |\n",
      "|    n_updates            | 536         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.00032     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012082377 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.000412    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009822248 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.00543     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 544         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.00041     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1325        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008109976 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00352     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 548         |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 0.000359    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 336         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1327        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012682037 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.00653    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000317    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010266104 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.000576    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010589412 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -0.000292   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 3.05e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 334      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 141      |\n",
      "|    time_elapsed    | 220      |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008825925 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.00247     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0325     |\n",
      "|    n_updates            | 564         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.000457    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009422807 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.000746   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 568         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    value_loss           | 9.27e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 328          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139023885 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.000851     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0164      |\n",
      "|    n_updates            | 572          |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.00056      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010650378 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.00217    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 8.58e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 328        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1322       |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 226        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00915391 |\n",
      "|    clip_fraction        | 0.0894     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | 0.000902   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.038     |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00863   |\n",
      "|    value_loss           | 0.000419   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012919709 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.000783    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0417     |\n",
      "|    n_updates            | 584         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000515    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 326         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1326        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009591136 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -0.00126    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 588         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000407    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 304000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011460906 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.00173    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 592         |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    value_loss           | 0.000287    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 149      |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 305152   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008977238 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.000741    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    value_loss           | 0.000473    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010325388 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.000195    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    value_loss           | 0.000323    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014531249 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -0.000157   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 604         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.000215    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 340        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1322       |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00927631 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 0.000876   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.029     |\n",
      "|    n_updates            | 608        |\n",
      "|    policy_gradient_loss | -0.00912   |\n",
      "|    value_loss           | 0.000874   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009893682 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.000195   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 612         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 4.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1326        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010799014 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.00304    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 616         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.000341    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 340        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1327       |\n",
      "|    iterations           | 156        |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00990059 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | 3.46e-06   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0294    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.00928   |\n",
      "|    value_loss           | 9.98e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009753248 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 4.47e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0465     |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 0.00046     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 341      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012789005 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -7.62e-05   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0325     |\n",
      "|    n_updates            | 628         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.000325    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010829337 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.000768   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 632         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.000246    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010978174 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 5.64e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 636         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.000389    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009133222 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.00099     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    value_loss           | 0.0004      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 350       |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1315      |\n",
      "|    iterations           | 162       |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 331776    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0101791 |\n",
      "|    clip_fraction        | 0.0857    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.68     |\n",
      "|    explained_variance   | -0.0635   |\n",
      "|    learning_rate        | 0.0007    |\n",
      "|    loss                 | -0.0253   |\n",
      "|    n_updates            | 644       |\n",
      "|    policy_gradient_loss | -0.0088   |\n",
      "|    value_loss           | 0.000615  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010289698 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.00011    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00847    |\n",
      "|    n_updates            | 648         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 0.000403    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010595733 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.00012     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 652         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000406    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011509741 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.000156    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    value_loss           | 0.000359    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 349      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 165      |\n",
      "|    time_elapsed    | 258      |\n",
      "|    total_timesteps | 337920   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010658126 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.000667   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0412     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.00034     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 349          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 342016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109009845 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | -0.000177    |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.03        |\n",
      "|    n_updates            | 664          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 0.000376     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008772937 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 6.19e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 668         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.00033     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011069116 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.000103    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0409     |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000795    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010478286 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.00127     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 676         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 7.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010393843 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.00234     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0434     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.000222    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 352000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011873528 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.000383   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0413     |\n",
      "|    n_updates            | 684         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.00029     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 172      |\n",
      "|    time_elapsed    | 270      |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 345        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 271        |\n",
      "|    total_timesteps      | 354304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01303717 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | -0.000911  |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0324    |\n",
      "|    n_updates            | 688        |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.000415   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 345        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1305       |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 356352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01190043 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 0.000177   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0238    |\n",
      "|    n_updates            | 692        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 0.000211   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009995699 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -8.29e-05   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0238     |\n",
      "|    n_updates            | 696         |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    value_loss           | 0.000371    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011633225 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.0031     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 0.000428    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009071464 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -0.000743   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 704         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    value_loss           | 0.000564    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012859689 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -0.00274    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 708         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011883168 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -0.000544   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 712         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.000393    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 368000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010961287 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.00176    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 716         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.000304    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 341      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1288     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 286      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010290954 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 9.89e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.000405    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008889595 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.004       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 724         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.000379    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075640394 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | -0.00936     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0393      |\n",
      "|    n_updates            | 728          |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    value_loss           | 0.000286     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1289        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009570469 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -0.000942   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 732         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000486    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010235456 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 736         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.000458    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009322262 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.000124   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.000358    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.00185     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211225 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.00204     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 744         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    value_loss           | 0.000331    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 360       |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 384000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0075616 |\n",
      "|    clip_fraction        | 0.0691    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.58     |\n",
      "|    explained_variance   | 0.000623  |\n",
      "|    learning_rate        | 0.0007    |\n",
      "|    loss                 | -0.029    |\n",
      "|    n_updates            | 748       |\n",
      "|    policy_gradient_loss | -0.00894  |\n",
      "|    value_loss           | 0.000661  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | 0.00185  |\n",
      "| time/              |          |\n",
      "|    fps             | 1280     |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 300      |\n",
      "|    total_timesteps | 385024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.00185     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010816956 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0105     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0278     |\n",
      "|    n_updates            | 752         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000372    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.00185      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1283         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 303          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120005645 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | -0.00448     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.000313     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 348        |\n",
      "|    ep_rew_mean          | 0.00185    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1284       |\n",
      "|    iterations           | 191        |\n",
      "|    time_elapsed         | 304        |\n",
      "|    total_timesteps      | 391168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00850662 |\n",
      "|    clip_fraction        | 0.0851     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.57      |\n",
      "|    explained_variance   | 0.00143    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0208    |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.00928   |\n",
      "|    value_loss           | 0.00045    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 0.00185     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524593 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -0.0054     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.031      |\n",
      "|    n_updates            | 764         |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    value_loss           | 0.000469    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 342        |\n",
      "|    ep_rew_mean          | 0.00185    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1288       |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 395264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01099485 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -0.00468   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0331    |\n",
      "|    n_updates            | 768        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.000344   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 340          |\n",
      "|    ep_rew_mean          | 0.00185      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 308          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095091835 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -2.13e-05    |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0272      |\n",
      "|    n_updates            | 772          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 0.000393     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0.00185     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011952829 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -0.00109    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 776         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.000335    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449687 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.000946   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0372     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000444    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 336      |\n",
      "|    ep_rew_mean     | 0.00185  |\n",
      "| time/              |          |\n",
      "|    fps             | 1282     |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 312      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | 0.00925     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011299856 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00123     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 784         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.00017     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 330        |\n",
      "|    ep_rew_mean          | 0.00925    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1286       |\n",
      "|    iterations           | 198        |\n",
      "|    time_elapsed         | 315        |\n",
      "|    total_timesteps      | 405504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00947636 |\n",
      "|    clip_fraction        | 0.0789     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | -0.00034   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.022     |\n",
      "|    n_updates            | 788        |\n",
      "|    policy_gradient_loss | -0.00661   |\n",
      "|    value_loss           | 0.00651    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 0.00925     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1289        |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012902968 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.0161     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 792         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 1.97e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 0.00925     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009736556 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.0502     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0447     |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.000415    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | 0.00925     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010117974 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.000157    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    value_loss           | 8.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 0.00925     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010441702 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 5.36e-07    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 804         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000395    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 323         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163428 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.000651    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 808         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000411    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010178039 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.000735    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0026     |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    value_loss           | 0.000211    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 0.0074   |\n",
      "| time/              |          |\n",
      "|    fps             | 1290     |\n",
      "|    iterations      | 204      |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 417792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009027364 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.000179    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 816         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 0.000627    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010602903 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.00264     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0373     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.000116    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 322         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009572571 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -0.00179    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 824         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.000377    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 325         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012017278 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.00031     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0393     |\n",
      "|    n_updates            | 828         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000288    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011290472 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.00107     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 832         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.000438    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1300        |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009752594 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.000627    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 836         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000268    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 432000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009395048 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -0.0546     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 0.000486    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 329      |\n",
      "|    ep_rew_mean     | 0.0074   |\n",
      "| time/              |          |\n",
      "|    fps             | 1291     |\n",
      "|    iterations      | 211      |\n",
      "|    time_elapsed    | 334      |\n",
      "|    total_timesteps | 432128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 331         |\n",
      "|    ep_rew_mean          | 0.0074      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008215828 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.00196     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 844         |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    value_loss           | 0.000345    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011655803 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.00127     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.027      |\n",
      "|    n_updates            | 848         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.000332    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009954825 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.000528    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 852         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.000404    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009600103 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -0.00023    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 856         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000281    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010118457 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.00332    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.00038     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008310689 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.000802   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 864         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.000811    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014210899 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 868         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 6.09e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 448000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109683275 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | -0.00311     |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0378      |\n",
      "|    n_updates            | 872          |\n",
      "|    policy_gradient_loss | -0.00864     |\n",
      "|    value_loss           | 0.000246     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1291     |\n",
      "|    iterations      | 219      |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 448512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009339657 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -0.0013     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 876         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.000369    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829197 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -8.81e-05   |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    value_loss           | 6.75e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 350          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 350          |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095920935 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0264      |\n",
      "|    n_updates            | 884          |\n",
      "|    policy_gradient_loss | -0.00962     |\n",
      "|    value_loss           | 0.000441     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009687962 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -0.0156     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 888         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 0.000373    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009611763 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.001      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0433     |\n",
      "|    n_updates            | 892         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.000595    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009097982 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -0.00416    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 896         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 8.86e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1300        |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010920752 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.00243    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0554     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.000245    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 464000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01011056 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | -0.000493  |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0288    |\n",
      "|    n_updates            | 904        |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    value_loss           | 0.000344   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 352      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1289     |\n",
      "|    iterations      | 227      |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 464896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1289        |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008466154 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 1.74e-05    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00771    |\n",
      "|    n_updates            | 908         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.000315    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1289        |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010522195 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.000269    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0483     |\n",
      "|    n_updates            | 912         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000342    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010838972 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.00268     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.000421    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010343695 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.008      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 0.000242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011414195 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.00198    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 924         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.000587    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012604759 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.000206    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 928         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000127    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017663196 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0334     |\n",
      "|    n_updates            | 932         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.000487    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 480000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00925272 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.000962   |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0254    |\n",
      "|    n_updates            | 936        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 0.000126   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1283     |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 374      |\n",
      "|    total_timesteps | 481280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010446165 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.00235    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000688    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 377         |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703679 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -0.00018    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 944         |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    value_loss           | 2.14e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011961421 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.00144     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0455     |\n",
      "|    n_updates            | 948         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.000342    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008764906 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.00362     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 952         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000313    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 354        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1291       |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 380        |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01105237 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.00061    |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0303    |\n",
      "|    n_updates            | 956        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.000316   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012922284 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.00762    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.000356    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009474585 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0557     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 964         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.000358    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 496000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009187238 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 968         |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    value_loss           | 0.000374    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 352      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 1286     |\n",
      "|    iterations      | 243      |\n",
      "|    time_elapsed    | 386      |\n",
      "|    total_timesteps | 497664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012533965 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.0032      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0479     |\n",
      "|    n_updates            | 972         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000476    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010885375 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.0436     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 976         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.000232    |\n",
      "-----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 1\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.0 +/- 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters (Adam test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_Adam\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 0.0007 # for RMSProp\n",
    "learning_rate = 2.5e-4 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.95\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"Adam\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.Adam}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "#eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_Adam_1\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009163605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 0.00391      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318327 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.847       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.000398     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185322 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 8.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 0.0113       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014565822 |\n",
      "|    clip_fraction        | 0.000122     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 0.000839     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009096736 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351728 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 8.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905658 |\n",
      "|    clip_fraction        | 0.00916     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 0.000456    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713062 |\n",
      "|    clip_fraction        | 0.00134      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0373      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 4.64e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 1425     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059436574 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.343       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.79e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.0401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065736375 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -2.63        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 0.000366     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853437 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0855      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005402373 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057163346 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403262 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163347 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0224      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.0115       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005009041 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.4         |\n",
      "|    ep_rew_mean          | 0.783        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051049516 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 316          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 0.0118       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.39\n",
      "Episode length: 290.20 +/- 139.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 290          |\n",
      "|    mean_reward          | 0.195        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037892307 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.8         |\n",
      "|    ep_rew_mean          | 0.872        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058894404 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 0.00802      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.70 +/- 168.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581107 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045598135 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 0.00502      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.80 +/- 168.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.576        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026045418 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 404          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.77 +/- 0.38\n",
      "Episode length: 84.80 +/- 137.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.8        |\n",
      "|    mean_reward          | 0.768       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044501 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.000693    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | 0.951    |\n",
      "| time/              |          |\n",
      "|    fps             | 1518     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.95 +/- 0.01\n",
      "Episode length: 18.20 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 18.2         |\n",
      "|    mean_reward          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360986 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00171     |\n",
      "|    n_updates            | 468          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.8         |\n",
      "|    ep_rew_mean          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015850707 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0105      |\n",
      "|    n_updates            | 476          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 0.000545     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.70 +/- 2.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 17.7        |\n",
      "|    mean_reward          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480293 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.1         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017767319 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00837     |\n",
      "|    n_updates            | 516          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.30 +/- 4.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.3         |\n",
      "|    mean_reward          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011759921 |\n",
      "|    clip_fraction        | 0.00647      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00445     |\n",
      "|    n_updates            | 528          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.000333     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002253478 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.50 +/- 3.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.5         |\n",
      "|    mean_reward          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018115845 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00447     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 15.80 +/- 4.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 15.8         |\n",
      "|    mean_reward          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 304000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031136516 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00181     |\n",
      "|    n_updates            | 592          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850601 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0942     |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000274    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.70 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.7         |\n",
      "|    mean_reward          | 0.966        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032337075 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00715     |\n",
      "|    n_updates            | 624          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.8       |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1617       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252318 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 636        |\n",
      "|    policy_gradient_loss | 0.0043     |\n",
      "|    value_loss           | 0.000885   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.30 +/- 2.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.3        |\n",
      "|    mean_reward          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951071 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00663    |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.2         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1638         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010997921 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0889      |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 676          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.000206     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.10 +/- 3.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.1         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035515958 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00552     |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 2.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652107 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 716          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.6     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 1655     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 3.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971462 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0586      |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00444      |\n",
      "|    n_updates            | 748          |\n",
      "|    policy_gradient_loss | 0.00379      |\n",
      "|    value_loss           | 0.000147     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0612      |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.96 +/- 0.00\n",
      "Episode length: 14.10 +/- 1.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 14.1         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022809508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00753     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1687        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018788 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 0.000139    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 13.20 +/- 1.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.2        |\n",
      "|    mean_reward          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668287 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.046      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.2         |\n",
      "|    ep_rew_mean          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787798 |\n",
      "|    clip_fraction        | 0.00671      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0015      |\n",
      "|    n_updates            | 836          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.30 +/- 2.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.3         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 432000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017914244 |\n",
      "|    clip_fraction        | 0.00696      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.00 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13          |\n",
      "|    mean_reward          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641758 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.9         |\n",
      "|    ep_rew_mean          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1702         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038081002 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 876          |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 0.000284     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 11.70 +/- 2.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.7        |\n",
      "|    mean_reward          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 464000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944987 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 904         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 0.000124    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.6        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470194 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0457     |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 49.10 +/- 103.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 49.1         |\n",
      "|    mean_reward          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037453393 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0396      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0074      |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746727 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 956         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.60 +/- 2.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.6       |\n",
      "|    mean_reward          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 496000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03600844 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 968        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.000397   |\n",
      "----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 10\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.96745 +/- 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
