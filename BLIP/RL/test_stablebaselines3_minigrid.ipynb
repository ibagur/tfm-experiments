{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MiniGrid FlatObsWrapper with stable-baselines3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, RGBImgObsWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    return wrap_env(eval_env)\n",
    "\n",
    "def monitor_eval_env(env_name, log_dir=None, seed=None):\n",
    "    env = gym.make(env_name)\n",
    "    env.seed(seed)\n",
    "    eval_env = FlatObsWrapper(env)\n",
    "    eval_env = stable_baselines3.common.monitor.Monitor(eval_env, log_dir)\n",
    "    return eval_env\n",
    "\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectorized environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(2)\n",
    "\n",
    "# By default, we use a DummyVecEnv as it is usually faster (cf doc)\n",
    "num_cpu = 16  # Number of processes to use\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "\n",
    "env_id = env_id\n",
    "\n",
    "seed = 2\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, wrapper_class=FlatObsWrapper, seed=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "obs = vec_env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in vec_env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_RMSprop\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0007 # for RMSProp\n",
    "#learning_rate = 0.0001 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.99\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"RMSprop\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.RMSprop}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_RMSprop_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2208 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1992        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019775392 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.8        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1936        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009170571 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.411      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 0.0486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1915        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821949 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.35       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.00312     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 0.0432      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1906        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423651 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.796      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1894        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506161 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.356      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 0.0243      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1891        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847523 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0825     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00728865 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0224    |\n",
      "|    n_updates            | 28         |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 0.0306   |\n",
      "| time/              |          |\n",
      "|    fps             | 1432     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0217      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1471        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008345105 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1504        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509145 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.00824    |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1530        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833168 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011894008 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.00117     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0262      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1555        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369951 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.0275      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006303926 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0197     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 0.00428     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 0.0328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008685214 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.302      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 0.000902    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152548 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 0.00695     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 0.0429   |\n",
      "| time/              |          |\n",
      "|    fps             | 1407     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007694764 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 0.00536     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 342          |\n",
      "|    ep_rew_mean          | 0.0557       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1447         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079638995 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    value_loss           | 0.00264      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 0.0495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140928 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | 0.0526       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1478         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073334756 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -0.401       |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0317      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 0.000852     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 0.0639      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065939 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 0.0715      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201875 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 0.00528     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 0.0819      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1519        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007159561 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.217      |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 88          |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 0.00442     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005685283 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 0.0793   |\n",
      "| time/              |          |\n",
      "|    fps             | 1406     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1417        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005780833 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -3.37       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 0.000863    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009687388 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 0.00285     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | 0.0959       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079590175 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -1.07        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.03        |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    value_loss           | 0.000648     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | 0.103        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1448         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076495185 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 108          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 0.00456      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1456        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010157565 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 324          |\n",
      "|    ep_rew_mean          | 0.114        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1466         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072516864 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0312      |\n",
      "|    n_updates            | 116          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1472        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127866 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.00855     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011218775 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 0.104    |\n",
      "| time/              |          |\n",
      "|    fps             | 1398     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | 0.129       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1404        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269294 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.00463     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | 0.127        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084593985 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 0.0107       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1418        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012237323 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 0.00467     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 0.153       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348253 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.0036      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012431674 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.00785     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1441        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010065392 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.00354     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 310         |\n",
      "|    ep_rew_mean          | 0.155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1447        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010351133 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 0.00171     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149271935 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00913     |\n",
      "|    value_loss           | 0.00255      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 0.179    |\n",
      "| time/              |          |\n",
      "|    fps             | 1371     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1378        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976298 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 283        |\n",
      "|    ep_rew_mean          | 0.234      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1385       |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961323 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0154    |\n",
      "|    n_updates            | 164        |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011408685 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 0.0119      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 0.289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810373 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00774     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | 0.312        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1404         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100941975 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0388      |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.0207       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 254         |\n",
      "|    ep_rew_mean          | 0.317       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1407        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011928789 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 360        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 96000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00972789 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0168    |\n",
      "|    n_updates            | 184        |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    value_loss           | 0.00799    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 0.321    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 0.324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700807 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 0.349       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821334 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00832     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 230         |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066237 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00972    |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905958 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.0128      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 227         |\n",
      "|    ep_rew_mean          | 0.389       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009255871 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 0.00979     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010448459 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 0.018       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 204        |\n",
      "|    ep_rew_mean          | 0.453      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849258 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 212        |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    value_loss           | 0.0164     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 324.80 +/- 105.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 325         |\n",
      "|    mean_reward          | 0.098       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729654 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.0249      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 0.477    |\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 112640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 0.586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007263053 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 0.617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008733772 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008444921 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008191827 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 0.0198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 0.645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506599 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 0.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737902 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00675    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 0.664       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010061242 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 0.0242      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007413777 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00787    |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.0173      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 0.635    |\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 0.627       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660727 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 0.013       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 145         |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890765 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 136          |\n",
      "|    ep_rew_mean          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1381         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070074527 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0147      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 0.0213       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009707212 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00994    |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.0259      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | 0.669       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009518158 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00454    |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | 0.724       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010742119 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.0258      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.2        |\n",
      "|    ep_rew_mean          | 0.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008646955 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00842    |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 0.0261      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.10 +/- 0.29\n",
      "Episode length: 325.40 +/- 103.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 325          |\n",
      "|    mean_reward          | 0.0965       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080566835 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.0174      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 0.0214       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.4     |\n",
      "|    ep_rew_mean     | 0.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 1373     |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 105      |\n",
      "|    total_timesteps | 145408   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 88.1       |\n",
      "|    ep_rew_mean          | 0.77       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1379       |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00765628 |\n",
      "|    clip_fraction        | 0.0884     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0177    |\n",
      "|    n_updates            | 284        |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    value_loss           | 0.0374     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.2        |\n",
      "|    ep_rew_mean          | 0.776       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780284 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00767     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.6        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663681 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00783    |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    value_loss           | 0.0315      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.882       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013481904 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.9        |\n",
      "|    ep_rew_mean          | 0.881       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010876687 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.022       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.5        |\n",
      "|    ep_rew_mean          | 0.897       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135613 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0318     |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.3        |\n",
      "|    ep_rew_mean          | 0.911       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099381 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.80 +/- 168.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011758837 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00115     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.3     |\n",
      "|    ep_rew_mean     | 0.905    |\n",
      "| time/              |          |\n",
      "|    fps             | 1380     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012846921 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0028     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 44         |\n",
      "|    ep_rew_mean          | 0.888      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1389       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287708 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.941     |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00807   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 0.0306     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36         |\n",
      "|    ep_rew_mean          | 0.909      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1392       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825456 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.919     |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.00843   |\n",
      "|    n_updates            | 324        |\n",
      "|    policy_gradient_loss | -0.00172   |\n",
      "|    value_loss           | 0.0225     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.5        |\n",
      "|    ep_rew_mean          | 0.909       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011439201 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00876     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.0184      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.924       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1401        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343361 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.9        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494961 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 0.0182      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 292.20 +/- 135.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 292        |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 176000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075115 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0157    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 0.0245     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | 0.919    |\n",
      "| time/              |          |\n",
      "|    fps             | 1385     |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 176128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.2        |\n",
      "|    ep_rew_mean          | 0.903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388014 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 344         |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | 0.917        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117297955 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.75        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | -0.00559     |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 0.0393       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 35.7       |\n",
      "|    ep_rew_mean          | 0.91       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1396       |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711984 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.819     |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.0196    |\n",
      "|    n_updates            | 352        |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    value_loss           | 0.013      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | 0.908        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125203915 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.000254     |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 0.0286       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.4       |\n",
      "|    ep_rew_mean          | 0.929      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1400       |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035146 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.747     |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.011     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00645   |\n",
      "|    value_loss           | 0.0173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.3        |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597158 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 0.00873     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1405        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008591977 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    value_loss           | 0.00818     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.90 +/- 168.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.575        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134988995 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0007       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 0.00493      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.9     |\n",
      "|    ep_rew_mean     | 0.948    |\n",
      "| time/              |          |\n",
      "|    fps             | 1397     |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 192512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | 0.949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736785 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782128 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0135     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.00227     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.7        |\n",
      "|    ep_rew_mean          | 0.951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1406        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011887598 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.00189     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.1        |\n",
      "|    ep_rew_mean          | 0.952       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497131 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00427    |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.00661     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.5        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1411        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014433542 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00507    |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279782 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.0026      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.7        |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1415        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017481608 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    value_loss           | 0.00291     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 47.30 +/- 104.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.3        |\n",
      "|    mean_reward          | 0.872       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343712 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | 0.000173    |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | 0.941    |\n",
      "| time/              |          |\n",
      "|    fps             | 1413     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1416        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034888618 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    value_loss           | 0.00968     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 23.7       |\n",
      "|    ep_rew_mean          | 0.939      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1418       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 150        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667555 |\n",
      "|    clip_fraction        | 0.0983     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.396     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0007     |\n",
      "|    loss                 | -0.000579  |\n",
      "|    n_updates            | 412        |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    value_loss           | 0.00822    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.4        |\n",
      "|    ep_rew_mean          | 0.957       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1420        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814387 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | 0.000265    |\n",
      "|    value_loss           | 0.00525     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.9        |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1423        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014388864 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.3        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1426        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015875302 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 0.00267     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.2        |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011128774 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.00659    |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16          |\n",
      "|    ep_rew_mean          | 0.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010601694 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 432         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.00373     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 14.60 +/- 3.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 14.6        |\n",
      "|    mean_reward          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361956 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0007      |\n",
      "|    loss                 | 0.00797     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.96  is above the threshold 0.92\n",
      "Final time_steps: 224000\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 1\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.9431000000000002 +/- 0.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters (Adam test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGrid-DoorKey-6x6-v0_PPO_Adam\n"
     ]
    }
   ],
   "source": [
    "#learning_rate = 0.0007 # for RMSProp\n",
    "learning_rate = 2.5e-4 # for Adam\n",
    "n_steps = 128\n",
    "batch_size = 256\n",
    "ent_coef = 0.01\n",
    "n_epochs = 4\n",
    "gae_lambda = 0.95\n",
    "#target_kl = 0.02\n",
    "target_kl = None\n",
    "#policy_kwargs = dict(activation_fn=torch.nn.ReLU,net_arch=nn_layers)\n",
    "\n",
    "experiment = \"_\".join([env_id, \"PPO\", \"Adam\"])\n",
    "print(experiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and define the Tensorboard log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "tensorboard_log = \"./tmp/log/\"\n",
    "os.makedirs(tensorboard_log, exist_ok=True)\n",
    "# Reset the environment\n",
    "vec_env.reset()\n",
    "\n",
    "# create the model\n",
    "model = PPO('MlpPolicy', env=vec_env, learning_rate=learning_rate, batch_size=batch_size, ent_coef=ent_coef, n_epochs=n_epochs, n_steps=n_steps, tensorboard_log=tensorboard_log,  policy_kwargs={'optimizer_class':torch.optim.Adam}, gae_lambda=gae_lambda, target_kl=target_kl, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback for the model evaluation while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create eval environment\n",
    "env = monitor_eval_env(env_id)\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "#For evaluating the performance of the agent periodically and logging the results.\n",
    "#callback = EvalCallback(env, log_path = log_dir, deterministic=True)\n",
    "# Stop training when the model reaches the reward threshold\n",
    "eval_env = env\n",
    "\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=0.92, verbose=1)\n",
    "#stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "#eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, callback_on_new_best=callback_on_best, eval_freq=1000, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, log_path=log_dir, n_eval_episodes=10, eval_freq=1000, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./tmp/log/MiniGrid-DoorKey-6x6-v0_PPO_Adam_1\n",
      "Eval num_timesteps=16000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009163605 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 0.000416     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | 0.00391      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1511         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318327 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.847       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0359      |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 0.000398     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005185322 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 8.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 0.0113       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014565822 |\n",
      "|    clip_fraction        | 0.000122     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.327       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 76           |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 0.000839     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009096736 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1533        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351728 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 8.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905658 |\n",
      "|    clip_fraction        | 0.00916     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -0.0237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 0.000456    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033713062 |\n",
      "|    clip_fraction        | 0.00134      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -1.44        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0373      |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 4.64e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 1425     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059436574 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -0.343       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.79e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 348          |\n",
      "|    ep_rew_mean          | 0.0401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065736375 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -2.63        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 196          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 0.000366     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003853437 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 0.0855      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005402373 |\n",
      "|    clip_fraction        | 0.00879     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057163346 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 248          |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 223         |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1475        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006403262 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.0111      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163347 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0224      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    value_loss           | 0.0115       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 360.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005009041 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 85.4         |\n",
      "|    ep_rew_mean          | 0.783        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051049516 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 316          |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 0.0118       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=0.19 +/- 0.39\n",
      "Episode length: 290.20 +/- 139.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 290          |\n",
      "|    mean_reward          | 0.195        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037892307 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 0.0103       |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.8         |\n",
      "|    ep_rew_mean          | 0.872        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1471         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058894404 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 0.00802      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 222.70 +/- 168.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 223         |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581107 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.92         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045598135 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0181      |\n",
      "|    n_updates            | 396          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 0.00502      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=208000, episode_reward=0.58 +/- 0.47\n",
      "Episode length: 153.80 +/- 168.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 154          |\n",
      "|    mean_reward          | 0.576        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026045418 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 404          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.77 +/- 0.38\n",
      "Episode length: 84.80 +/- 137.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 84.8        |\n",
      "|    mean_reward          | 0.768       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044501 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.000693    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | 0.951    |\n",
      "| time/              |          |\n",
      "|    fps             | 1518     |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 148      |\n",
      "|    total_timesteps | 225280   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.95 +/- 0.01\n",
      "Episode length: 18.20 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 18.2         |\n",
      "|    mean_reward          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360986 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.227       |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00171     |\n",
      "|    n_updates            | 468          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.8         |\n",
      "|    ep_rew_mean          | 0.955        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015850707 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0105      |\n",
      "|    n_updates            | 476          |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 0.000545     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.70 +/- 2.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 17.7        |\n",
      "|    mean_reward          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001480293 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.1         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017767319 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00837     |\n",
      "|    n_updates            | 516          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 0.000439     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=272000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.30 +/- 4.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.3         |\n",
      "|    mean_reward          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011759921 |\n",
      "|    clip_fraction        | 0.00647      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00445     |\n",
      "|    n_updates            | 528          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.000333     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002253478 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 17.50 +/- 3.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 17.5         |\n",
      "|    mean_reward          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018115845 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00447     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 0.000256     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=304000, episode_reward=0.96 +/- 0.01\n",
      "Episode length: 15.80 +/- 4.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 15.8         |\n",
      "|    mean_reward          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 304000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031136516 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0984      |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00181     |\n",
      "|    n_updates            | 592          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 0.00032      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.3        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850601 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0942     |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.000274    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.70 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.7         |\n",
      "|    mean_reward          | 0.966        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032337075 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00715     |\n",
      "|    n_updates            | 624          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 17.8       |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1617       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252318 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.171     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0167    |\n",
      "|    n_updates            | 636        |\n",
      "|    policy_gradient_loss | 0.0043     |\n",
      "|    value_loss           | 0.000885   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=336000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.30 +/- 2.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.3        |\n",
      "|    mean_reward          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 336000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951071 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00663    |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.2         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1638         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010997921 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0889      |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00766     |\n",
      "|    n_updates            | 676          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.000206     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=352000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.10 +/- 3.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.1         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035515958 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.13        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00552     |\n",
      "|    n_updates            | 684          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=368000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 2.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652107 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0712      |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00548     |\n",
      "|    n_updates            | 716          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 0.000174     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.6     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 1655     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=384000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.90 +/- 3.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.9         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 384000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025971462 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0586      |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00444      |\n",
      "|    n_updates            | 748          |\n",
      "|    policy_gradient_loss | 0.00379      |\n",
      "|    value_loss           | 0.000147     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 14.3         |\n",
      "|    ep_rew_mean          | 0.964        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0612      |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 756          |\n",
      "|    policy_gradient_loss | 0.000311     |\n",
      "|    value_loss           | 0.000155     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.96 +/- 0.00\n",
      "Episode length: 14.10 +/- 1.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 14.1         |\n",
      "|    mean_reward          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022809508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0655      |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00753     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1687        |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018788 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00963    |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 0.000139    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=416000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 13.20 +/- 1.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13.2        |\n",
      "|    mean_reward          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 416000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008668287 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.046      |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 812         |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.2         |\n",
      "|    ep_rew_mean          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1701         |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787798 |\n",
      "|    clip_fraction        | 0.00671      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0015      |\n",
      "|    n_updates            | 836          |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=432000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.30 +/- 2.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 13.3         |\n",
      "|    mean_reward          | 0.967        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 432000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017914244 |\n",
      "|    clip_fraction        | 0.00696      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00601     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=448000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 13.00 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 13          |\n",
      "|    mean_reward          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641758 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0809     |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 872         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13.9         |\n",
      "|    ep_rew_mean          | 0.965        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1702         |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038081002 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0649      |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 876          |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 0.000284     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=464000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 11.70 +/- 2.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 11.7        |\n",
      "|    mean_reward          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 464000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005944987 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 904         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 0.000124    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.6        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007470194 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0457     |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 916         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.87 +/- 0.29\n",
      "Episode length: 49.10 +/- 103.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 49.1         |\n",
      "|    mean_reward          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037453393 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0396      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0074      |\n",
      "|    n_updates            | 936          |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 0.000107     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746727 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00399    |\n",
      "|    n_updates            | 956         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=496000, episode_reward=0.97 +/- 0.01\n",
      "Episode length: 12.60 +/- 2.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.6       |\n",
      "|    mean_reward          | 0.968      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 496000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03600844 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0829    |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0449    |\n",
      "|    n_updates            | 968        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.000397   |\n",
      "----------------------------------------\n",
      "Final time_steps: 501760\n"
     ]
    }
   ],
   "source": [
    "total_timesteps = 500000\n",
    "log_interval = 10\n",
    "#tb_log_name = env_id\n",
    "tb_log_name = experiment\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps,\n",
    "            log_interval=log_interval,\n",
    "            tb_log_name = tb_log_name,\n",
    "            callback=eval_callback)\n",
    "# The performance of the training will be printed every 10 episodes. Change it to 1, if you wish to\n",
    "# view the performance at every training episode.\n",
    "print('Final time_steps:', model.num_timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate teh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.96745 +/- 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We create a separate environment for evaluation\n",
    "eval_env = monitor_eval_env(env_id, seed=3)\n",
    "\n",
    "eval_env.reset()\n",
    "before_img = eval_env.render('rgb_array')\n",
    "plt.figure(figsize=(4., 4.))\n",
    "plt.imshow(before_img);\n",
    "\n",
    "# Evaluate the trained model over 100 episodes\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
