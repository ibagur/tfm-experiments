{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Initial Meta-RIMs learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some function helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env\n",
    "\n",
    "# def sample_tasks(env_id, procs=16, n_tasks=20, seed=None):\n",
    "#     tasks = []\n",
    "#     for i in range(n_tasks):\n",
    "#         tasks.append(make_envs(env_id, procs, seed))\n",
    "#         if seed: seed+=1\n",
    "#     return tasks\n",
    "\n",
    "# def sample_tasks(env_id, n_tasks, procs):\n",
    "#     seed_list = []\n",
    "#     for i in range(n_tasks):\n",
    "#         random_data = os.urandom(4)\n",
    "#         seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "#         seed_list.append(seed)\n",
    "#     tasks = {'env_id':env_id, 'seed_list':seed_list, 'procs':procs}\n",
    "#     return tasks\n",
    "\n",
    "# def sample_tasks(n_tasks):\n",
    "#     seed_list = []\n",
    "#     for i in range(n_tasks):\n",
    "#         random_data = os.urandom(4)\n",
    "#         seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "#         seed_list.append(seed)\n",
    "#     tasks = {'seed_list':seed_list}\n",
    "#     return tasks\n",
    "\n",
    "def sample_tasks(n_tasks):\n",
    "    tasks_list = []\n",
    "    for i in range(n_tasks):\n",
    "        random_data = os.urandom(4)\n",
    "        seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "        tasks_list.append(seed)\n",
    "    return tasks_list\n",
    "\n",
    "def env_snapshot(env:ParallelEnv):\n",
    "    im_list = []\n",
    "    for e in env.envs:\n",
    "        #print(type(e.render('rgb_array')))\n",
    "        #e.reset()\n",
    "        im_list.append(e.render('rgb_array'))\n",
    "\n",
    "    fig = plt.figure(figsize=(8., 8.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                    nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                    axes_pad=0.1,  # pad between axes in inch.\n",
    "                    )\n",
    "\n",
    "    for ax, im in zip(grid, im_list):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im)\n",
    "\n",
    "def set_freeze_status(model, params, freeze=True):\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(ext in name for ext in params):\n",
    "            param.requires_grad = False if freeze else True\n",
    "            #param.grad = None if freeze else param.grad\n",
    "\n",
    "# Function to concatenate two tasks rollout exps dictionaries\n",
    "def cat_exps(exps_1, exps_2):\n",
    "    exp_out = {}\n",
    "    for (k,v), (k2,v2) in zip(exps_1.items(), exps_2.items()):\n",
    "        if k == 'obs':\n",
    "            obs = k\n",
    "            exp_out[obs] = {}\n",
    "            for (k,v), (k2,v2) in zip(exps_1.obs.items(), exps_2.obs.items()):\n",
    "                exp_out[obs][k] = torch.cat((v, v2), 0)\n",
    "        else:\n",
    "            exp_out[k] = torch.cat((v, v2), 0)\n",
    "    return exp_out\n",
    "\n",
    "# Function to concatenate two tasks rollout logs dictionaries\n",
    "def cat_logs(logs_1, logs_2):\n",
    "    logs_out = {}\n",
    "    for (k,v), (k2,v2) in zip(logs_1.items(), logs_2.items()):\n",
    "        logs_out[k] = v + v2\n",
    "    return logs_out\n",
    "\n",
    "def change_multienv_seed(env, seed):\n",
    "    for i, e in enumerate(env.envs):\n",
    "        e.seed(seed + 10000 * i)\n",
    "        e.reset()\n",
    "    return env\n",
    "        \n",
    "# Function to sample and collect tasks experiences from each tasks\n",
    "# def sample_tasks_experiences(agent, tasks_batch):\n",
    "#     exps_batch = []\n",
    "#     logs1_batch = []\n",
    "\n",
    "#     for task in tasks_batch:\n",
    "#         agent.env = task\n",
    "#         exps, logs1 = agent.collect_experiences() \n",
    "#         exps_batch.append(exps)\n",
    "#         logs1_batch.append(logs1)\n",
    "#         #agent.env.close()\n",
    "#     return exps_batch, logs1_batch\n",
    "\n",
    "\n",
    "def sample_tasks_experiences(agent, tasks):\n",
    "    seed_list = tasks['seed_list']\n",
    "    exps_batch = []\n",
    "    logs1_batch = []\n",
    "    for seed in seed_list:\n",
    "        agent.env = change_multienv_seed(agent.env, seed)\n",
    "        #agent.env = make_envs(env_id, procs, seed)\n",
    "        exps, logs1 = agent.collect_experiences() \n",
    "        exps_batch.append(exps)\n",
    "        logs1_batch.append(logs1)\n",
    "    return exps_batch, logs1_batch\n",
    "\n",
    "# Function to collect and concatenate all tasks rollout exps dictionaries\n",
    "def collect_tasks_meta_experiences(agent, tasks):\n",
    "    seed_list = tasks['seed_list']\n",
    "    for i, seed in enumerate(seed_list):\n",
    "        #agent.env = make_envs(env_id, procs, seed)\n",
    "        agent.env = change_multienv_seed(agent.env, seed)\n",
    "        exps, logs1 = agent.collect_experiences()\n",
    "        concat_exps = exps if i==0 else cat_exps(concat_exps, exps)\n",
    "        concat_exps = DictList(concat_exps)\n",
    "        concat_exps.obs = DictList(concat_exps.obs)\n",
    "        concat_logs1 = logs1 if i==0 else cat_logs(concat_logs1, logs1)\n",
    "    return concat_exps, concat_logs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "\n",
    "seed = 5\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "env_snapshot(env)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "\n",
    "# # stochastic task sampling (for training)\n",
    "# test_tasks_sto_1 = sample_tasks(env_id = 'MiniGrid-Empty-Random-6x6-v0', n_tasks=2)\n",
    "# test_tasks_sto_2 = sample_tasks(env_id = 'MiniGrid-Empty-Random-6x6-v0', n_tasks=2)\n",
    "\n",
    "# # deterministic task sampling (for testing)\n",
    "# test_tasks_det_1 = sample_tasks(env_id = 'MiniGrid-Empty-Random-6x6-v0', n_tasks=2, seed=1)\n",
    "# test_tasks_det_2 = sample_tasks(env_id = 'MiniGrid-Empty-Random-6x6-v0', n_tasks=2, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps, logs1 = algo.collect_experiences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(exps))\n",
    "print(type(logs1))\n",
    "for k,v in exps.items():\n",
    "    if k == 'obs':\n",
    "        for k1,v1 in exps.obs.items():\n",
    "            print(k1, type(v1))\n",
    "    print(k, type(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-learn parameters\n",
    "lr_alpha = 0.0001 # inner loop lr\n",
    "lr_beta = 0.0001 # outer loop lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete param_groups after it has been created\n",
    "for i in range(len(algo.optimizer.param_groups)):\n",
    "    del algo.optimizer.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign param_groups\n",
    "\n",
    "# inner loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.image_conv.parameters(), \n",
    "    *acmodel.memory_rnn.rnn.parameters(), \n",
    "    *acmodel.actor.parameters()], 'lr': lr_alpha})\n",
    "\n",
    "# outer loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.critic.parameters(), \n",
    "    *acmodel.memory_rnn.key.parameters(),\n",
    "    *acmodel.memory_rnn.key_.parameters(),\n",
    "    *acmodel.memory_rnn.query.parameters(),\n",
    "    *acmodel.memory_rnn.query_.parameters(),\n",
    "    *acmodel.memory_rnn.value.parameters(),\n",
    "    *acmodel.memory_rnn.value_.parameters(),\n",
    "    *acmodel.memory_rnn.comm_attention_output.parameters()\n",
    "    ], 'lr': lr_beta})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in acmodel.named_parameters():\n",
    "    print(name, param.requires_grad, param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing input attention layers in inner loop\n",
    "acmodel.memory_rnn.query.w.requires_grad = False\n",
    "acmodel.memory_rnn.query.w.grad = None\n",
    "acmodel.memory_rnn.key.weight.requires_grad = False\n",
    "acmodel.memory_rnn.key.weight.grad = None\n",
    "acmodel.memory_rnn.key.bias.requires_grad = False\n",
    "acmodel.memory_rnn.key.bias.grad = None\n",
    "acmodel.memory_rnn.value.weight.requires_grad = False\n",
    "acmodel.memory_rnn.value.weight.grad = None\n",
    "acmodel.memory_rnn.value.bias.requires_grad = False\n",
    "acmodel.memory_rnn.value.bias.grad = None\n",
    "\n",
    "# Freezing comm attention layers in inner loop\n",
    "acmodel.memory_rnn.query_.w.requires_grad = False\n",
    "acmodel.memory_rnn.query_.w.grad = None\n",
    "acmodel.memory_rnn.key_.w.requires_grad = False\n",
    "acmodel.memory_rnn.key_.w.grad = None\n",
    "acmodel.memory_rnn.value_.w.requires_grad = False\n",
    "acmodel.memory_rnn.value_.w.grad = None\n",
    "acmodel.memory_rnn.comm_attention_output.w.requires_grad = False\n",
    "acmodel.memory_rnn.comm_attention_output.w.grad = None\n",
    "\n",
    "# Freezing critic (value head) layers in inner loop\n",
    "acmodel.critic[0].weight.requires_grad = False\n",
    "acmodel.critic[0].weight.grad = None\n",
    "acmodel.critic[0].bias.requires_grad = False\n",
    "acmodel.critic[0].bias.grad = None\n",
    "acmodel.critic[2].weight.requires_grad = False\n",
    "acmodel.critic[2].weight.grad = None\n",
    "acmodel.critic[2].bias.requires_grad = False\n",
    "acmodel.critic[2].bias.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_params = ['query', 'key', 'value', 'comm', 'critic']\n",
    "outer_params = ['image_conv', 'i2h', 'h2h', 'actor']\n",
    "\n",
    "for name, param in acmodel.named_parameters():\n",
    "    if any(ext in name for ext in inner_params):\n",
    "        print(name, param.requires_grad)\n",
    "    #if param.requires_grad:\n",
    "        #print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_params(acmodel, inner_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in acmodel.named_parameters():\n",
    "    print(name, param.requires_grad, param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_params(acmodel, inner_params, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in acmodel.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_batch = sample_tasks(env_id=args.env, procs=args.procs, n_tasks=5)\n",
    "print(type(tasks_batch[0]))\n",
    "print(type(algo.env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_snapshot(task_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_snapshot(algo.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "# meta-learn parameters\n",
    "lr_alpha = 0.0001 # inner loop lr\n",
    "lr_beta = 0.0001 # outer loop lr\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "print(num_frames)\n",
    "print(update)\n",
    "print(start_time)\n",
    "print(args.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(meta_logs))\n",
    "print(meta_logs[\"num_frames\"])\n",
    "print(meta_exps.obs.image.size())\n",
    "print(type(meta_logs2))\n",
    "print(type(logs2))\n",
    "print(type(meta_logs1))\n",
    "print(type(logs1_batch[0]))\n",
    "\n",
    "print(meta_logs2)\n",
    "print(logs2)\n",
    "print(len(meta_logs1['return_per_episode']))\n",
    "print(len(logs1_batch[0]['return_per_episode']))\n",
    "print(meta_logs2)\n",
    "print(logs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_MiniGrid-LavaGapS5-v0_test'\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':16,\n",
    "'frames':500000, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':True # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 5\n",
    "    args.k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_MiniGrid-LavaGapS5-v0_test', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 500000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "def reshape_reward(obs, action, reward, done):\n",
    "    if not done:\n",
    "        reward = -1\n",
    "    else:\n",
    "        reward = 1\n",
    "    return reward\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (memory_rnn): RIMCell(\n",
      "    (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (rnn): GroupLSTMCell(\n",
      "      (i2h): GroupLinearLayer()\n",
      "      (h2h): GroupLinearLayer()\n",
      "    )\n",
      "    (query): GroupLinearLayer()\n",
      "    (query_): GroupLinearLayer()\n",
      "    (key_): GroupLinearLayer()\n",
      "    (value_): GroupLinearLayer()\n",
      "    (comm_attention_output): GroupLinearLayer()\n",
      "    (comm_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (input_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text, args.use_rim, args.num_units, args.k)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-learn parameters\n",
    "#lr_alpha = 0.0001 # inner loop lr - Adam\n",
    "#lr_beta = 0.0001 # outer loop lr - Adam\n",
    "lr_alpha = 0.0007 # RMSProp\n",
    "lr_beta = 0.0007 # RMSProp\n",
    "inner_recurrence = 16\n",
    "outer_recurrence = 64 # 4x inner_recurrence\n",
    "num_tasks = 2\n",
    "\n",
    "inner_params = ['image_conv', 'i2h', 'h2h', 'actor'] # params to be updated in inner loop\n",
    "outer_params = ['query', 'key', 'value', 'comm', 'critic'] # params to be updated in outer loop\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# delete param_groups after it has been created\n",
    "for i in range(len(algo.optimizer.param_groups)):\n",
    "    del algo.optimizer.param_groups[0]\n",
    "\n",
    "# Re-create separate param_groups for different inner and outer loop optimizer lr\n",
    "\n",
    "# inner loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.image_conv.parameters(), \n",
    "    *acmodel.memory_rnn.rnn.parameters(), \n",
    "    *acmodel.actor.parameters()], 'lr': lr_alpha})\n",
    "\n",
    "# outer loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.critic.parameters(), \n",
    "    *acmodel.memory_rnn.key.parameters(),\n",
    "    *acmodel.memory_rnn.key_.parameters(),\n",
    "    *acmodel.memory_rnn.query.parameters(),\n",
    "    *acmodel.memory_rnn.query_.parameters(),\n",
    "    *acmodel.memory_rnn.value.parameters(),\n",
    "    *acmodel.memory_rnn.value_.parameters(),\n",
    "    *acmodel.memory_rnn.comm_attention_output.parameters()\n",
    "    ], 'lr': lr_beta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "exps, _ = algo.collect_experiences()\n",
    "algo.update_parameters(exps)\n",
    "\n",
    "while num_frames < args.frames: # STEP 2\n",
    "\n",
    "    update_start_time = time.time()\n",
    "\n",
    "    # # run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "    # exps, _ = algo.collect_experiences()\n",
    "    # algo.update_parameters(exps)\n",
    "\n",
    "    # Sample batch of tasks: STEP 3\n",
    "    tasks_batch = sample_tasks(n_tasks=num_tasks)\n",
    "\n",
    "    # Sample pre-trajectories from each task: STEP 4\n",
    "    exps_batch, logs1_batch = sample_tasks_experiences(agent=algo, tasks=tasks_batch)\n",
    "\n",
    "    # Inner loop: STEPS 5-7\n",
    "\n",
    "    # Unfreeze inner loop params so they can get updated in the inner loop\n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=False)\n",
    "\n",
    "    # Freeze outer loop parameters, so those grads will be zero in update\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=True)\n",
    "\n",
    "    # set inner recurence\n",
    "    algo.recurrence = inner_recurrence\n",
    "\n",
    "    # Update parameters for all tasks \n",
    "    logs2_batch = []\n",
    "    for exps in exps_batch: # STEP 5\n",
    "        logs2 = algo.update_parameters(exps) # STEP 6\n",
    "        logs2_batch.append(logs2)\n",
    "    # STEP 7\n",
    "\n",
    "    # Sample post-trajectories t_i from tasks T_i and concatenate to get D_meta: STEP 8\n",
    "    meta_exps, meta_logs1 = collect_tasks_meta_experiences(agent=algo, tasks=tasks_batch)\n",
    "\n",
    "    # Unfreeze outer loop params so they can get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=False)\n",
    "    # Freeze inner loop params \n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=True)\n",
    "\n",
    "    # set outer recurence\n",
    "    algo.recurrence = outer_recurrence\n",
    "\n",
    "    # Update parameters while keeping inner parametes (module and policy) frozen: STEP 9\n",
    "    meta_logs2 = algo.update_parameters(meta_exps)\n",
    "\n",
    "    meta_logs = {**meta_logs1, **meta_logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += meta_logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = meta_logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(meta_logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(meta_logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(meta_logs[\"num_frames_per_episode\"])\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [meta_logs[\"entropy\"], meta_logs[\"value\"], meta_logs[\"policy_loss\"], meta_logs[\"value_loss\"], meta_logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "# STEP 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "exps, _ = algo.collect_experiences()\n",
    "algo.update_parameters(exps)\n",
    "\n",
    "while num_frames < args.frames: # STEP 2\n",
    "\n",
    "    update_start_time = time.time()\n",
    "\n",
    "    # Sample batch of tasks: STEP 3\n",
    "    tasks_batch = sample_tasks(n_tasks=num_tasks)\n",
    "\n",
    "    for i, task in enumerate(tasks_batch):\n",
    "\n",
    "        algo.env = change_multienv_seed(algo.env, seed=task)\n",
    "        #algo.env = make_envs(args.env, args.procs, seed=task)\n",
    "        # Sample pre-trajectories from each task: STEP 4\n",
    "        pre_exps, pre_logs1 = algo.collect_experiences()\n",
    "         # Unfreeze inner loop params so they can get updated in the inner loop\n",
    "        set_freeze_status(algo.acmodel, inner_params, freeze=False)\n",
    "        # Freeze outer loop parameters, so those grads will be zero in update\n",
    "        set_freeze_status(algo.acmodel, outer_params, freeze=True)\n",
    "        # set inner recurence\n",
    "        algo.recurrence = inner_recurrence\n",
    "        # Update parameters: STEP 6\n",
    "        algo.update_parameters(pre_exps)\n",
    "        # Sample post-trajectories t_i from tasks T_i: STEP 7\n",
    "        post_exps, post_logs1 = algo.collect_experiences()\n",
    "        # Concatenate to get D_meta: STEP 8\n",
    "        meta_exps = post_exps if i==0 else cat_exps(meta_exps, post_exps)\n",
    "        meta_exps = DictList(meta_exps)\n",
    "        meta_exps.obs = DictList(meta_exps.obs)\n",
    "        meta_logs1 = post_logs1 if i==0 else cat_logs(meta_logs1, post_logs1)\n",
    "\n",
    "    # Unfreeze outer loop params so they can get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=False)\n",
    "    # Freeze inner loop params \n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=True)   \n",
    "    \n",
    "    # set outer recurence\n",
    "    algo.recurrence = outer_recurrence\n",
    "\n",
    "    # Update parameters while keeping inner parametes (module and policy) frozen: STEP 9\n",
    "    meta_logs2 = algo.update_parameters(meta_exps)\n",
    "\n",
    "    meta_logs = {**meta_logs1, **meta_logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += meta_logs[\"num_frames\"]\n",
    "    update += 1    \n",
    "    \n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = meta_logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(meta_logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(meta_logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(meta_logs[\"num_frames_per_episode\"])\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [meta_logs[\"entropy\"], meta_logs[\"value\"], meta_logs[\"policy_loss\"], meta_logs[\"value_loss\"], meta_logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "# STEP 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "args.env = env_id\n",
    "model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':model,\n",
    "#'model':'MiniGrid-Empty-Random-6x6-v0_meta_RIM_4_2_200k_test_2',\n",
    "'episodes':100,\n",
    "'seed':2,\n",
    "'procs':16,\n",
    "'argmax':False,\n",
    "'worst_episodes_to_show':10,\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "#'num_units':4,\n",
    "#'k':2\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, args.procs, args.use_rim, args.num_units, args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim, num_units = args.num_units, k = args.k)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meta-RIMs Zero-shot test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':env_id,\n",
    "'model':args.model,\n",
    "'episodes':100,\n",
    "'seed':10,\n",
    "'procs':16,\n",
    "'argmax':False,\n",
    "'worst_episodes_to_show':10,\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set agent and test environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, args.procs, args.use_rim, args.num_units, args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue meta-RIMs learning on 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "\n",
    "add_frames = 500000\n",
    "total_frames = args.frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':16,\n",
    "'frames':total_frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':True # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 5\n",
    "    args.k = 3\n",
    "\n",
    "# meta-learn parameters\n",
    "#lr_alpha = 0.0001 # inner loop lr - Adam\n",
    "#lr_beta = 0.0001 # outer loop lr - Adam\n",
    "lr_alpha = 0.0007 # RMSProp\n",
    "lr_beta = 0.0007 # RMSProp\n",
    "inner_recurrence = 16\n",
    "outer_recurrence = 64 # 4x inner_recurrence\n",
    "num_tasks = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text, args.use_rim, args.num_units, args.k)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "exps, _ = algo.collect_experiences()\n",
    "algo.update_parameters(exps)\n",
    "\n",
    "while num_frames < args.frames: # STEP 2\n",
    "\n",
    "    update_start_time = time.time()\n",
    "\n",
    "    # # run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "    # exps, _ = algo.collect_experiences()\n",
    "    # algo.update_parameters(exps)\n",
    "\n",
    "    # Sample batch of tasks: STEP 3\n",
    "    tasks_batch = sample_tasks(n_tasks=num_tasks)\n",
    "\n",
    "    for i, task in enumerate(tasks_batch):\n",
    "\n",
    "        algo.env = change_multienv_seed(algo.env, seed=task)\n",
    "        #algo.env = make_envs(args.env, args.procs, seed=task)\n",
    "        # Sample pre-trajectories from each task: STEP 4\n",
    "        pre_exps, pre_logs1 = algo.collect_experiences()\n",
    "         # Unfreeze inner loop params so they can get updated in the inner loop\n",
    "        set_freeze_status(algo.acmodel, inner_params, freeze=False)\n",
    "        # Freeze outer loop parameters, so those grads will be zero in update\n",
    "        set_freeze_status(algo.acmodel, outer_params, freeze=True)\n",
    "        # set inner recurence\n",
    "        algo.recurrence = inner_recurrence\n",
    "        # Update parameters: STEP 6\n",
    "        algo.update_parameters(pre_exps)\n",
    "        # Sample post-trajectories t_i from tasks T_i: STEP 7\n",
    "        post_exps, post_logs1 = algo.collect_experiences()\n",
    "        # Concatenate to get D_meta: STEP 8\n",
    "        meta_exps = post_exps if i==0 else cat_exps(meta_exps, post_exps)\n",
    "        meta_exps = DictList(meta_exps)\n",
    "        meta_exps.obs = DictList(meta_exps.obs)\n",
    "        meta_logs1 = post_logs1 if i==0 else cat_logs(meta_logs1, post_logs1)\n",
    "\n",
    "    # Unfreeze outer loop params so they can get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=False)\n",
    "    # Freeze inner loop params \n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=True)   \n",
    "    \n",
    "    # set outer recurence\n",
    "    algo.recurrence = outer_recurrence\n",
    "\n",
    "    # Update parameters while keeping inner parametes (module and policy) frozen: STEP 9\n",
    "    meta_logs2 = algo.update_parameters(meta_exps)\n",
    "\n",
    "    meta_logs = {**meta_logs1, **meta_logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += meta_logs[\"num_frames\"]\n",
    "    update += 1    \n",
    "    \n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = meta_logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(meta_logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(meta_logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(meta_logs[\"num_frames_per_episode\"])\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [meta_logs[\"entropy\"], meta_logs[\"value\"], meta_logs[\"policy_loss\"], meta_logs[\"value_loss\"], meta_logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "# STEP 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "args.env = env_id\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':model,\n",
    "'episodes':100,\n",
    "'seed':2,\n",
    "'procs':16,\n",
    "'argmax':False,\n",
    "'worst_episodes_to_show':10,\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, args.procs, args.use_rim, args.num_units, args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st enviroment and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "args.env = env_id\n",
    "\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':model,\n",
    "'episodes':100,\n",
    "'seed':2,\n",
    "'procs':16,\n",
    "'argmax':False,\n",
    "'worst_episodes_to_show':10,\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, args.procs, args.use_rim, args.num_units, args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-rims",
   "language": "python",
   "name": "tfm-rims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
