{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Initial Meta-RIMs learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env\n",
    "\n",
    "def sample_tasks(n_tasks):\n",
    "    tasks_list = []\n",
    "    for i in range(n_tasks):\n",
    "        random_data = os.urandom(4)\n",
    "        seed = int.from_bytes(random_data, byteorder=\"big\")\n",
    "        tasks_list.append(seed)\n",
    "    return tasks_list\n",
    "\n",
    "def env_snapshot(env:ParallelEnv):\n",
    "    im_list = []\n",
    "    for e in env.envs:\n",
    "        #print(type(e.render('rgb_array')))\n",
    "        #e.reset()\n",
    "        im_list.append(e.render('rgb_array'))\n",
    "\n",
    "    fig = plt.figure(figsize=(8., 8.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                    nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                    axes_pad=0.1,  # pad between axes in inch.\n",
    "                    )\n",
    "\n",
    "    for ax, im in zip(grid, im_list):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im)\n",
    "\n",
    "def set_freeze_status(model, params, freeze=True):\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(ext in name for ext in params):\n",
    "            param.requires_grad = False if freeze else True\n",
    "            #param.grad = None if freeze else param.grad\n",
    "\n",
    "# Function to concatenate two tasks rollout exps dictionaries\n",
    "def cat_exps(exps_1, exps_2):\n",
    "    exp_out = {}\n",
    "    for (k,v), (k2,v2) in zip(exps_1.items(), exps_2.items()):\n",
    "        if k == 'obs':\n",
    "            obs = k\n",
    "            exp_out[obs] = {}\n",
    "            for (k,v), (k2,v2) in zip(exps_1.obs.items(), exps_2.obs.items()):\n",
    "                exp_out[obs][k] = torch.cat((v, v2), 0)\n",
    "        else:\n",
    "            exp_out[k] = torch.cat((v, v2), 0)\n",
    "    return exp_out\n",
    "\n",
    "# Function to concatenate two tasks rollout logs dictionaries\n",
    "def cat_logs(logs_1, logs_2):\n",
    "    logs_out = {}\n",
    "    for (k,v), (k2,v2) in zip(logs_1.items(), logs_2.items()):\n",
    "        logs_out[k] = v + v2\n",
    "    return logs_out\n",
    "\n",
    "def change_multienv_seed(env, seed):\n",
    "    for i, e in enumerate(env.envs):\n",
    "        e.seed(seed + 10000 * i)\n",
    "        e.reset()\n",
    "    return env\n",
    "        \n",
    "def sample_tasks_experiences(agent, tasks):\n",
    "    seed_list = tasks['seed_list']\n",
    "    exps_batch = []\n",
    "    logs1_batch = []\n",
    "    for seed in seed_list:\n",
    "        agent.env = change_multienv_seed(agent.env, seed)\n",
    "        #agent.env = make_envs(env_id, procs, seed)\n",
    "        exps, logs1 = agent.collect_experiences() \n",
    "        exps_batch.append(exps)\n",
    "        logs1_batch.append(logs1)\n",
    "    return exps_batch, logs1_batch\n",
    "\n",
    "# Function to collect and concatenate all tasks rollout exps dictionaries\n",
    "def collect_tasks_meta_experiences(agent, tasks):\n",
    "    seed_list = tasks['seed_list']\n",
    "    for i, seed in enumerate(seed_list):\n",
    "        #agent.env = make_envs(env_id, procs, seed)\n",
    "        agent.env = change_multienv_seed(agent.env, seed)\n",
    "        exps, logs1 = agent.collect_experiences()\n",
    "        concat_exps = exps if i==0 else cat_exps(concat_exps, exps)\n",
    "        concat_exps = DictList(concat_exps)\n",
    "        concat_exps.obs = DictList(concat_exps.obs)\n",
    "        concat_logs1 = logs1 if i==0 else cat_logs(concat_logs1, logs1)\n",
    "    return concat_exps, concat_logs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "\n",
    "seed = 5\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "env_snapshot(env)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "model = 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0'\n",
    "frames = 400000\n",
    "processes = 16\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':True # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 5\n",
    "    args.k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 400000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (memory_rnn): RIMCell(\n",
      "    (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (rnn): GroupLSTMCell(\n",
      "      (i2h): GroupLinearLayer()\n",
      "      (h2h): GroupLinearLayer()\n",
      "    )\n",
      "    (query): GroupLinearLayer()\n",
      "    (query_): GroupLinearLayer()\n",
      "    (key_): GroupLinearLayer()\n",
      "    (value_): GroupLinearLayer()\n",
      "    (comm_attention_output): GroupLinearLayer()\n",
      "    (comm_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (input_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=60, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text, args.use_rim, args.num_units, args.k)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-learn parameters\n",
    "#lr_alpha = 0.0001 # inner loop lr - Adam\n",
    "#lr_beta = 0.0001 # outer loop lr - Adam\n",
    "lr_alpha = 0.0007 # RMSProp\n",
    "lr_beta = 0.0007 # RMSProp\n",
    "inner_recurrence = 16\n",
    "outer_recurrence = 64 # 4x inner_recurrence\n",
    "num_tasks = 2\n",
    "\n",
    "inner_params = ['image_conv', 'i2h', 'h2h', 'actor'] # params to be updated in inner loop\n",
    "outer_params = ['query', 'key', 'value', 'comm', 'critic'] # params to be updated in outer loop\n",
    "\n",
    "# delete param_groups after it has been created\n",
    "for i in range(len(algo.optimizer.param_groups)):\n",
    "    del algo.optimizer.param_groups[0]\n",
    "\n",
    "# Re-create separate param_groups for different inner and outer loop optimizer lr\n",
    "\n",
    "# inner loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.image_conv.parameters(), \n",
    "    *acmodel.memory_rnn.rnn.parameters(), \n",
    "    *acmodel.actor.parameters()], 'lr': lr_alpha})\n",
    "\n",
    "# outer loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.critic.parameters(), \n",
    "    *acmodel.memory_rnn.key.parameters(),\n",
    "    *acmodel.memory_rnn.key_.parameters(),\n",
    "    *acmodel.memory_rnn.query.parameters(),\n",
    "    *acmodel.memory_rnn.query_.parameters(),\n",
    "    *acmodel.memory_rnn.value.parameters(),\n",
    "    *acmodel.memory_rnn.value_.parameters(),\n",
    "    *acmodel.memory_rnn.comm_attention_output.parameters()\n",
    "    ], 'lr': lr_beta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1 | F 004096 | FPS 0297 | D 18 | rR:μσmM 0.09 0.20 0.00 0.71 | F:μσmM 139.5 41.0 47.0 272.0 | H 1.925 | V 0.023 | pL -0.008 | vL 0.005 | ∇ 0.028\n",
      "U 2 | F 008192 | FPS 0309 | D 32 | rR:μσmM 0.14 0.28 0.00 0.98 | F:μσmM 124.9 39.1 3.0 144.0 | H 1.936 | V 0.053 | pL -0.019 | vL 0.013 | ∇ 0.053\n",
      "U 3 | F 012288 | FPS 0313 | D 45 | rR:μσmM 0.08 0.20 0.00 0.93 | F:μσmM 138.8 34.2 12.0 256.0 | H 1.938 | V 0.024 | pL 0.007 | vL 0.003 | ∇ 0.024\n",
      "U 4 | F 016384 | FPS 0287 | D 59 | rR:μσmM 0.10 0.22 0.00 0.80 | F:μσmM 133.7 32.4 32.0 208.0 | H 1.929 | V 0.031 | pL 0.015 | vL 0.001 | ∇ 0.021\n",
      "U 5 | F 020480 | FPS 0320 | D 72 | rR:μσmM 0.08 0.18 0.00 0.60 | F:μσmM 137.5 31.5 64.0 256.0 | H 1.943 | V 0.035 | pL 0.013 | vL 0.003 | ∇ 0.033\n",
      "U 6 | F 024576 | FPS 0323 | D 85 | rR:μσmM 0.18 0.27 0.00 0.77 | F:μσmM 123.1 39.0 36.0 197.0 | H 1.927 | V 0.066 | pL -0.000 | vL 0.005 | ∇ 0.040\n",
      "U 7 | F 028672 | FPS 0277 | D 99 | rR:μσmM 0.24 0.30 0.00 0.88 | F:μσmM 113.8 40.9 19.0 153.0 | H 1.915 | V 0.087 | pL -0.040 | vL 0.016 | ∇ 0.058\n",
      "U 8 | F 032768 | FPS 0261 | D 115 | rR:μσmM 0.27 0.31 0.00 0.86 | F:μσmM 108.4 42.6 23.0 144.0 | H 1.891 | V 0.167 | pL -0.014 | vL 0.022 | ∇ 0.106\n",
      "U 9 | F 036864 | FPS 0308 | D 128 | rR:μσmM 0.26 0.32 0.00 0.86 | F:μσmM 112.6 49.8 22.0 256.0 | H 1.886 | V 0.146 | pL 0.040 | vL 0.023 | ∇ 0.085\n",
      "U 10 | F 040960 | FPS 0321 | D 141 | rR:μσmM 0.28 0.33 0.00 0.96 | F:μσmM 109.3 51.7 7.0 256.0 | H 1.917 | V 0.126 | pL 0.005 | vL 0.012 | ∇ 0.042\n",
      "Status saved\n",
      "U 11 | F 045056 | FPS 0312 | D 154 | rR:μσmM 0.30 0.34 0.00 0.94 | F:μσmM 108.5 53.9 9.0 263.0 | H 1.906 | V 0.080 | pL 0.007 | vL 0.015 | ∇ 0.081\n",
      "U 12 | F 049152 | FPS 0348 | D 166 | rR:μσmM 0.39 0.34 0.00 0.96 | F:μσmM 93.0 49.2 6.0 144.0 | H 1.851 | V 0.188 | pL 0.015 | vL 0.019 | ∇ 0.055\n",
      "U 13 | F 053248 | FPS 0337 | D 178 | rR:μσmM 0.31 0.37 0.00 0.98 | F:μσmM 101.2 52.2 4.0 144.0 | H 1.874 | V 0.160 | pL 0.010 | vL 0.019 | ∇ 0.077\n",
      "U 14 | F 057344 | FPS 0339 | D 190 | rR:μσmM 0.49 0.35 0.00 0.98 | F:μσmM 77.5 49.8 4.0 144.0 | H 1.845 | V 0.215 | pL 0.030 | vL 0.019 | ∇ 0.053\n",
      "U 15 | F 061440 | FPS 0323 | D 203 | rR:μσmM 0.42 0.34 0.00 0.97 | F:μσmM 88.8 48.0 5.0 144.0 | H 1.878 | V 0.206 | pL 0.053 | vL 0.014 | ∇ 0.076\n",
      "U 16 | F 065536 | FPS 0343 | D 215 | rR:μσmM 0.44 0.35 0.00 0.94 | F:μσmM 85.1 50.4 10.0 153.0 | H 1.872 | V 0.197 | pL 0.023 | vL 0.017 | ∇ 0.076\n",
      "U 17 | F 069632 | FPS 0335 | D 227 | rR:μσmM 0.54 0.36 0.00 0.96 | F:μσmM 72.6 56.5 6.0 265.0 | H 1.859 | V 0.170 | pL 0.012 | vL 0.012 | ∇ 0.069\n",
      "U 18 | F 073728 | FPS 0339 | D 239 | rR:μσmM 0.47 0.35 0.00 0.95 | F:μσmM 83.0 55.6 8.0 256.0 | H 1.846 | V 0.261 | pL 0.029 | vL 0.015 | ∇ 0.091\n",
      "U 19 | F 077824 | FPS 0305 | D 253 | rR:μσmM 0.51 0.29 0.00 0.96 | F:μσmM 76.7 43.1 6.0 144.0 | H 1.808 | V 0.319 | pL 0.061 | vL 0.022 | ∇ 0.196\n",
      "U 20 | F 081920 | FPS 0330 | D 265 | rR:μσmM 0.58 0.32 0.00 0.98 | F:μσmM 65.4 49.6 3.0 189.0 | H 1.812 | V 0.257 | pL 0.024 | vL 0.021 | ∇ 0.189\n",
      "Status saved\n",
      "U 21 | F 086016 | FPS 0306 | D 278 | rR:μσmM 0.58 0.29 0.00 0.96 | F:μσmM 65.3 42.9 6.0 144.0 | H 1.776 | V 0.404 | pL 0.050 | vL 0.019 | ∇ 0.154\n",
      "U 22 | F 090112 | FPS 0331 | D 291 | rR:μσmM 0.65 0.27 0.00 0.96 | F:μσmM 54.4 41.3 6.0 144.0 | H 1.755 | V 0.380 | pL 0.038 | vL 0.025 | ∇ 0.156\n",
      "U 23 | F 094208 | FPS 0336 | D 303 | rR:μσmM 0.63 0.27 0.00 0.96 | F:μσmM 57.7 40.5 7.0 168.0 | H 1.735 | V 0.389 | pL 0.065 | vL 0.032 | ∇ 0.197\n",
      "U 24 | F 098304 | FPS 0306 | D 316 | rR:μσmM 0.66 0.25 0.00 0.96 | F:μσmM 53.1 37.7 6.0 144.0 | H 1.732 | V 0.454 | pL 0.021 | vL 0.031 | ∇ 0.333\n",
      "U 25 | F 102400 | FPS 0314 | D 329 | rR:μσmM 0.68 0.25 0.00 0.98 | F:μσmM 50.5 38.0 3.0 144.0 | H 1.744 | V 0.430 | pL 0.003 | vL 0.026 | ∇ 0.256\n",
      "U 26 | F 106496 | FPS 0308 | D 343 | rR:μσmM 0.61 0.26 0.00 0.94 | F:μσmM 61.1 39.2 10.0 144.0 | H 1.786 | V 0.427 | pL 0.086 | vL 0.030 | ∇ 0.355\n",
      "U 27 | F 110592 | FPS 0314 | D 356 | rR:μσmM 0.60 0.31 0.00 0.98 | F:μσmM 62.4 46.0 3.0 163.0 | H 1.788 | V 0.339 | pL 0.067 | vL 0.031 | ∇ 0.386\n",
      "U 28 | F 114688 | FPS 0297 | D 370 | rR:μσmM 0.63 0.29 0.00 0.96 | F:μσmM 58.4 47.8 7.0 247.0 | H 1.785 | V 0.348 | pL 0.055 | vL 0.030 | ∇ 0.296\n",
      "U 29 | F 118784 | FPS 0318 | D 382 | rR:μσmM 0.65 0.28 0.00 0.97 | F:μσmM 54.8 41.1 5.0 144.0 | H 1.778 | V 0.442 | pL 0.021 | vL 0.026 | ∇ 0.136\n",
      "U 30 | F 122880 | FPS 0318 | D 395 | rR:μσmM 0.70 0.26 0.00 0.99 | F:μσmM 47.4 38.9 2.0 144.0 | H 1.700 | V 0.460 | pL 0.068 | vL 0.023 | ∇ 0.113\n",
      "Status saved\n",
      "U 31 | F 126976 | FPS 0324 | D 408 | rR:μσmM 0.75 0.22 0.00 0.99 | F:μσmM 40.2 34.9 2.0 154.0 | H 1.655 | V 0.441 | pL 0.100 | vL 0.019 | ∇ 0.178\n",
      "U 32 | F 131072 | FPS 0316 | D 421 | rR:μσmM 0.75 0.18 0.00 0.96 | F:μσmM 39.3 28.7 7.0 144.0 | H 1.685 | V 0.544 | pL 0.050 | vL 0.030 | ∇ 0.471\n",
      "U 33 | F 135168 | FPS 0328 | D 433 | rR:μσmM 0.77 0.14 0.31 0.97 | F:μσmM 36.6 22.2 5.0 111.0 | H 1.677 | V 0.595 | pL -0.032 | vL 0.016 | ∇ 0.186\n",
      "U 34 | F 139264 | FPS 0311 | D 447 | rR:μσmM 0.81 0.12 0.32 0.98 | F:μσmM 29.8 18.6 4.0 108.0 | H 1.664 | V 0.600 | pL 0.042 | vL 0.020 | ∇ 0.384\n",
      "U 35 | F 143360 | FPS 0331 | D 459 | rR:μσmM 0.82 0.11 0.42 0.97 | F:μσmM 28.8 18.1 5.0 93.0 | H 1.628 | V 0.664 | pL 0.022 | vL 0.015 | ∇ 0.222\n",
      "U 36 | F 147456 | FPS 0314 | D 472 | rR:μσmM 0.85 0.09 0.48 0.98 | F:μσmM 24.4 13.9 3.0 83.0 | H 1.544 | V 0.711 | pL -0.017 | vL 0.010 | ∇ 0.120\n",
      "U 37 | F 151552 | FPS 0328 | D 485 | rR:μσmM 0.83 0.10 0.49 0.97 | F:μσmM 26.7 16.4 5.0 81.0 | H 1.589 | V 0.668 | pL 0.065 | vL 0.013 | ∇ 0.128\n",
      "U 38 | F 155648 | FPS 0320 | D 497 | rR:μσmM 0.86 0.07 0.61 0.98 | F:μσmM 22.6 11.6 4.0 62.0 | H 1.494 | V 0.741 | pL -0.008 | vL 0.008 | ∇ 0.080\n",
      "U 39 | F 159744 | FPS 0323 | D 510 | rR:μσmM 0.88 0.06 0.57 0.99 | F:μσmM 19.2 10.1 2.0 68.0 | H 1.463 | V 0.757 | pL 0.016 | vL 0.010 | ∇ 0.133\n",
      "U 40 | F 163840 | FPS 0323 | D 523 | rR:μσmM 0.89 0.05 0.69 0.98 | F:μσmM 17.7 8.2 3.0 49.0 | H 1.369 | V 0.776 | pL -0.005 | vL 0.012 | ∇ 0.258\n",
      "Status saved\n",
      "U 41 | F 167936 | FPS 0317 | D 536 | rR:μσmM 0.90 0.04 0.64 0.98 | F:μσmM 16.0 6.7 3.0 58.0 | H 1.275 | V 0.810 | pL -0.013 | vL 0.008 | ∇ 0.069\n",
      "U 42 | F 172032 | FPS 0327 | D 548 | rR:μσmM 0.90 0.05 0.76 0.98 | F:μσmM 16.7 7.3 3.0 39.0 | H 1.357 | V 0.810 | pL 0.004 | vL 0.004 | ∇ 0.044\n",
      "U 43 | F 176128 | FPS 0315 | D 561 | rR:μσmM 0.90 0.04 0.77 0.98 | F:μσmM 15.8 5.8 3.0 37.0 | H 1.353 | V 0.819 | pL -0.011 | vL 0.004 | ∇ 0.057\n",
      "U 44 | F 180224 | FPS 0316 | D 574 | rR:μσmM 0.90 0.05 0.64 0.98 | F:μσmM 15.8 7.5 3.0 57.0 | H 1.379 | V 0.810 | pL -0.001 | vL 0.006 | ∇ 0.106\n",
      "U 45 | F 184320 | FPS 0325 | D 587 | rR:μσmM 0.90 0.04 0.69 0.98 | F:μσmM 15.7 7.1 3.0 49.0 | H 1.352 | V 0.823 | pL -0.005 | vL 0.004 | ∇ 0.048\n",
      "U 46 | F 188416 | FPS 0344 | D 599 | rR:μσmM 0.90 0.05 0.64 0.98 | F:μσmM 16.7 8.2 4.0 57.0 | H 1.322 | V 0.799 | pL -0.014 | vL 0.005 | ∇ 0.071\n",
      "U 47 | F 192512 | FPS 0342 | D 611 | rR:μσmM 0.90 0.04 0.69 0.98 | F:μσmM 15.3 6.5 3.0 49.0 | H 1.357 | V 0.819 | pL -0.008 | vL 0.004 | ∇ 0.112\n",
      "U 48 | F 196608 | FPS 0342 | D 623 | rR:μσmM 0.89 0.06 0.59 0.98 | F:μσmM 18.2 8.9 3.0 65.0 | H 1.392 | V 0.792 | pL 0.032 | vL 0.006 | ∇ 0.105\n",
      "U 49 | F 200704 | FPS 0327 | D 635 | rR:μσmM 0.90 0.05 0.70 0.99 | F:μσmM 15.5 7.4 2.0 48.0 | H 1.279 | V 0.811 | pL -0.044 | vL 0.004 | ∇ 0.113\n",
      "U 50 | F 204800 | FPS 0327 | D 648 | rR:μσmM 0.90 0.05 0.56 0.98 | F:μσmM 16.1 8.4 4.0 71.0 | H 1.295 | V 0.841 | pL -0.004 | vL 0.002 | ∇ 0.043\n",
      "Status saved\n",
      "U 51 | F 208896 | FPS 0325 | D 660 | rR:μσmM 0.90 0.04 0.74 0.98 | F:μσmM 15.4 5.9 3.0 42.0 | H 1.319 | V 0.825 | pL 0.002 | vL 0.002 | ∇ 0.050\n",
      "U 52 | F 212992 | FPS 0279 | D 675 | rR:μσmM 0.90 0.05 0.71 0.98 | F:μσmM 15.8 7.2 3.0 46.0 | H 1.372 | V 0.824 | pL 0.007 | vL 0.005 | ∇ 0.156\n",
      "U 53 | F 217088 | FPS 0318 | D 688 | rR:μσmM 0.91 0.04 0.76 0.98 | F:μσmM 14.9 5.6 3.0 38.0 | H 1.299 | V 0.831 | pL -0.020 | vL 0.002 | ∇ 0.039\n",
      "U 54 | F 221184 | FPS 0308 | D 701 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 15.2 6.0 3.0 33.0 | H 1.287 | V 0.828 | pL -0.010 | vL 0.002 | ∇ 0.046\n",
      "U 55 | F 225280 | FPS 0300 | D 715 | rR:μσmM 0.91 0.04 0.68 0.98 | F:μσmM 14.5 6.2 3.0 51.0 | H 1.303 | V 0.835 | pL 0.010 | vL 0.004 | ∇ 0.041\n",
      "U 56 | F 229376 | FPS 0311 | D 728 | rR:μσmM 0.91 0.03 0.76 0.99 | F:μσmM 13.7 5.3 2.0 38.0 | H 1.256 | V 0.837 | pL -0.014 | vL 0.003 | ∇ 0.048\n",
      "U 57 | F 233472 | FPS 0304 | D 742 | rR:μσmM 0.91 0.04 0.77 0.98 | F:μσmM 14.8 6.2 3.0 36.0 | H 1.283 | V 0.836 | pL 0.008 | vL 0.002 | ∇ 0.086\n",
      "U 58 | F 237568 | FPS 0334 | D 754 | rR:μσmM 0.91 0.03 0.81 0.98 | F:μσmM 13.6 5.1 3.0 30.0 | H 1.263 | V 0.836 | pL -0.009 | vL 0.002 | ∇ 0.014\n",
      "U 59 | F 241664 | FPS 0295 | D 768 | rR:μσmM 0.91 0.04 0.75 0.99 | F:μσmM 14.0 5.8 2.0 40.0 | H 1.240 | V 0.835 | pL 0.002 | vL 0.002 | ∇ 0.037\n",
      "Number of frames:  245760\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "break_flag = False\n",
    "\n",
    "# Moving average settings for early stop\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "# run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "exps, _ = algo.collect_experiences()\n",
    "algo.update_parameters(exps)\n",
    "\n",
    "while num_frames < args.frames: # STEP 2\n",
    "\n",
    "    update_start_time = time.time()\n",
    "\n",
    "    # Sample batch of tasks: STEP 3\n",
    "    tasks_batch = sample_tasks(n_tasks=num_tasks)\n",
    "\n",
    "    for n, task in enumerate(tasks_batch):\n",
    "\n",
    "        algo.env = change_multienv_seed(algo.env, seed=task)\n",
    "        # Sample pre-trajectories from each task: STEP 4\n",
    "        pre_exps, pre_logs1 = algo.collect_experiences()\n",
    "         # Unfreeze inner loop params,so grads can get updated in the inner loop\n",
    "        set_freeze_status(algo.acmodel, inner_params, freeze=False)\n",
    "        # Freeze outer loop parameters, so grads do not get updated in the inner loop\n",
    "        set_freeze_status(algo.acmodel, outer_params, freeze=True)\n",
    "        # set inner RIM recurence\n",
    "        algo.recurrence = inner_recurrence\n",
    "        # Update parameters: STEP 6\n",
    "        algo.update_parameters(pre_exps)\n",
    "        # Sample post-trajectories t_i from tasks T_i: STEP 7\n",
    "        post_exps, post_logs1 = algo.collect_experiences()\n",
    "        # Concatenate to get D_meta: STEP 8\n",
    "        meta_exps = post_exps if n==0 else cat_exps(meta_exps, post_exps)\n",
    "        meta_exps = DictList(meta_exps)\n",
    "        meta_exps.obs = DictList(meta_exps.obs)\n",
    "        meta_logs1 = post_logs1 if n==0 else cat_logs(meta_logs1, post_logs1)\n",
    "\n",
    "    # Unfreeze outer loop params, so so grads can get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=False)\n",
    "    # Freeze inner loop params, so grads do not get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=True)   \n",
    "    \n",
    "    # set outer RIM recurence\n",
    "    algo.recurrence = outer_recurrence\n",
    "\n",
    "    # Update parameters while keeping inner parametes (module and policy) frozen: STEP 9\n",
    "    meta_logs2 = algo.update_parameters(meta_exps)\n",
    "\n",
    "    meta_logs = {**meta_logs1, **meta_logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += meta_logs[\"num_frames\"]\n",
    "    update += 1    \n",
    "    \n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = meta_logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(meta_logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(meta_logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(meta_logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=rreturn_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [meta_logs[\"entropy\"], meta_logs[\"value\"], meta_logs[\"policy_loss\"], meta_logs[\"value_loss\"], meta_logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "# STEP 10\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 400000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Agent loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim, num_units=args.num_units, k=args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent run completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 1443.0 | FPS 3108 | D 0 | R:μσmM 0.91 0.03 0.82 0.98 | F:μσmM 14.4 4.9 4.0 29.0\n",
      "\n",
      "10 worst episodes:\n",
      "- episode 23: R=0.8187500238418579, F=29.0\n",
      "- episode 80: R=0.8187500238418579, F=29.0\n",
      "- episode 60: R=0.8374999761581421, F=26.0\n",
      "- episode 42: R=0.8500000238418579, F=24.0\n",
      "- episode 61: R=0.856249988079071, F=23.0\n",
      "- episode 14: R=0.862500011920929, F=22.0\n",
      "- episode 95: R=0.862500011920929, F=22.0\n",
      "- episode 12: R=0.8687499761581421, F=21.0\n",
      "- episode 13: R=0.8687499761581421, F=21.0\n",
      "- episode 22: R=0.8687499761581421, F=21.0\n"
     ]
    }
   ],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim, num_units = args.num_units, k = args.k)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue meta-RIMs learning on 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "\n",
    "add_frames = 500000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':True # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 5\n",
    "    args.k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status (TEST for CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "envs = make_envs(args.env, args.procs, args.seed)\n",
    "\n",
    "algo.env = envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text, args.use_rim, args.num_units, args.k)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "# delete param_groups after it has been created\n",
    "for i in range(len(algo.optimizer.param_groups)):\n",
    "    del algo.optimizer.param_groups[0]\n",
    "\n",
    "# Re-create separate param_groups for different inner and outer loop optimizer lr\n",
    "\n",
    "# inner loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.image_conv.parameters(), \n",
    "    *acmodel.memory_rnn.rnn.parameters(), \n",
    "    *acmodel.actor.parameters()], 'lr': lr_alpha})\n",
    "\n",
    "# outer loop param group\n",
    "algo.optimizer.add_param_group({'params': [\n",
    "    *acmodel.critic.parameters(), \n",
    "    *acmodel.memory_rnn.key.parameters(),\n",
    "    *acmodel.memory_rnn.key_.parameters(),\n",
    "    *acmodel.memory_rnn.query.parameters(),\n",
    "    *acmodel.memory_rnn.query_.parameters(),\n",
    "    *acmodel.memory_rnn.value.parameters(),\n",
    "    *acmodel.memory_rnn.value_.parameters(),\n",
    "    *acmodel.memory_rnn.comm_attention_output.parameters()\n",
    "    ], 'lr': lr_beta})\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 51 | F 208896 | FPS 0296 | D 13 | rR:μσmM 0.47 0.43 0.00 0.95 | F:μσmM 197.9 170.1 10.0 452.0 | H 1.678 | V 0.380 | pL 0.195 | vL 0.003 | ∇ 0.117\n",
      "U 52 | F 212992 | FPS 0315 | D 26 | rR:μσmM 0.07 0.18 0.00 0.62 | F:μσmM 346.4 54.8 154.0 452.0 | H 1.803 | V 0.130 | pL 0.168 | vL 0.007 | ∇ 0.182\n",
      "U 53 | F 217088 | FPS 0291 | D 40 | rR:μσmM 0.01 0.04 0.00 0.20 | F:μσmM 358.1 7.9 318.0 360.0 | H 1.893 | V 0.040 | pL 0.030 | vL 0.002 | ∇ 0.103\n",
      "U 54 | F 221184 | FPS 0279 | D 55 | rR:μσmM 0.03 0.06 0.00 0.21 | F:μσmM 355.6 11.7 315.0 360.0 | H 1.918 | V -0.003 | pL -0.012 | vL 0.003 | ∇ 0.132\n",
      "U 55 | F 225280 | FPS 0315 | D 68 | rR:μσmM 0.03 0.12 0.00 0.61 | F:μσmM 349.9 37.5 158.0 360.0 | H 1.938 | V 0.016 | pL 0.007 | vL 0.000 | ∇ 0.012\n",
      "U 56 | F 229376 | FPS 0310 | D 81 | rR:μσmM 0.09 0.22 0.00 0.75 | F:μσmM 403.0 390.6 100.0 2544.0 | H 1.933 | V 0.033 | pL -0.017 | vL 0.013 | ∇ 0.182\n",
      "U 57 | F 233472 | FPS 0288 | D 96 | rR:μσmM 0.18 0.29 0.00 0.93 | F:μσmM 377.6 401.0 29.0 2544.0 | H 1.928 | V 0.027 | pL -0.007 | vL 0.005 | ∇ 0.125\n",
      "U 58 | F 237568 | FPS 0293 | D 110 | rR:μσmM 0.11 0.24 0.00 0.93 | F:μσmM 323.6 80.5 29.0 360.0 | H 1.928 | V 0.004 | pL -0.011 | vL 0.003 | ∇ 0.068\n",
      "U 59 | F 241664 | FPS 0243 | D 126 | rR:μσmM 0.25 0.30 0.00 0.84 | F:μσmM 277.8 103.8 65.0 360.0 | H 1.914 | V 0.039 | pL 0.006 | vL 0.006 | ∇ 0.102\n",
      "U 60 | F 245760 | FPS 0319 | D 139 | rR:μσmM 0.13 0.22 0.00 0.71 | F:μσmM 321.2 73.2 116.0 360.0 | H 1.935 | V 0.034 | pL 0.017 | vL 0.001 | ∇ 0.044\n",
      "Status saved\n",
      "U 61 | F 249856 | FPS 0305 | D 153 | rR:μσmM 0.19 0.30 0.00 0.92 | F:μσmM 297.6 104.8 31.0 360.0 | H 1.915 | V 0.059 | pL -0.027 | vL 0.008 | ∇ 0.050\n",
      "U 62 | F 253952 | FPS 0315 | D 166 | rR:μσmM 0.14 0.27 0.00 0.92 | F:μσmM 314.4 92.7 31.0 360.0 | H 1.929 | V 0.032 | pL -0.013 | vL 0.007 | ∇ 0.143\n",
      "U 63 | F 258048 | FPS 0307 | D 179 | rR:μσmM 0.20 0.26 0.00 0.66 | F:μσmM 296.4 87.9 135.0 360.0 | H 1.917 | V 0.085 | pL -0.019 | vL 0.009 | ∇ 0.127\n",
      "U 64 | F 262144 | FPS 0312 | D 192 | rR:μσmM 0.12 0.21 0.00 0.59 | F:μσmM 323.7 65.8 165.0 360.0 | H 1.936 | V 0.041 | pL -0.011 | vL 0.004 | ∇ 0.116\n",
      "U 65 | F 266240 | FPS 0319 | D 205 | rR:μσmM 0.12 0.24 0.00 0.84 | F:μσmM 321.1 81.7 65.0 360.0 | H 1.924 | V 0.023 | pL -0.001 | vL 0.006 | ∇ 0.108\n",
      "U 66 | F 270336 | FPS 0296 | D 219 | rR:μσmM 0.26 0.30 0.00 0.81 | F:μσmM 421.3 789.0 78.0 4781.0 | H 1.899 | V 0.065 | pL -0.016 | vL 0.006 | ∇ 0.109\n",
      "U 67 | F 274432 | FPS 0314 | D 232 | rR:μσmM 0.30 0.31 0.00 0.87 | F:μσmM 262.3 106.3 53.0 360.0 | H 1.865 | V 0.113 | pL 0.013 | vL 0.011 | ∇ 0.109\n",
      "U 68 | F 278528 | FPS 0312 | D 245 | rR:μσmM 0.39 0.31 0.00 0.92 | F:μσmM 263.2 179.6 31.0 1062.0 | H 1.869 | V 0.071 | pL -0.013 | vL 0.014 | ∇ 0.081\n",
      "U 69 | F 282624 | FPS 0316 | D 258 | rR:μσmM 0.49 0.34 0.00 0.94 | F:μσmM 199.1 120.6 25.0 360.0 | H 1.873 | V 0.118 | pL 0.012 | vL 0.009 | ∇ 0.063\n",
      "U 70 | F 286720 | FPS 0314 | D 271 | rR:μσmM 0.47 0.35 0.00 0.90 | F:μσmM 202.7 123.3 39.0 360.0 | H 1.877 | V 0.188 | pL 0.036 | vL 0.011 | ∇ 0.159\n",
      "Status saved\n",
      "U 71 | F 290816 | FPS 0311 | D 284 | rR:μσmM 0.47 0.37 0.00 0.94 | F:μσmM 211.4 133.9 23.0 468.0 | H 1.888 | V 0.123 | pL 0.031 | vL 0.005 | ∇ 0.064\n",
      "U 72 | F 294912 | FPS 0316 | D 297 | rR:μσmM 0.52 0.31 0.00 0.92 | F:μσmM 203.6 166.5 31.0 885.0 | H 1.850 | V 0.144 | pL -0.014 | vL 0.013 | ∇ 0.136\n",
      "U 73 | F 299008 | FPS 0299 | D 311 | rR:μσmM 0.67 0.27 0.00 0.93 | F:μσmM 127.4 97.8 28.0 360.0 | H 1.791 | V 0.288 | pL -0.008 | vL 0.030 | ∇ 0.162\n",
      "U 74 | F 303104 | FPS 0298 | D 325 | rR:μσmM 0.69 0.27 0.00 0.95 | F:μσmM 121.9 102.1 21.0 360.0 | H 1.749 | V 0.309 | pL 0.010 | vL 0.018 | ∇ 0.209\n",
      "U 75 | F 307200 | FPS 0305 | D 338 | rR:μσmM 0.65 0.30 0.00 0.96 | F:μσmM 137.8 112.4 17.0 360.0 | H 1.823 | V 0.241 | pL 0.024 | vL 0.009 | ∇ 0.145\n",
      "U 76 | F 311296 | FPS 0321 | D 351 | rR:μσmM 0.71 0.24 0.00 0.95 | F:μσmM 114.8 92.2 20.0 360.0 | H 1.711 | V 0.380 | pL -0.061 | vL 0.023 | ∇ 0.164\n",
      "U 77 | F 315392 | FPS 0322 | D 364 | rR:μσmM 0.83 0.10 0.46 0.96 | F:μσmM 67.1 40.8 16.0 215.0 | H 1.619 | V 0.543 | pL -0.038 | vL 0.022 | ∇ 0.229\n",
      "U 78 | F 319488 | FPS 0316 | D 377 | rR:μσmM 0.85 0.11 0.38 0.96 | F:μσmM 60.1 44.0 17.0 249.0 | H 1.531 | V 0.602 | pL -0.038 | vL 0.014 | ∇ 0.109\n",
      "U 79 | F 323584 | FPS 0311 | D 390 | rR:μσmM 0.85 0.11 0.28 0.96 | F:μσmM 61.5 45.1 14.0 290.0 | H 1.619 | V 0.581 | pL 0.068 | vL 0.015 | ∇ 0.163\n",
      "U 80 | F 327680 | FPS 0305 | D 403 | rR:μσmM 0.87 0.07 0.63 0.94 | F:μσmM 53.7 28.1 22.0 148.0 | H 1.647 | V 0.620 | pL 0.006 | vL 0.012 | ∇ 0.104\n",
      "Status saved\n",
      "U 81 | F 331776 | FPS 0306 | D 417 | rR:μσmM 0.84 0.15 0.00 0.96 | F:μσmM 64.7 58.3 17.0 360.0 | H 1.579 | V 0.593 | pL 0.013 | vL 0.016 | ∇ 0.171\n",
      "U 82 | F 335872 | FPS 0321 | D 429 | rR:μσmM 0.87 0.08 0.59 0.97 | F:μσmM 51.1 32.9 13.0 163.0 | H 1.616 | V 0.592 | pL -0.035 | vL 0.017 | ∇ 0.130\n",
      "U 83 | F 339968 | FPS 0318 | D 442 | rR:μσmM 0.87 0.07 0.48 0.95 | F:μσmM 50.2 29.5 18.0 207.0 | H 1.588 | V 0.602 | pL 0.039 | vL 0.015 | ∇ 0.138\n",
      "U 84 | F 344064 | FPS 0322 | D 455 | rR:μσmM 0.89 0.06 0.61 0.97 | F:μσmM 43.9 25.1 12.0 155.0 | H 1.564 | V 0.671 | pL -0.032 | vL 0.009 | ∇ 0.103\n",
      "U 85 | F 348160 | FPS 0268 | D 470 | rR:μσmM 0.89 0.06 0.68 0.97 | F:μσmM 42.7 22.5 11.0 128.0 | H 1.578 | V 0.654 | pL 0.051 | vL 0.009 | ∇ 0.107\n",
      "U 86 | F 352256 | FPS 0293 | D 484 | rR:μσmM 0.88 0.06 0.65 0.97 | F:μσmM 49.0 24.6 12.0 140.0 | H 1.638 | V 0.645 | pL 0.022 | vL 0.009 | ∇ 0.107\n",
      "U 87 | F 356352 | FPS 0322 | D 497 | rR:μσmM 0.89 0.06 0.67 0.96 | F:μσmM 45.2 23.3 15.0 134.0 | H 1.603 | V 0.665 | pL -0.014 | vL 0.006 | ∇ 0.067\n",
      "U 88 | F 360448 | FPS 0326 | D 510 | rR:μσmM 0.89 0.07 0.50 0.96 | F:μσmM 44.5 29.3 14.0 204.0 | H 1.592 | V 0.635 | pL -0.012 | vL 0.012 | ∇ 0.107\n",
      "U 89 | F 364544 | FPS 0312 | D 523 | rR:μσmM 0.90 0.05 0.63 0.97 | F:μσmM 39.9 20.7 11.0 146.0 | H 1.610 | V 0.682 | pL -0.019 | vL 0.008 | ∇ 0.084\n",
      "U 90 | F 368640 | FPS 0316 | D 536 | rR:μσmM 0.90 0.04 0.79 0.96 | F:μσmM 41.2 16.8 17.0 84.0 | H 1.539 | V 0.711 | pL 0.028 | vL 0.008 | ∇ 0.124\n",
      "Status saved\n",
      "U 91 | F 372736 | FPS 0319 | D 549 | rR:μσmM 0.91 0.04 0.62 0.97 | F:μσmM 34.3 17.7 12.0 150.0 | H 1.459 | V 0.728 | pL -0.008 | vL 0.005 | ∇ 0.062\n",
      "U 92 | F 376832 | FPS 0313 | D 562 | rR:μσmM 0.91 0.04 0.71 0.97 | F:μσmM 34.3 16.3 11.0 114.0 | H 1.493 | V 0.725 | pL 0.004 | vL 0.008 | ∇ 0.079\n",
      "U 93 | F 380928 | FPS 0301 | D 575 | rR:μσmM 0.92 0.03 0.75 0.97 | F:μσmM 33.0 13.6 12.0 101.0 | H 1.472 | V 0.729 | pL -0.014 | vL 0.008 | ∇ 0.082\n",
      "U 94 | F 385024 | FPS 0322 | D 588 | rR:μσmM 0.92 0.03 0.80 0.96 | F:μσmM 33.2 13.5 14.0 80.0 | H 1.460 | V 0.779 | pL 0.004 | vL 0.005 | ∇ 0.077\n",
      "U 95 | F 389120 | FPS 0315 | D 601 | rR:μσmM 0.92 0.03 0.76 0.98 | F:μσmM 30.1 13.0 10.0 95.0 | H 1.424 | V 0.753 | pL -0.020 | vL 0.005 | ∇ 0.072\n",
      "U 96 | F 393216 | FPS 0323 | D 614 | rR:μσmM 0.92 0.03 0.78 0.97 | F:μσmM 32.7 13.1 13.0 89.0 | H 1.476 | V 0.779 | pL 0.004 | vL 0.003 | ∇ 0.048\n",
      "U 97 | F 397312 | FPS 0313 | D 627 | rR:μσmM 0.92 0.04 0.75 0.97 | F:μσmM 33.4 15.3 13.0 102.0 | H 1.476 | V 0.732 | pL 0.008 | vL 0.007 | ∇ 0.096\n",
      "U 98 | F 401408 | FPS 0323 | D 640 | rR:μσmM 0.92 0.03 0.80 0.97 | F:μσmM 32.7 13.4 11.0 82.0 | H 1.410 | V 0.767 | pL -0.032 | vL 0.004 | ∇ 0.056\n",
      "U 99 | F 405504 | FPS 0320 | D 652 | rR:μσmM 0.93 0.03 0.81 0.97 | F:μσmM 28.9 10.7 12.0 75.0 | H 1.392 | V 0.788 | pL 0.004 | vL 0.003 | ∇ 0.048\n",
      "Number of frames:  409600\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average settings for early stop\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "# run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "# exps, _ = algo.collect_experiences()\n",
    "# algo.update_parameters(exps)\n",
    "\n",
    "while num_frames < args.frames: # STEP 2\n",
    "\n",
    "    update_start_time = time.time()\n",
    "\n",
    "    # # run just once to have initial grads in all parameters and avoid backward error on first pass\n",
    "    # exps, _ = algo.collect_experiences()\n",
    "    # algo.update_parameters(exps)\n",
    "\n",
    "    # Sample batch of tasks: STEP 3\n",
    "    tasks_batch = sample_tasks(n_tasks=num_tasks)\n",
    "\n",
    "    for n, task in enumerate(tasks_batch):\n",
    "\n",
    "        algo.env = change_multienv_seed(algo.env, seed=task)\n",
    "        #algo.env = make_envs(args.env, args.procs, seed=task)\n",
    "        # Sample pre-trajectories from each task: STEP 4\n",
    "        pre_exps, pre_logs1 = algo.collect_experiences()\n",
    "         # Unfreeze inner loop params so they can get updated in the inner loop\n",
    "        set_freeze_status(algo.acmodel, inner_params, freeze=False)\n",
    "        # Freeze outer loop parameters, so those grads will be zero in update\n",
    "        set_freeze_status(algo.acmodel, outer_params, freeze=True)\n",
    "        # set inner recurence\n",
    "        algo.recurrence = inner_recurrence\n",
    "        # Update parameters: STEP 6\n",
    "        algo.update_parameters(pre_exps)\n",
    "        # Sample post-trajectories t_i from tasks T_i: STEP 7\n",
    "        post_exps, post_logs1 = algo.collect_experiences()\n",
    "        # Concatenate to get D_meta: STEP 8\n",
    "        meta_exps = post_exps if n==0 else cat_exps(meta_exps, post_exps)\n",
    "        meta_exps = DictList(meta_exps)\n",
    "        meta_exps.obs = DictList(meta_exps.obs)\n",
    "        meta_logs1 = post_logs1 if n==0 else cat_logs(meta_logs1, post_logs1)\n",
    "\n",
    "    # Unfreeze outer loop params so they can get updated in the outer loop\n",
    "    set_freeze_status(algo.acmodel, outer_params, freeze=False)\n",
    "    # Freeze inner loop params \n",
    "    set_freeze_status(algo.acmodel, inner_params, freeze=True)   \n",
    "    \n",
    "    # set outer recurence\n",
    "    algo.recurrence = outer_recurrence\n",
    "\n",
    "    # Update parameters while keeping inner parametes (module and policy) frozen: STEP 9\n",
    "    meta_logs2 = algo.update_parameters(meta_exps)\n",
    "\n",
    "    meta_logs = {**meta_logs1, **meta_logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += meta_logs[\"num_frames\"]\n",
    "    update += 1    \n",
    "    \n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = meta_logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(meta_logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(meta_logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(meta_logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=rreturn_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [meta_logs[\"entropy\"], meta_logs[\"value\"], meta_logs[\"policy_loss\"], meta_logs[\"value_loss\"], meta_logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "# STEP 10\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Agent loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim, num_units=args.num_units, k=args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent run completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 3814.0 | FPS 3231 | D 1 | R:μσmM 0.91 0.04 0.77 0.97 | F:μσmM 37.8 15.1 13.0 93.0\n",
      "\n",
      "10 worst episodes:\n",
      "- episode 42: R=0.7674999833106995, F=93.0\n",
      "- episode 64: R=0.7900000214576721, F=84.0\n",
      "- episode 87: R=0.8100000023841858, F=76.0\n",
      "- episode 99: R=0.8274999856948853, F=69.0\n",
      "- episode 44: R=0.8324999809265137, F=67.0\n",
      "- episode 56: R=0.8450000286102295, F=62.0\n",
      "- episode 18: R=0.8525000214576721, F=59.0\n",
      "- episode 54: R=0.8575000166893005, F=57.0\n",
      "- episode 91: R=0.8600000143051147, F=56.0\n",
      "- episode 50: R=0.862500011920929, F=55.0\n"
     ]
    }
   ],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st enviroment and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'MiniGrid-WallGapS6-v0_meta_RIM_5_3_frames_300k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': True, 'mem': True, 'num_units': 5, 'k': 3, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Agent loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    env = utils.make_env(args.env, args.seed + 10000 * i)\n",
    "    envs.append(env)\n",
    "env = ParallelEnv(envs)\n",
    "print(\"Environments loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim, num_units=args.num_units, k=args.k)\n",
    "print(\"Agent loaded\\n\")\n",
    "\n",
    "# Initialize logs\n",
    "\n",
    "logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent run completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run agent\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "obss = env.reset()\n",
    "\n",
    "log_done_counter = 0\n",
    "log_episode_return = torch.zeros(args.procs, device=device)\n",
    "log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "while log_done_counter < args.episodes:\n",
    "    actions = agent.get_actions(obss)\n",
    "    obss, rewards, dones, _ = env.step(actions)\n",
    "    agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "    log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "    for i, done in enumerate(dones):\n",
    "        if done:\n",
    "            log_done_counter += 1\n",
    "            logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "            logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "    log_episode_return *= mask\n",
    "    log_episode_num_frames *= mask\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Agent run completed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print logs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F 8814.0 | FPS 3205 | D 2 | R:μσmM 0.40 0.43 0.00 0.98 | F:μσmM 87.3 61.2 4.0 144.0\n",
      "\n",
      "10 worst episodes:\n",
      "- episode 8: R=0.0, F=144.0\n",
      "- episode 9: R=0.0, F=144.0\n",
      "- episode 10: R=0.0, F=144.0\n",
      "- episode 11: R=0.0, F=144.0\n",
      "- episode 12: R=0.0, F=144.0\n",
      "- episode 13: R=0.0, F=144.0\n",
      "- episode 14: R=0.0, F=144.0\n",
      "- episode 15: R=0.0, F=144.0\n",
      "- episode 16: R=0.0, F=144.0\n",
      "- episode 17: R=0.0, F=144.0\n"
     ]
    }
   ],
   "source": [
    "# Print logs\n",
    "\n",
    "num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "fps = num_frames/(end_time - start_time)\n",
    "duration = int(end_time - start_time)\n",
    "return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(num_frames, fps, duration,\n",
    "              *return_per_episode.values(),\n",
    "              *num_frames_per_episode.values()))\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "n = args.worst_episodes_to_show\n",
    "if n > 0:\n",
    "    print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "    indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "    for i in indexes[:n]:\n",
    "        print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-rims",
   "language": "python",
   "name": "tfm-rims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
