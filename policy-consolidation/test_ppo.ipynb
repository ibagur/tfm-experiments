{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, FullyObsWrapper, ViewSizeWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([0 0 0 ... 0 0 0], [255 255 255 ... 255 255 255], (2739,), uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);\n",
    "#eval_env = ImgObsWrapper(RGBImgPartialObsWrapper(eval_env))\n",
    "#eval_env = ViewSizeWrapper(eval_env, 7)\n",
    "#eval_env = FlatObsWrapper(eval_env)\n",
    "#print(eval_env._observation_space.shape)\n",
    "#print(eval_env._observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Standard PPO learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "\n",
    "seed = 1\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#model = 'MiniGrid-WallGapS6-v0_PPO_frames_600k_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "processes = 16\n",
    "frames = 300000\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1 | F 002048 | FPS 2774 | D 0 | rR:μσmM 0.11 0.23 0.00 0.75 | F:μσmM 13.2 29.1 0.0 94.0 | H 1.912 | V -0.071 | pL -0.089 | vL 0.016 | ∇ 0.056\n",
      "U 2 | F 004096 | FPS 2965 | D 1 | rR:μσmM 0.01 0.03 0.00 0.14 | F:μσmM 143.6 1.7 137.0 144.0 | H 1.925 | V -0.026 | pL -0.024 | vL 0.000 | ∇ 0.008\n",
      "U 3 | F 006144 | FPS 2745 | D 2 | rR:μσmM 0.07 0.19 0.00 0.61 | F:μσmM 135.2 25.0 62.0 144.0 | H 1.915 | V 0.008 | pL -0.035 | vL 0.008 | ∇ 0.026\n",
      "U 4 | F 008192 | FPS 2979 | D 2 | rR:μσmM 0.07 0.19 0.00 0.71 | F:μσmM 135.0 25.5 46.0 144.0 | H 1.927 | V 0.022 | pL -0.011 | vL 0.006 | ∇ 0.049\n",
      "U 5 | F 010240 | FPS 2492 | D 3 | rR:μσmM 0.09 0.23 0.00 0.77 | F:μσmM 131.9 31.8 37.0 144.0 | H 1.927 | V 0.031 | pL -0.016 | vL 0.008 | ∇ 0.040\n",
      "U 6 | F 012288 | FPS 2590 | D 4 | rR:μσmM 0.16 0.26 0.00 0.72 | F:μσmM 122.8 34.4 45.0 144.0 | H 1.918 | V 0.039 | pL -0.035 | vL 0.012 | ∇ 0.094\n",
      "U 7 | F 014336 | FPS 2757 | D 5 | rR:μσmM 0.21 0.32 0.00 0.84 | F:μσmM 115.8 44.6 26.0 144.0 | H 1.902 | V 0.072 | pL -0.022 | vL 0.019 | ∇ 0.089\n",
      "U 8 | F 016384 | FPS 3037 | D 5 | rR:μσmM 0.28 0.30 0.00 0.95 | F:μσmM 107.3 41.1 8.0 144.0 | H 1.899 | V 0.099 | pL -0.023 | vL 0.012 | ∇ 0.060\n",
      "U 9 | F 018432 | FPS 2997 | D 6 | rR:μσmM 0.14 0.24 0.00 0.84 | F:μσmM 126.9 32.4 26.0 144.0 | H 1.893 | V 0.083 | pL 0.022 | vL 0.009 | ∇ 0.080\n",
      "U 10 | F 020480 | FPS 3119 | D 7 | rR:μσmM 0.26 0.34 0.00 0.84 | F:μσmM 108.6 47.5 26.0 144.0 | H 1.883 | V 0.075 | pL -0.008 | vL 0.012 | ∇ 0.070\n",
      "Status saved\n",
      "U 11 | F 022528 | FPS 3097 | D 7 | rR:μσmM 0.45 0.36 0.00 0.94 | F:μσmM 83.8 52.7 10.0 144.0 | H 1.872 | V 0.165 | pL -0.074 | vL 0.024 | ∇ 0.093\n",
      "U 12 | F 024576 | FPS 2961 | D 8 | rR:μσmM 0.48 0.35 0.00 0.94 | F:μσmM 78.2 50.2 10.0 144.0 | H 1.845 | V 0.187 | pL -0.040 | vL 0.021 | ∇ 0.074\n",
      "U 13 | F 026624 | FPS 3048 | D 9 | rR:μσmM 0.39 0.34 0.00 0.99 | F:μσmM 92.6 48.3 2.0 144.0 | H 1.799 | V 0.205 | pL 0.022 | vL 0.021 | ∇ 0.101\n",
      "U 14 | F 028672 | FPS 2829 | D 10 | rR:μσmM 0.37 0.36 0.00 0.98 | F:μσmM 94.6 50.1 4.0 144.0 | H 1.861 | V 0.164 | pL 0.018 | vL 0.018 | ∇ 0.082\n",
      "U 15 | F 030720 | FPS 3022 | D 10 | rR:μσmM 0.46 0.34 0.00 0.94 | F:μσmM 83.2 48.9 10.0 144.0 | H 1.821 | V 0.221 | pL -0.022 | vL 0.025 | ∇ 0.118\n",
      "U 16 | F 032768 | FPS 3057 | D 11 | rR:μσmM 0.40 0.34 0.00 0.91 | F:μσmM 90.1 47.5 14.0 144.0 | H 1.831 | V 0.230 | pL 0.017 | vL 0.018 | ∇ 0.099\n",
      "U 17 | F 034816 | FPS 3035 | D 12 | rR:μσmM 0.57 0.29 0.00 0.93 | F:μσmM 66.5 42.1 12.0 144.0 | H 1.800 | V 0.296 | pL -0.073 | vL 0.032 | ∇ 0.129\n",
      "U 18 | F 036864 | FPS 3104 | D 12 | rR:μσmM 0.51 0.30 0.00 0.84 | F:μσmM 75.8 42.5 26.0 144.0 | H 1.790 | V 0.304 | pL -0.009 | vL 0.030 | ∇ 0.100\n",
      "U 19 | F 038912 | FPS 3149 | D 13 | rR:μσmM 0.59 0.26 0.00 0.95 | F:μσmM 64.5 39.6 8.0 144.0 | H 1.771 | V 0.320 | pL -0.032 | vL 0.027 | ∇ 0.166\n",
      "U 20 | F 040960 | FPS 3102 | D 14 | rR:μσmM 0.59 0.31 0.00 0.96 | F:μσmM 62.8 45.5 7.0 144.0 | H 1.769 | V 0.350 | pL 0.009 | vL 0.027 | ∇ 0.126\n",
      "Status saved\n",
      "U 21 | F 043008 | FPS 3083 | D 14 | rR:μσmM 0.68 0.28 0.00 0.98 | F:μσmM 48.9 41.1 4.0 144.0 | H 1.727 | V 0.369 | pL -0.032 | vL 0.033 | ∇ 0.168\n",
      "U 22 | F 045056 | FPS 3046 | D 15 | rR:μσmM 0.63 0.32 0.00 0.97 | F:μσmM 56.5 46.9 5.0 144.0 | H 1.731 | V 0.378 | pL -0.015 | vL 0.036 | ∇ 0.192\n",
      "U 23 | F 047104 | FPS 2990 | D 16 | rR:μσmM 0.70 0.23 0.00 0.96 | F:μσmM 47.7 35.0 6.0 144.0 | H 1.709 | V 0.452 | pL -0.044 | vL 0.028 | ∇ 0.113\n",
      "U 24 | F 049152 | FPS 2953 | D 16 | rR:μσmM 0.72 0.23 0.00 0.99 | F:μσmM 44.7 35.2 2.0 144.0 | H 1.659 | V 0.491 | pL 0.018 | vL 0.026 | ∇ 0.131\n",
      "U 25 | F 051200 | FPS 3035 | D 17 | rR:μσmM 0.74 0.22 0.00 0.96 | F:μσmM 40.2 32.7 6.0 144.0 | H 1.689 | V 0.495 | pL 0.013 | vL 0.026 | ∇ 0.156\n",
      "U 26 | F 053248 | FPS 2750 | D 18 | rR:μσmM 0.75 0.21 0.00 0.98 | F:μσmM 40.4 33.1 3.0 144.0 | H 1.657 | V 0.515 | pL -0.005 | vL 0.026 | ∇ 0.161\n",
      "U 27 | F 055296 | FPS 2997 | D 18 | rR:μσmM 0.76 0.19 0.29 0.98 | F:μσmM 38.3 30.5 4.0 114.0 | H 1.624 | V 0.532 | pL -0.011 | vL 0.025 | ∇ 0.172\n",
      "U 28 | F 057344 | FPS 3039 | D 19 | rR:μσmM 0.82 0.14 0.35 0.97 | F:μσmM 28.8 21.7 5.0 104.0 | H 1.555 | V 0.618 | pL -0.109 | vL 0.018 | ∇ 0.167\n",
      "U 29 | F 059392 | FPS 3058 | D 20 | rR:μσmM 0.83 0.11 0.54 0.97 | F:μσmM 26.8 18.2 5.0 74.0 | H 1.492 | V 0.620 | pL -0.064 | vL 0.017 | ∇ 0.135\n",
      "U 30 | F 061440 | FPS 3033 | D 20 | rR:μσmM 0.84 0.11 0.42 0.98 | F:μσmM 25.4 18.4 4.0 93.0 | H 1.498 | V 0.664 | pL -0.021 | vL 0.015 | ∇ 0.142\n",
      "Status saved\n",
      "U 31 | F 063488 | FPS 2974 | D 21 | rR:μσmM 0.83 0.13 0.37 0.98 | F:μσmM 27.8 20.0 4.0 101.0 | H 1.504 | V 0.657 | pL 0.020 | vL 0.014 | ∇ 0.136\n",
      "U 32 | F 065536 | FPS 2958 | D 22 | rR:μσmM 0.84 0.10 0.51 0.98 | F:μσmM 25.2 16.8 3.0 78.0 | H 1.479 | V 0.671 | pL -0.056 | vL 0.014 | ∇ 0.199\n",
      "U 33 | F 067584 | FPS 2988 | D 23 | rR:μσmM 0.87 0.08 0.68 0.98 | F:μσmM 21.4 12.5 4.0 52.0 | H 1.405 | V 0.731 | pL -0.001 | vL 0.009 | ∇ 0.139\n",
      "U 34 | F 069632 | FPS 2969 | D 23 | rR:μσmM 0.87 0.08 0.56 0.98 | F:μσmM 21.2 12.8 3.0 70.0 | H 1.409 | V 0.729 | pL -0.029 | vL 0.009 | ∇ 0.112\n",
      "U 35 | F 071680 | FPS 2971 | D 24 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.6 3.0 75.0 | H 1.366 | V 0.750 | pL -0.015 | vL 0.011 | ∇ 0.174\n",
      "U 36 | F 073728 | FPS 2963 | D 25 | rR:μσmM 0.88 0.07 0.49 0.98 | F:μσmM 19.0 12.0 3.0 81.0 | H 1.339 | V 0.765 | pL -0.004 | vL 0.008 | ∇ 0.096\n",
      "U 37 | F 075776 | FPS 2974 | D 25 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.7 3.0 75.0 | H 1.334 | V 0.760 | pL 0.018 | vL 0.010 | ∇ 0.161\n",
      "U 38 | F 077824 | FPS 2950 | D 26 | rR:μσmM 0.88 0.06 0.66 0.98 | F:μσmM 19.1 10.2 3.0 55.0 | H 1.411 | V 0.771 | pL 0.031 | vL 0.005 | ∇ 0.100\n",
      "U 39 | F 079872 | FPS 2946 | D 27 | rR:μσmM 0.89 0.06 0.68 0.98 | F:μσmM 16.9 9.6 3.0 51.0 | H 1.323 | V 0.783 | pL -0.025 | vL 0.011 | ∇ 0.202\n",
      "U 40 | F 081920 | FPS 2951 | D 27 | rR:μσmM 0.89 0.05 0.68 0.98 | F:μσmM 17.8 8.6 3.0 51.0 | H 1.339 | V 0.780 | pL -0.009 | vL 0.006 | ∇ 0.118\n",
      "Status saved\n",
      "U 41 | F 083968 | FPS 2919 | D 28 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.5 4.0 45.0 | H 1.274 | V 0.792 | pL -0.047 | vL 0.005 | ∇ 0.114\n",
      "U 42 | F 086016 | FPS 2822 | D 29 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.1 5.8 3.0 34.0 | H 1.206 | V 0.823 | pL -0.061 | vL 0.003 | ∇ 0.098\n",
      "U 43 | F 088064 | FPS 2860 | D 30 | rR:μσmM 0.91 0.04 0.73 0.98 | F:μσmM 13.8 6.5 3.0 43.0 | H 1.260 | V 0.837 | pL 0.021 | vL 0.003 | ∇ 0.097\n",
      "U 44 | F 090112 | FPS 2891 | D 30 | rR:μσmM 0.89 0.06 0.74 0.98 | F:μσmM 17.4 9.3 3.0 42.0 | H 1.367 | V 0.781 | pL 0.048 | vL 0.004 | ∇ 0.094\n",
      "U 45 | F 092160 | FPS 2870 | D 31 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.0 3.0 45.0 | H 1.378 | V 0.805 | pL 0.018 | vL 0.003 | ∇ 0.062\n",
      "U 46 | F 094208 | FPS 2800 | D 32 | rR:μσmM 0.89 0.06 0.66 0.98 | F:μσmM 16.9 9.2 3.0 55.0 | H 1.358 | V 0.787 | pL 0.014 | vL 0.009 | ∇ 0.182\n",
      "U 47 | F 096256 | FPS 2859 | D 32 | rR:μσmM 0.90 0.06 0.41 0.98 | F:μσmM 16.5 10.0 4.0 95.0 | H 1.372 | V 0.805 | pL 0.038 | vL 0.006 | ∇ 0.084\n",
      "U 48 | F 098304 | FPS 2851 | D 33 | rR:μσmM 0.88 0.07 0.68 0.98 | F:μσmM 19.8 10.9 4.0 52.0 | H 1.365 | V 0.752 | pL 0.019 | vL 0.006 | ∇ 0.097\n",
      "U 49 | F 100352 | FPS 2763 | D 34 | rR:μσmM 0.89 0.06 0.68 0.96 | F:μσmM 17.6 9.5 6.0 52.0 | H 1.262 | V 0.775 | pL -0.033 | vL 0.005 | ∇ 0.077\n",
      "U 50 | F 102400 | FPS 2160 | D 35 | rR:μσmM 0.89 0.06 0.68 0.99 | F:μσmM 17.3 9.3 2.0 51.0 | H 1.256 | V 0.784 | pL -0.025 | vL 0.005 | ∇ 0.094\n",
      "Status saved\n",
      "U 51 | F 104448 | FPS 2859 | D 36 | rR:μσmM 0.90 0.05 0.75 0.97 | F:μσmM 16.1 7.5 5.0 40.0 | H 1.230 | V 0.798 | pL -0.059 | vL 0.004 | ∇ 0.092\n",
      "U 52 | F 106496 | FPS 2374 | D 36 | rR:μσmM 0.90 0.04 0.77 0.98 | F:μσmM 15.3 6.2 4.0 37.0 | H 1.217 | V 0.823 | pL -0.027 | vL 0.003 | ∇ 0.072\n",
      "U 53 | F 108544 | FPS 2459 | D 37 | rR:μσmM 0.91 0.04 0.71 0.98 | F:μσmM 14.0 6.7 3.0 46.0 | H 1.177 | V 0.821 | pL -0.046 | vL 0.004 | ∇ 0.099\n",
      "U 54 | F 110592 | FPS 2523 | D 38 | rR:μσmM 0.92 0.03 0.78 0.98 | F:μσmM 12.2 5.4 3.0 35.0 | H 1.055 | V 0.846 | pL -0.067 | vL 0.002 | ∇ 0.097\n",
      "U 55 | F 112640 | FPS 2833 | D 39 | rR:μσmM 0.92 0.03 0.79 0.99 | F:μσmM 13.0 5.5 2.0 33.0 | H 1.118 | V 0.840 | pL -0.019 | vL 0.002 | ∇ 0.066\n",
      "U 56 | F 114688 | FPS 2722 | D 40 | rR:μσmM 0.92 0.03 0.79 0.98 | F:μσmM 13.0 5.1 3.0 34.0 | H 1.238 | V 0.853 | pL 0.035 | vL 0.002 | ∇ 0.055\n",
      "U 57 | F 116736 | FPS 2881 | D 40 | rR:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 13.9 6.2 3.0 35.0 | H 1.268 | V 0.831 | pL -0.000 | vL 0.004 | ∇ 0.115\n",
      "U 58 | F 118784 | FPS 2865 | D 41 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.9 6.7 3.0 34.0 | H 1.333 | V 0.822 | pL 0.045 | vL 0.003 | ∇ 0.066\n",
      "U 59 | F 120832 | FPS 2896 | D 42 | rR:μσmM 0.90 0.05 0.68 0.98 | F:μσmM 16.5 8.6 3.0 51.0 | H 1.295 | V 0.802 | pL 0.011 | vL 0.005 | ∇ 0.106\n",
      "Number of frames:  122880\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 1439.0 | FPS 3977 | D 0.0 | R:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 14.4 6.3 3.0 35.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim, num_units = args.num_units, k = args.k)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status (TEST for CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "envs = make_envs(args.env, args.procs, args.seed)\n",
    "\n",
    "algo.env = envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 51 | F 104448 | FPS 2588 | D 0 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.509 | V 0.490 | pL 0.217 | vL 0.010 | ∇ 0.239\n",
      "U 52 | F 106496 | FPS 3027 | D 1 | rR:μσmM 0.03 0.10 0.00 0.43 | F:μσmM 14.4 55.7 0.0 230.0 | H 1.523 | V 0.365 | pL 0.173 | vL 0.005 | ∇ 0.132\n",
      "U 53 | F 108544 | FPS 2680 | D 2 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 345.4 38.8 230.0 360.0 | H 1.705 | V 0.162 | pL 0.196 | vL 0.009 | ∇ 0.151\n",
      "U 54 | F 110592 | FPS 2925 | D 2 | rR:μσmM 0.07 0.18 0.00 0.70 | F:μσmM 338.6 61.5 121.0 360.0 | H 1.784 | V 0.130 | pL 0.047 | vL 0.003 | ∇ 0.050\n",
      "U 55 | F 112640 | FPS 2558 | D 3 | rR:μσmM 0.07 0.19 0.00 0.70 | F:μσmM 336.8 64.2 121.0 360.0 | H 1.839 | V 0.089 | pL 0.040 | vL 0.001 | ∇ 0.029\n",
      "U 56 | F 114688 | FPS 3023 | D 4 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 346.1 37.5 228.0 360.0 | H 1.870 | V 0.054 | pL 0.037 | vL 0.001 | ∇ 0.024\n",
      "U 57 | F 116736 | FPS 2580 | D 5 | rR:μσmM 0.09 0.20 0.00 0.71 | F:μσmM 330.8 67.2 114.0 360.0 | H 1.873 | V 0.066 | pL -0.006 | vL 0.004 | ∇ 0.043\n",
      "U 58 | F 118784 | FPS 2783 | D 5 | rR:μσmM 0.21 0.24 0.00 0.71 | F:μσmM 294.8 76.4 114.0 360.0 | H 1.893 | V 0.063 | pL 0.003 | vL 0.003 | ∇ 0.042\n",
      "U 59 | F 120832 | FPS 3068 | D 6 | rR:μσmM 0.23 0.29 0.00 0.94 | F:μσmM 286.1 100.3 26.0 360.0 | H 1.885 | V 0.043 | pL 0.018 | vL 0.005 | ∇ 0.059\n",
      "U 60 | F 122880 | FPS 3192 | D 7 | rR:μσmM 0.20 0.28 0.00 0.94 | F:μσmM 300.9 97.1 26.0 360.0 | H 1.903 | V 0.053 | pL -0.011 | vL 0.005 | ∇ 0.044\n",
      "Status saved\n",
      "U 61 | F 124928 | FPS 3163 | D 7 | rR:μσmM 0.20 0.29 0.00 0.94 | F:μσmM 299.1 101.2 26.0 360.0 | H 1.918 | V 0.043 | pL 0.002 | vL 0.002 | ∇ 0.039\n",
      "U 62 | F 126976 | FPS 3109 | D 8 | rR:μσmM 0.27 0.30 0.00 0.75 | F:μσmM 273.9 101.1 98.0 360.0 | H 1.909 | V 0.100 | pL -0.047 | vL 0.011 | ∇ 0.077\n",
      "U 63 | F 129024 | FPS 3308 | D 9 | rR:μσmM 0.35 0.31 0.00 0.76 | F:μσmM 244.1 106.7 94.0 360.0 | H 1.895 | V 0.108 | pL 0.001 | vL 0.008 | ∇ 0.065\n",
      "U 64 | F 131072 | FPS 3268 | D 9 | rR:μσmM 0.54 0.31 0.00 0.88 | F:μσmM 180.8 114.8 46.0 360.0 | H 1.859 | V 0.161 | pL -0.054 | vL 0.022 | ∇ 0.097\n",
      "U 65 | F 133120 | FPS 3290 | D 10 | rR:μσmM 0.47 0.35 0.00 0.88 | F:μσmM 205.5 129.0 46.0 360.0 | H 1.886 | V 0.147 | pL 0.005 | vL 0.011 | ∇ 0.072\n",
      "U 66 | F 135168 | FPS 2980 | D 11 | rR:μσmM 0.44 0.33 0.00 0.93 | F:μσmM 218.2 121.7 30.0 360.0 | H 1.868 | V 0.140 | pL 0.007 | vL 0.012 | ∇ 0.078\n",
      "U 67 | F 137216 | FPS 3352 | D 11 | rR:μσmM 0.34 0.33 0.00 0.93 | F:μσmM 250.4 115.3 30.0 360.0 | H 1.860 | V 0.141 | pL 0.033 | vL 0.009 | ∇ 0.078\n",
      "U 68 | F 139264 | FPS 3286 | D 12 | rR:μσmM 0.50 0.35 0.00 0.93 | F:μσmM 191.2 125.2 28.0 360.0 | H 1.849 | V 0.166 | pL -0.010 | vL 0.013 | ∇ 0.110\n",
      "U 69 | F 141312 | FPS 3231 | D 13 | rR:μσmM 0.54 0.31 0.00 0.93 | F:μσmM 176.3 110.3 29.0 360.0 | H 1.801 | V 0.204 | pL -0.032 | vL 0.016 | ∇ 0.115\n",
      "U 70 | F 143360 | FPS 3211 | D 13 | rR:μσmM 0.60 0.28 0.00 0.89 | F:μσmM 153.9 102.6 45.0 360.0 | H 1.815 | V 0.210 | pL -0.039 | vL 0.018 | ∇ 0.149\n",
      "Status saved\n",
      "U 71 | F 145408 | FPS 3197 | D 14 | rR:μσmM 0.60 0.30 0.00 0.93 | F:μσmM 155.9 108.5 27.0 360.0 | H 1.806 | V 0.262 | pL -0.014 | vL 0.015 | ∇ 0.130\n",
      "U 72 | F 147456 | FPS 3215 | D 15 | rR:μσmM 0.55 0.29 0.00 0.94 | F:μσmM 173.8 108.1 23.0 360.0 | H 1.801 | V 0.248 | pL 0.022 | vL 0.014 | ∇ 0.119\n",
      "U 73 | F 149504 | FPS 3235 | D 15 | rR:μσmM 0.55 0.34 0.00 0.89 | F:μσmM 170.3 121.2 42.0 360.0 | H 1.771 | V 0.314 | pL 0.021 | vL 0.020 | ∇ 0.142\n",
      "U 74 | F 151552 | FPS 3259 | D 16 | rR:μσmM 0.66 0.27 0.00 0.94 | F:μσmM 131.6 102.5 22.0 360.0 | H 1.742 | V 0.306 | pL -0.008 | vL 0.016 | ∇ 0.099\n",
      "U 75 | F 153600 | FPS 3020 | D 16 | rR:μσmM 0.74 0.21 0.00 0.93 | F:μσmM 101.8 78.1 30.0 360.0 | H 1.739 | V 0.378 | pL -0.074 | vL 0.022 | ∇ 0.186\n",
      "U 76 | F 155648 | FPS 3174 | D 17 | rR:μσmM 0.74 0.21 0.00 0.97 | F:μσmM 101.7 79.4 13.0 360.0 | H 1.713 | V 0.408 | pL -0.011 | vL 0.024 | ∇ 0.137\n",
      "U 77 | F 157696 | FPS 3180 | D 18 | rR:μσmM 0.83 0.12 0.49 0.95 | F:μσmM 69.0 48.5 19.0 206.0 | H 1.693 | V 0.443 | pL -0.036 | vL 0.018 | ∇ 0.151\n",
      "U 78 | F 159744 | FPS 2693 | D 19 | rR:μσmM 0.75 0.24 0.00 0.95 | F:μσmM 97.1 89.7 18.0 360.0 | H 1.681 | V 0.461 | pL 0.010 | vL 0.023 | ∇ 0.154\n",
      "U 79 | F 161792 | FPS 2871 | D 19 | rR:μσmM 0.79 0.13 0.36 0.94 | F:μσmM 83.7 53.7 25.0 255.0 | H 1.648 | V 0.483 | pL -0.026 | vL 0.013 | ∇ 0.104\n",
      "U 80 | F 163840 | FPS 2931 | D 20 | rR:μσmM 0.83 0.13 0.29 0.96 | F:μσmM 69.1 52.1 14.0 285.0 | H 1.590 | V 0.509 | pL -0.035 | vL 0.016 | ∇ 0.151\n",
      "Status saved\n",
      "U 81 | F 165888 | FPS 3028 | D 21 | rR:μσmM 0.84 0.08 0.66 0.96 | F:μσmM 64.1 30.0 17.0 137.0 | H 1.620 | V 0.519 | pL -0.026 | vL 0.016 | ∇ 0.158\n",
      "U 82 | F 167936 | FPS 2507 | D 21 | rR:μσmM 0.83 0.10 0.58 0.96 | F:μσmM 69.0 41.8 16.0 166.0 | H 1.650 | V 0.537 | pL -0.033 | vL 0.012 | ∇ 0.174\n",
      "U 83 | F 169984 | FPS 2630 | D 22 | rR:μσmM 0.83 0.10 0.56 0.94 | F:μσmM 66.2 38.5 22.0 178.0 | H 1.594 | V 0.569 | pL -0.005 | vL 0.014 | ∇ 0.126\n",
      "U 84 | F 172032 | FPS 2977 | D 23 | rR:μσmM 0.88 0.07 0.57 0.97 | F:μσmM 49.6 29.8 12.0 171.0 | H 1.642 | V 0.617 | pL -0.018 | vL 0.012 | ∇ 0.173\n",
      "U 85 | F 174080 | FPS 2920 | D 24 | rR:μσmM 0.86 0.10 0.48 0.97 | F:μσmM 55.2 41.6 12.0 208.0 | H 1.568 | V 0.599 | pL -0.004 | vL 0.016 | ∇ 0.154\n",
      "U 86 | F 176128 | FPS 3135 | D 24 | rR:μσmM 0.86 0.08 0.57 0.97 | F:μσmM 55.0 32.1 12.0 173.0 | H 1.584 | V 0.618 | pL -0.073 | vL 0.011 | ∇ 0.151\n",
      "U 87 | F 178176 | FPS 3100 | D 25 | rR:μσmM 0.89 0.05 0.76 0.96 | F:μσmM 45.6 19.4 17.0 95.0 | H 1.481 | V 0.680 | pL -0.009 | vL 0.008 | ∇ 0.134\n",
      "U 88 | F 180224 | FPS 3202 | D 26 | rR:μσmM 0.89 0.06 0.76 0.98 | F:μσmM 43.7 23.4 10.0 97.0 | H 1.531 | V 0.667 | pL 0.020 | vL 0.007 | ∇ 0.098\n",
      "U 89 | F 182272 | FPS 3248 | D 26 | rR:μσmM 0.89 0.06 0.69 0.95 | F:μσmM 45.1 25.9 18.0 122.0 | H 1.528 | V 0.673 | pL 0.001 | vL 0.009 | ∇ 0.134\n",
      "U 90 | F 184320 | FPS 3244 | D 27 | rR:μσmM 0.89 0.07 0.63 0.98 | F:μσmM 42.4 28.8 10.0 146.0 | H 1.550 | V 0.689 | pL 0.022 | vL 0.009 | ∇ 0.136\n",
      "Status saved\n",
      "U 91 | F 186368 | FPS 3229 | D 28 | rR:μσmM 0.89 0.05 0.74 0.96 | F:μσmM 43.3 19.6 14.0 104.0 | H 1.536 | V 0.731 | pL 0.019 | vL 0.004 | ∇ 0.074\n",
      "U 92 | F 188416 | FPS 2948 | D 28 | rR:μσmM 0.90 0.05 0.67 0.97 | F:μσmM 42.0 20.7 11.0 134.0 | H 1.544 | V 0.671 | pL 0.035 | vL 0.011 | ∇ 0.134\n",
      "U 93 | F 190464 | FPS 3098 | D 29 | rR:μσmM 0.90 0.05 0.72 0.98 | F:μσmM 38.2 20.2 10.0 112.0 | H 1.539 | V 0.644 | pL 0.002 | vL 0.010 | ∇ 0.115\n",
      "U 94 | F 192512 | FPS 3155 | D 30 | rR:μσmM 0.86 0.17 0.00 0.97 | F:μσmM 54.6 63.1 11.0 360.0 | H 1.535 | V 0.638 | pL 0.001 | vL 0.015 | ∇ 0.187\n",
      "U 95 | F 194560 | FPS 3110 | D 30 | rR:μσmM 0.90 0.06 0.56 0.96 | F:μσmM 39.6 25.7 17.0 178.0 | H 1.515 | V 0.676 | pL 0.009 | vL 0.009 | ∇ 0.120\n",
      "U 96 | F 196608 | FPS 3222 | D 31 | rR:μσmM 0.90 0.08 0.43 0.96 | F:μσmM 39.2 31.2 15.0 228.0 | H 1.502 | V 0.695 | pL -0.002 | vL 0.010 | ∇ 0.126\n",
      "U 97 | F 198656 | FPS 1984 | D 32 | rR:μσmM 0.91 0.05 0.69 0.98 | F:μσmM 35.6 21.4 10.0 126.0 | H 1.439 | V 0.704 | pL -0.023 | vL 0.008 | ∇ 0.101\n",
      "U 98 | F 200704 | FPS 2849 | D 33 | rR:μσmM 0.91 0.08 0.33 0.97 | F:μσmM 35.4 31.5 12.0 269.0 | H 1.382 | V 0.750 | pL -0.048 | vL 0.007 | ∇ 0.124\n",
      "U 99 | F 202752 | FPS 2904 | D 33 | rR:μσmM 0.93 0.04 0.78 0.97 | F:μσmM 29.8 14.4 12.0 87.0 | H 1.358 | V 0.752 | pL -0.043 | vL 0.006 | ∇ 0.104\n",
      "Number of frames:  204800\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "args.env = env_id\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 3686.0 | FPS 2420 | D 1.0 | R:μσmM 0.91 0.04 0.73 0.97 | F:μσmM 36.9 16.9 12.0 107.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 5632.0 | FPS 3792 | D 1.0 | R:μσmM 0.65 0.37 0.00 0.98 | F:μσmM 52.2 53.7 3.0 144.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 3rd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 91 | F 186368 | FPS 2537 | D 0 | rR:μσmM 0.31 0.41 0.00 0.93 | F:μσmM 21.8 33.9 0.0 121.0 | H 1.700 | V 0.490 | pL 0.162 | vL 0.016 | ∇ 0.172\n",
      "U 92 | F 188416 | FPS 3129 | D 1 | rR:μσmM 0.45 0.38 0.00 0.93 | F:μσmM 64.0 75.4 0.0 252.0 | H 1.712 | V 0.366 | pL 0.161 | vL 0.008 | ∇ 0.150\n",
      "U 93 | F 190464 | FPS 3103 | D 2 | rR:μσmM 0.17 0.27 0.00 0.78 | F:μσmM 272.6 83.4 78.0 324.0 | H 1.752 | V 0.213 | pL 0.151 | vL 0.012 | ∇ 0.146\n",
      "U 94 | F 192512 | FPS 3132 | D 2 | rR:μσmM 0.24 0.27 0.00 0.63 | F:μσmM 254.1 80.6 134.0 324.0 | H 1.712 | V 0.207 | pL 0.025 | vL 0.005 | ∇ 0.064\n",
      "U 95 | F 194560 | FPS 3132 | D 3 | rR:μσmM 0.30 0.28 0.00 0.71 | F:μσmM 235.4 83.4 104.0 324.0 | H 1.755 | V 0.140 | pL 0.058 | vL 0.003 | ∇ 0.059\n",
      "U 96 | F 196608 | FPS 3109 | D 4 | rR:μσmM 0.21 0.25 0.00 0.71 | F:μσmM 266.6 73.5 104.0 324.0 | H 1.801 | V 0.136 | pL 0.012 | vL 0.007 | ∇ 0.061\n",
      "U 97 | F 198656 | FPS 3052 | D 4 | rR:μσmM 0.42 0.31 0.00 0.90 | F:μσmM 200.2 98.0 36.0 324.0 | H 1.790 | V 0.145 | pL -0.003 | vL 0.011 | ∇ 0.083\n",
      "U 98 | F 200704 | FPS 2894 | D 5 | rR:μσmM 0.39 0.33 0.00 0.90 | F:μσmM 208.8 106.2 36.0 324.0 | H 1.805 | V 0.117 | pL 0.016 | vL 0.006 | ∇ 0.054\n",
      "U 99 | F 202752 | FPS 3106 | D 6 | rR:μσmM 0.31 0.31 0.00 0.79 | F:μσmM 233.8 97.1 75.0 324.0 | H 1.792 | V 0.127 | pL -0.010 | vL 0.011 | ∇ 0.071\n",
      "U 100 | F 204800 | FPS 3148 | D 6 | rR:μσmM 0.34 0.32 0.00 0.77 | F:μσmM 223.2 99.9 84.0 324.0 | H 1.781 | V 0.117 | pL 0.008 | vL 0.007 | ∇ 0.066\n",
      "Status saved\n",
      "U 101 | F 206848 | FPS 3120 | D 7 | rR:μσmM 0.36 0.29 0.00 0.74 | F:μσmM 218.8 91.2 94.0 324.0 | H 1.822 | V 0.071 | pL 0.029 | vL 0.002 | ∇ 0.038\n",
      "U 102 | F 208896 | FPS 3072 | D 8 | rR:μσmM 0.21 0.27 0.00 0.80 | F:μσmM 263.8 80.4 71.0 324.0 | H 1.847 | V 0.074 | pL -0.000 | vL 0.008 | ∇ 0.060\n",
      "U 103 | F 210944 | FPS 3104 | D 8 | rR:μσmM 0.27 0.30 0.00 0.80 | F:μσmM 245.6 90.6 71.0 324.0 | H 1.839 | V 0.073 | pL -0.003 | vL 0.007 | ∇ 0.053\n",
      "U 104 | F 212992 | FPS 3113 | D 9 | rR:μσmM 0.29 0.26 0.00 0.71 | F:μσmM 240.5 78.2 105.0 324.0 | H 1.860 | V 0.073 | pL 0.002 | vL 0.004 | ∇ 0.044\n",
      "U 105 | F 215040 | FPS 3138 | D 10 | rR:μσmM 0.30 0.28 0.00 0.82 | F:μσmM 236.1 86.2 65.0 324.0 | H 1.866 | V 0.094 | pL -0.019 | vL 0.007 | ∇ 0.052\n",
      "U 106 | F 217088 | FPS 3115 | D 10 | rR:μσmM 0.24 0.28 0.00 0.82 | F:μσmM 254.0 85.8 65.0 324.0 | H 1.880 | V 0.081 | pL 0.013 | vL 0.004 | ∇ 0.038\n",
      "U 107 | F 219136 | FPS 3106 | D 11 | rR:μσmM 0.23 0.29 0.00 0.86 | F:μσmM 255.6 90.2 52.0 324.0 | H 1.875 | V 0.071 | pL 0.015 | vL 0.005 | ∇ 0.053\n",
      "U 108 | F 221184 | FPS 3046 | D 12 | rR:μσmM 0.18 0.29 0.00 0.86 | F:μσmM 269.6 91.1 52.0 324.0 | H 1.882 | V 0.050 | pL -0.008 | vL 0.004 | ∇ 0.042\n",
      "U 109 | F 223232 | FPS 3102 | D 12 | rR:μσmM 0.29 0.27 0.00 0.81 | F:μσmM 240.6 80.9 70.0 324.0 | H 1.849 | V 0.097 | pL -0.024 | vL 0.009 | ∇ 0.068\n",
      "U 110 | F 225280 | FPS 3145 | D 13 | rR:μσmM 0.38 0.27 0.00 0.81 | F:μσmM 215.0 84.0 70.0 324.0 | H 1.860 | V 0.104 | pL 0.005 | vL 0.006 | ∇ 0.058\n",
      "Status saved\n",
      "U 111 | F 227328 | FPS 3140 | D 14 | rR:μσmM 0.28 0.30 0.00 0.78 | F:μσmM 244.1 94.5 79.0 324.0 | H 1.847 | V 0.097 | pL -0.007 | vL 0.011 | ∇ 0.065\n",
      "U 112 | F 229376 | FPS 3021 | D 14 | rR:μσmM 0.31 0.29 0.00 0.78 | F:μσmM 233.3 91.2 79.0 324.0 | H 1.849 | V 0.102 | pL -0.003 | vL 0.006 | ∇ 0.053\n",
      "U 113 | F 231424 | FPS 2490 | D 15 | rR:μσmM 0.35 0.27 0.00 0.72 | F:μσmM 223.3 84.2 102.0 324.0 | H 1.863 | V 0.106 | pL 0.005 | vL 0.006 | ∇ 0.051\n",
      "U 114 | F 233472 | FPS 2585 | D 16 | rR:μσmM 0.35 0.30 0.00 0.88 | F:μσmM 219.1 93.2 45.0 324.0 | H 1.875 | V 0.080 | pL 0.006 | vL 0.007 | ∇ 0.048\n",
      "U 115 | F 235520 | FPS 2715 | D 17 | rR:μσmM 0.30 0.36 0.00 0.93 | F:μσmM 232.6 114.4 24.0 324.0 | H 1.869 | V 0.098 | pL -0.009 | vL 0.012 | ∇ 0.054\n",
      "U 116 | F 237568 | FPS 1575 | D 18 | rR:μσmM 0.28 0.34 0.00 0.93 | F:μσmM 242.2 106.4 24.0 324.0 | H 1.878 | V 0.080 | pL 0.013 | vL 0.003 | ∇ 0.039\n",
      "U 117 | F 239616 | FPS 2600 | D 19 | rR:μσmM 0.17 0.21 0.00 0.57 | F:μσmM 279.6 61.5 153.0 324.0 | H 1.886 | V 0.067 | pL 0.016 | vL 0.003 | ∇ 0.042\n",
      "U 118 | F 241664 | FPS 2229 | D 20 | rR:μσmM 0.31 0.32 0.00 0.85 | F:μσmM 231.2 100.4 53.0 324.0 | H 1.854 | V 0.108 | pL -0.026 | vL 0.011 | ∇ 0.071\n",
      "U 119 | F 243712 | FPS 2463 | D 21 | rR:μσmM 0.31 0.34 0.00 0.85 | F:μσmM 229.0 107.2 53.0 324.0 | H 1.872 | V 0.085 | pL 0.003 | vL 0.006 | ∇ 0.057\n",
      "U 120 | F 245760 | FPS 2843 | D 21 | rR:μσmM 0.27 0.30 0.00 0.79 | F:μσmM 246.0 92.5 74.0 324.0 | H 1.875 | V 0.081 | pL 0.010 | vL 0.005 | ∇ 0.047\n",
      "Status saved\n",
      "U 121 | F 247808 | FPS 3000 | D 22 | rR:μσmM 0.22 0.29 0.00 0.78 | F:μσmM 261.0 89.2 80.0 324.0 | H 1.885 | V 0.072 | pL 0.006 | vL 0.003 | ∇ 0.041\n",
      "U 122 | F 249856 | FPS 3083 | D 23 | rR:μσmM 0.15 0.25 0.00 0.74 | F:μσmM 280.4 75.3 95.0 324.0 | H 1.885 | V 0.045 | pL 0.015 | vL 0.001 | ∇ 0.037\n",
      "U 123 | F 251904 | FPS 3027 | D 23 | rR:μσmM 0.16 0.25 0.00 0.74 | F:μσmM 279.4 74.2 95.0 324.0 | H 1.887 | V 0.068 | pL -0.003 | vL 0.005 | ∇ 0.040\n",
      "U 124 | F 253952 | FPS 2508 | D 24 | rR:μσmM 0.12 0.20 0.00 0.58 | F:μσmM 292.5 58.2 150.0 324.0 | H 1.898 | V 0.049 | pL 0.008 | vL 0.001 | ∇ 0.023\n",
      "U 125 | F 256000 | FPS 2228 | D 25 | rR:μσmM 0.20 0.26 0.00 0.82 | F:μσmM 269.4 81.2 64.0 324.0 | H 1.883 | V 0.054 | pL -0.007 | vL 0.004 | ∇ 0.038\n",
      "U 126 | F 258048 | FPS 2726 | D 26 | rR:μσmM 0.26 0.28 0.00 0.87 | F:μσmM 251.9 88.3 47.0 324.0 | H 1.877 | V 0.078 | pL -0.020 | vL 0.010 | ∇ 0.057\n",
      "U 127 | F 260096 | FPS 3039 | D 27 | rR:μσmM 0.35 0.37 0.00 0.88 | F:μσmM 215.3 118.3 43.0 324.0 | H 1.868 | V 0.068 | pL -0.024 | vL 0.012 | ∇ 0.059\n",
      "U 128 | F 262144 | FPS 3120 | D 27 | rR:μσmM 0.34 0.36 0.00 0.88 | F:μσmM 217.9 113.3 43.0 324.0 | H 1.891 | V 0.051 | pL 0.009 | vL 0.002 | ∇ 0.029\n",
      "U 129 | F 264192 | FPS 3209 | D 28 | rR:μσmM 0.20 0.29 0.00 0.78 | F:μσmM 265.1 87.1 80.0 324.0 | H 1.882 | V 0.059 | pL -0.006 | vL 0.007 | ∇ 0.047\n",
      "U 130 | F 266240 | FPS 2635 | D 29 | rR:μσmM 0.22 0.27 0.00 0.78 | F:μσmM 259.6 82.4 80.0 324.0 | H 1.868 | V 0.083 | pL -0.015 | vL 0.007 | ∇ 0.051\n",
      "Status saved\n",
      "U 131 | F 268288 | FPS 3019 | D 29 | rR:μσmM 0.28 0.28 0.00 0.78 | F:μσmM 243.3 84.2 80.0 324.0 | H 1.875 | V 0.076 | pL -0.013 | vL 0.005 | ∇ 0.046\n",
      "U 132 | F 270336 | FPS 3075 | D 30 | rR:μσmM 0.37 0.31 0.00 0.85 | F:μσmM 217.0 97.9 53.0 324.0 | H 1.861 | V 0.109 | pL -0.038 | vL 0.013 | ∇ 0.074\n",
      "U 133 | F 272384 | FPS 3060 | D 31 | rR:μσmM 0.34 0.36 0.00 0.85 | F:μσmM 220.1 112.9 53.0 324.0 | H 1.857 | V 0.096 | pL 0.005 | vL 0.008 | ∇ 0.057\n",
      "U 134 | F 274432 | FPS 3001 | D 31 | rR:μσmM 0.34 0.33 0.00 0.82 | F:μσmM 220.9 100.9 63.0 324.0 | H 1.842 | V 0.125 | pL -0.030 | vL 0.011 | ∇ 0.074\n",
      "U 135 | F 276480 | FPS 2487 | D 32 | rR:μσmM 0.38 0.32 0.00 0.82 | F:μσmM 208.0 98.1 63.0 324.0 | H 1.848 | V 0.122 | pL -0.006 | vL 0.009 | ∇ 0.077\n",
      "U 136 | F 278528 | FPS 2184 | D 33 | rR:μσmM 0.39 0.31 0.00 0.84 | F:μσmM 208.7 98.7 56.0 324.0 | H 1.829 | V 0.117 | pL 0.002 | vL 0.013 | ∇ 0.077\n",
      "U 137 | F 280576 | FPS 2514 | D 34 | rR:μσmM 0.38 0.32 0.00 0.84 | F:μσmM 211.1 101.5 56.0 324.0 | H 1.834 | V 0.130 | pL -0.018 | vL 0.011 | ∇ 0.061\n",
      "U 138 | F 282624 | FPS 2362 | D 35 | rR:μσmM 0.43 0.33 0.00 0.89 | F:μσmM 192.6 105.7 38.0 324.0 | H 1.837 | V 0.137 | pL -0.007 | vL 0.012 | ∇ 0.081\n",
      "U 139 | F 284672 | FPS 2785 | D 36 | rR:μσmM 0.53 0.22 0.00 0.89 | F:μσmM 165.2 73.3 39.0 324.0 | H 1.813 | V 0.212 | pL -0.043 | vL 0.023 | ∇ 0.102\n",
      "U 140 | F 286720 | FPS 3023 | D 36 | rR:μσmM 0.59 0.28 0.00 0.89 | F:μσmM 142.1 90.3 39.0 324.0 | H 1.803 | V 0.204 | pL 0.001 | vL 0.013 | ∇ 0.089\n",
      "Status saved\n",
      "U 141 | F 288768 | FPS 3136 | D 37 | rR:μσmM 0.54 0.25 0.00 0.89 | F:μσmM 165.1 86.1 40.0 324.0 | H 1.781 | V 0.253 | pL -0.037 | vL 0.016 | ∇ 0.101\n",
      "U 142 | F 290816 | FPS 3061 | D 38 | rR:μσmM 0.68 0.17 0.20 0.90 | F:μσmM 114.9 61.1 37.0 287.0 | H 1.787 | V 0.254 | pL -0.020 | vL 0.016 | ∇ 0.083\n",
      "U 143 | F 292864 | FPS 2740 | D 38 | rR:μσmM 0.54 0.35 0.00 0.92 | F:μσmM 154.9 112.3 29.0 324.0 | H 1.783 | V 0.230 | pL 0.021 | vL 0.017 | ∇ 0.093\n",
      "U 144 | F 294912 | FPS 2543 | D 39 | rR:μσmM 0.62 0.30 0.00 0.92 | F:μσmM 132.1 97.7 30.0 324.0 | H 1.793 | V 0.207 | pL -0.001 | vL 0.012 | ∇ 0.081\n",
      "U 145 | F 296960 | FPS 2696 | D 40 | rR:μσmM 0.38 0.31 0.00 0.86 | F:μσmM 213.2 99.0 49.0 324.0 | H 1.811 | V 0.184 | pL 0.017 | vL 0.015 | ∇ 0.078\n",
      "U 146 | F 299008 | FPS 2174 | D 41 | rR:μσmM 0.60 0.29 0.00 0.88 | F:μσmM 140.4 93.9 42.0 324.0 | H 1.794 | V 0.194 | pL 0.006 | vL 0.013 | ∇ 0.088\n",
      "U 147 | F 301056 | FPS 2351 | D 42 | rR:μσmM 0.43 0.33 0.00 0.88 | F:μσmM 195.1 106.0 42.0 324.0 | H 1.807 | V 0.165 | pL 0.010 | vL 0.015 | ∇ 0.087\n",
      "U 148 | F 303104 | FPS 3050 | D 42 | rR:μσmM 0.47 0.36 0.00 0.91 | F:μσmM 179.6 114.5 32.0 324.0 | H 1.772 | V 0.185 | pL 0.003 | vL 0.015 | ∇ 0.093\n",
      "U 149 | F 305152 | FPS 3033 | D 43 | rR:μσmM 0.41 0.34 0.00 0.78 | F:μσmM 199.6 108.1 80.0 324.0 | H 1.763 | V 0.183 | pL 0.004 | vL 0.016 | ∇ 0.092\n",
      "U 150 | F 307200 | FPS 3055 | D 44 | rR:μσmM 0.53 0.34 0.00 0.93 | F:μσmM 160.9 111.2 25.0 324.0 | H 1.760 | V 0.215 | pL -0.044 | vL 0.021 | ∇ 0.104\n",
      "Status saved\n",
      "U 151 | F 309248 | FPS 3065 | D 44 | rR:μσmM 0.63 0.25 0.00 0.92 | F:μσmM 130.9 85.4 30.0 324.0 | H 1.753 | V 0.259 | pL -0.062 | vL 0.026 | ∇ 0.140\n",
      "U 152 | F 311296 | FPS 2699 | D 45 | rR:μσmM 0.64 0.31 0.00 0.90 | F:μσmM 123.9 99.7 37.0 324.0 | H 1.767 | V 0.287 | pL 0.003 | vL 0.020 | ∇ 0.107\n",
      "U 153 | F 313344 | FPS 2799 | D 46 | rR:μσmM 0.56 0.32 0.00 0.90 | F:μσmM 152.7 103.8 37.0 324.0 | H 1.764 | V 0.263 | pL 0.014 | vL 0.016 | ∇ 0.098\n",
      "U 154 | F 315392 | FPS 3044 | D 47 | rR:μσmM 0.62 0.27 0.00 0.92 | F:μσmM 132.1 87.9 28.0 324.0 | H 1.783 | V 0.232 | pL 0.018 | vL 0.011 | ∇ 0.085\n",
      "U 155 | F 317440 | FPS 2987 | D 47 | rR:μσmM 0.46 0.33 0.00 0.86 | F:μσmM 185.3 104.9 52.0 324.0 | H 1.818 | V 0.206 | pL 0.020 | vL 0.015 | ∇ 0.084\n",
      "U 156 | F 319488 | FPS 2900 | D 48 | rR:μσmM 0.54 0.31 0.00 0.86 | F:μσmM 158.9 96.8 51.0 324.0 | H 1.775 | V 0.291 | pL -0.033 | vL 0.016 | ∇ 0.102\n",
      "U 157 | F 321536 | FPS 2896 | D 49 | rR:μσmM 0.59 0.26 0.00 0.83 | F:μσmM 143.0 84.5 60.0 324.0 | H 1.798 | V 0.228 | pL 0.022 | vL 0.011 | ∇ 0.070\n",
      "U 158 | F 323584 | FPS 2804 | D 49 | rR:μσmM 0.49 0.26 0.00 0.86 | F:μσmM 178.4 85.6 52.0 324.0 | H 1.802 | V 0.217 | pL 0.004 | vL 0.015 | ∇ 0.080\n",
      "U 159 | F 325632 | FPS 2957 | D 50 | rR:μσmM 0.54 0.32 0.00 0.91 | F:μσmM 159.4 103.2 33.0 324.0 | H 1.773 | V 0.238 | pL -0.022 | vL 0.019 | ∇ 0.101\n",
      "U 160 | F 327680 | FPS 3108 | D 51 | rR:μσmM 0.67 0.22 0.00 0.89 | F:μσmM 117.3 74.5 38.0 324.0 | H 1.747 | V 0.255 | pL -0.020 | vL 0.014 | ∇ 0.100\n",
      "Status saved\n",
      "U 161 | F 329728 | FPS 3019 | D 51 | rR:μσmM 0.60 0.25 0.00 0.85 | F:μσmM 139.0 78.5 55.0 324.0 | H 1.755 | V 0.248 | pL 0.007 | vL 0.017 | ∇ 0.136\n",
      "U 162 | F 331776 | FPS 2993 | D 52 | rR:μσmM 0.61 0.28 0.00 0.94 | F:μσmM 136.8 94.3 23.0 324.0 | H 1.730 | V 0.308 | pL -0.007 | vL 0.019 | ∇ 0.120\n",
      "U 163 | F 333824 | FPS 2775 | D 53 | rR:μσmM 0.60 0.28 0.00 0.93 | F:μσmM 141.2 92.6 27.0 324.0 | H 1.748 | V 0.295 | pL -0.005 | vL 0.015 | ∇ 0.096\n",
      "U 164 | F 335872 | FPS 2322 | D 54 | rR:μσmM 0.71 0.14 0.38 0.88 | F:μσmM 103.7 51.8 42.0 224.0 | H 1.738 | V 0.320 | pL -0.014 | vL 0.018 | ∇ 0.117\n",
      "U 165 | F 337920 | FPS 2591 | D 55 | rR:μσmM 0.65 0.31 0.00 0.93 | F:μσmM 121.9 102.6 27.0 324.0 | H 1.732 | V 0.314 | pL -0.013 | vL 0.024 | ∇ 0.135\n",
      "U 166 | F 339968 | FPS 2941 | D 55 | rR:μσmM 0.66 0.25 0.00 0.91 | F:μσmM 120.3 84.1 33.0 324.0 | H 1.714 | V 0.338 | pL -0.010 | vL 0.025 | ∇ 0.158\n",
      "U 167 | F 342016 | FPS 3081 | D 56 | rR:μσmM 0.59 0.28 0.00 0.91 | F:μσmM 142.1 91.3 33.0 324.0 | H 1.755 | V 0.255 | pL 0.041 | vL 0.013 | ∇ 0.099\n",
      "U 168 | F 344064 | FPS 3003 | D 57 | rR:μσmM 0.56 0.29 0.00 0.90 | F:μσmM 154.7 96.6 35.0 324.0 | H 1.714 | V 0.283 | pL -0.009 | vL 0.017 | ∇ 0.105\n",
      "U 169 | F 346112 | FPS 3122 | D 57 | rR:μσmM 0.65 0.24 0.00 0.91 | F:μσmM 125.2 80.4 34.0 324.0 | H 1.725 | V 0.290 | pL -0.017 | vL 0.020 | ∇ 0.102\n",
      "U 170 | F 348160 | FPS 2715 | D 58 | rR:μσmM 0.67 0.24 0.00 0.95 | F:μσmM 118.0 81.5 17.0 324.0 | H 1.709 | V 0.260 | pL 0.007 | vL 0.015 | ∇ 0.101\n",
      "Status saved\n",
      "U 171 | F 350208 | FPS 3107 | D 59 | rR:μσmM 0.54 0.36 0.00 0.95 | F:μσmM 158.4 118.7 17.0 324.0 | H 1.775 | V 0.205 | pL 0.050 | vL 0.011 | ∇ 0.071\n",
      "U 172 | F 352256 | FPS 3118 | D 59 | rR:μσmM 0.50 0.33 0.00 0.94 | F:μσmM 174.2 107.6 22.0 324.0 | H 1.763 | V 0.210 | pL -0.008 | vL 0.015 | ∇ 0.108\n",
      "U 173 | F 354304 | FPS 3121 | D 60 | rR:μσmM 0.64 0.32 0.00 0.93 | F:μσmM 126.9 106.2 25.0 324.0 | H 1.698 | V 0.319 | pL -0.053 | vL 0.033 | ∇ 0.180\n",
      "U 174 | F 356352 | FPS 3053 | D 61 | rR:μσmM 0.71 0.17 0.28 0.94 | F:μσmM 103.1 60.7 22.0 258.0 | H 1.743 | V 0.287 | pL 0.009 | vL 0.013 | ∇ 0.097\n",
      "U 175 | F 358400 | FPS 2527 | D 62 | rR:μσmM 0.59 0.29 0.00 0.93 | F:μσmM 143.9 99.0 25.0 324.0 | H 1.753 | V 0.252 | pL 0.021 | vL 0.017 | ∇ 0.097\n",
      "U 176 | F 360448 | FPS 2333 | D 62 | rR:μσmM 0.49 0.31 0.00 0.84 | F:μσmM 175.9 101.8 59.0 324.0 | H 1.756 | V 0.251 | pL 0.027 | vL 0.010 | ∇ 0.096\n",
      "U 177 | F 362496 | FPS 1766 | D 64 | rR:μσmM 0.62 0.32 0.00 0.94 | F:μσmM 131.5 108.8 20.0 324.0 | H 1.720 | V 0.269 | pL -0.018 | vL 0.026 | ∇ 0.125\n",
      "U 178 | F 364544 | FPS 2986 | D 64 | rR:μσmM 0.61 0.28 0.00 0.93 | F:μσmM 139.6 97.1 27.0 324.0 | H 1.738 | V 0.247 | pL 0.000 | vL 0.018 | ∇ 0.117\n",
      "U 179 | F 366592 | FPS 3086 | D 65 | rR:μσmM 0.59 0.22 0.00 0.88 | F:μσmM 144.1 74.5 44.0 324.0 | H 1.722 | V 0.287 | pL -0.022 | vL 0.017 | ∇ 0.106\n",
      "U 180 | F 368640 | FPS 2764 | D 66 | rR:μσmM 0.71 0.24 0.22 0.91 | F:μσmM 106.1 85.4 34.0 280.0 | H 1.737 | V 0.252 | pL 0.007 | vL 0.016 | ∇ 0.093\n",
      "Status saved\n",
      "U 181 | F 370688 | FPS 3022 | D 66 | rR:μσmM 0.51 0.34 0.00 0.89 | F:μσmM 169.4 111.0 40.0 324.0 | H 1.775 | V 0.191 | pL 0.039 | vL 0.012 | ∇ 0.088\n",
      "U 182 | F 372736 | FPS 2773 | D 67 | rR:μσmM 0.56 0.36 0.00 0.92 | F:μσmM 149.3 115.7 29.0 324.0 | H 1.741 | V 0.273 | pL -0.046 | vL 0.022 | ∇ 0.119\n",
      "U 183 | F 374784 | FPS 2942 | D 68 | rR:μσmM 0.70 0.24 0.00 0.94 | F:μσmM 104.1 81.3 22.0 324.0 | H 1.728 | V 0.295 | pL -0.029 | vL 0.023 | ∇ 0.123\n",
      "U 184 | F 376832 | FPS 3114 | D 68 | rR:μσmM 0.55 0.31 0.00 0.93 | F:μσmM 159.2 103.8 27.0 324.0 | H 1.731 | V 0.244 | pL 0.012 | vL 0.017 | ∇ 0.106\n",
      "U 185 | F 378880 | FPS 3098 | D 69 | rR:μσmM 0.61 0.29 0.00 0.89 | F:μσmM 135.3 96.3 40.0 324.0 | H 1.723 | V 0.220 | pL -0.000 | vL 0.019 | ∇ 0.112\n",
      "U 186 | F 380928 | FPS 3147 | D 70 | rR:μσmM 0.57 0.36 0.00 0.94 | F:μσmM 147.2 115.3 20.0 324.0 | H 1.726 | V 0.226 | pL 0.014 | vL 0.017 | ∇ 0.101\n",
      "U 187 | F 382976 | FPS 3140 | D 70 | rR:μσmM 0.54 0.34 0.00 0.89 | F:μσmM 159.8 115.0 39.0 324.0 | H 1.708 | V 0.246 | pL -0.008 | vL 0.022 | ∇ 0.113\n",
      "U 188 | F 385024 | FPS 3086 | D 71 | rR:μσmM 0.71 0.26 0.00 0.93 | F:μσmM 103.6 88.4 26.0 324.0 | H 1.703 | V 0.233 | pL -0.013 | vL 0.021 | ∇ 0.115\n",
      "U 189 | F 387072 | FPS 3130 | D 72 | rR:μσmM 0.59 0.27 0.00 0.93 | F:μσmM 144.6 93.7 27.0 324.0 | H 1.661 | V 0.250 | pL -0.017 | vL 0.021 | ∇ 0.111\n",
      "U 190 | F 389120 | FPS 3140 | D 72 | rR:μσmM 0.71 0.26 0.00 0.95 | F:μσmM 102.2 90.2 19.0 324.0 | H 1.615 | V 0.366 | pL -0.096 | vL 0.032 | ∇ 0.173\n",
      "Status saved\n",
      "U 191 | F 391168 | FPS 3199 | D 73 | rR:μσmM 0.78 0.17 0.25 0.96 | F:μσmM 79.8 61.6 16.0 271.0 | H 1.608 | V 0.392 | pL -0.031 | vL 0.023 | ∇ 0.125\n",
      "U 192 | F 393216 | FPS 3156 | D 74 | rR:μσmM 0.73 0.24 0.00 0.95 | F:μσmM 95.6 81.3 17.0 324.0 | H 1.625 | V 0.397 | pL -0.017 | vL 0.021 | ∇ 0.122\n",
      "U 193 | F 395264 | FPS 3135 | D 74 | rR:μσmM 0.75 0.22 0.00 0.95 | F:μσmM 86.9 74.0 17.0 324.0 | H 1.596 | V 0.422 | pL -0.003 | vL 0.027 | ∇ 0.161\n",
      "U 194 | F 397312 | FPS 3195 | D 75 | rR:μσmM 0.78 0.22 0.00 0.95 | F:μσmM 79.1 74.8 17.0 324.0 | H 1.560 | V 0.455 | pL -0.019 | vL 0.025 | ∇ 0.138\n",
      "U 195 | F 399360 | FPS 3163 | D 76 | rR:μσmM 0.78 0.20 0.00 0.94 | F:μσmM 78.3 68.7 21.0 324.0 | H 1.571 | V 0.469 | pL -0.040 | vL 0.019 | ∇ 0.124\n",
      "U 196 | F 401408 | FPS 3206 | D 76 | rR:μσmM 0.81 0.16 0.40 0.94 | F:μσmM 68.0 57.9 20.0 217.0 | H 1.606 | V 0.427 | pL 0.033 | vL 0.020 | ∇ 0.123\n",
      "U 197 | F 403456 | FPS 3187 | D 77 | rR:μσmM 0.73 0.25 0.00 0.95 | F:μσmM 92.9 83.5 17.0 324.0 | H 1.580 | V 0.410 | pL 0.032 | vL 0.026 | ∇ 0.155\n",
      "U 198 | F 405504 | FPS 3065 | D 78 | rR:μσmM 0.79 0.19 0.00 0.96 | F:μσmM 73.9 65.7 16.0 324.0 | H 1.532 | V 0.483 | pL -0.040 | vL 0.024 | ∇ 0.116\n",
      "U 199 | F 407552 | FPS 3118 | D 78 | rR:μσmM 0.77 0.22 0.00 0.95 | F:μσmM 81.3 73.2 19.0 324.0 | H 1.583 | V 0.435 | pL 0.024 | vL 0.023 | ∇ 0.131\n",
      "U 200 | F 409600 | FPS 3198 | D 79 | rR:μσmM 0.78 0.23 0.00 0.94 | F:μσmM 79.4 77.8 22.0 324.0 | H 1.611 | V 0.443 | pL 0.007 | vL 0.027 | ∇ 0.128\n",
      "Status saved\n",
      "U 201 | F 411648 | FPS 3120 | D 80 | rR:μσmM 0.78 0.17 0.31 0.94 | F:μσmM 79.6 59.4 22.0 247.0 | H 1.594 | V 0.420 | pL 0.015 | vL 0.020 | ∇ 0.120\n",
      "U 202 | F 413696 | FPS 3196 | D 80 | rR:μσmM 0.75 0.24 0.00 0.93 | F:μσmM 89.2 81.9 25.0 324.0 | H 1.605 | V 0.377 | pL 0.034 | vL 0.023 | ∇ 0.124\n",
      "U 203 | F 415744 | FPS 2839 | D 81 | rR:μσmM 0.75 0.17 0.16 0.94 | F:μσmM 91.6 60.0 21.0 302.0 | H 1.573 | V 0.469 | pL -0.045 | vL 0.022 | ∇ 0.133\n",
      "U 204 | F 417792 | FPS 2961 | D 82 | rR:μσmM 0.82 0.19 0.00 0.95 | F:μσmM 63.6 62.4 19.0 324.0 | H 1.594 | V 0.455 | pL -0.004 | vL 0.026 | ∇ 0.140\n",
      "U 205 | F 419840 | FPS 3005 | D 82 | rR:μσmM 0.72 0.20 0.23 0.94 | F:μσmM 99.3 73.6 23.0 276.0 | H 1.666 | V 0.412 | pL 0.020 | vL 0.018 | ∇ 0.142\n",
      "U 206 | F 421888 | FPS 2863 | D 83 | rR:μσmM 0.78 0.18 0.00 0.93 | F:μσmM 77.6 58.6 24.0 324.0 | H 1.626 | V 0.455 | pL -0.034 | vL 0.023 | ∇ 0.148\n",
      "U 207 | F 423936 | FPS 2963 | D 84 | rR:μσmM 0.71 0.25 0.00 0.94 | F:μσmM 103.5 83.8 22.0 324.0 | H 1.669 | V 0.413 | pL 0.035 | vL 0.019 | ∇ 0.130\n",
      "U 208 | F 425984 | FPS 2939 | D 85 | rR:μσmM 0.72 0.18 0.35 0.93 | F:μσmM 100.1 63.7 26.0 234.0 | H 1.694 | V 0.354 | pL 0.053 | vL 0.013 | ∇ 0.103\n",
      "U 209 | F 428032 | FPS 3103 | D 85 | rR:μσmM 0.60 0.28 0.00 0.93 | F:μσmM 142.3 97.9 25.0 324.0 | H 1.706 | V 0.331 | pL 0.023 | vL 0.019 | ∇ 0.129\n",
      "U 210 | F 430080 | FPS 3040 | D 86 | rR:μσmM 0.72 0.24 0.00 0.94 | F:μσmM 98.9 79.6 20.0 324.0 | H 1.670 | V 0.337 | pL 0.003 | vL 0.023 | ∇ 0.133\n",
      "Status saved\n",
      "U 211 | F 432128 | FPS 3095 | D 87 | rR:μσmM 0.68 0.20 0.11 0.91 | F:μσmM 114.1 72.7 33.0 322.0 | H 1.675 | V 0.359 | pL -0.016 | vL 0.019 | ∇ 0.102\n",
      "U 212 | F 434176 | FPS 3001 | D 87 | rR:μσmM 0.67 0.25 0.00 0.90 | F:μσmM 116.6 83.3 35.0 324.0 | H 1.671 | V 0.352 | pL -0.007 | vL 0.020 | ∇ 0.117\n",
      "U 213 | F 436224 | FPS 2960 | D 88 | rR:μσmM 0.71 0.26 0.00 0.92 | F:μσmM 103.6 87.6 30.0 324.0 | H 1.680 | V 0.354 | pL -0.020 | vL 0.025 | ∇ 0.129\n",
      "U 214 | F 438272 | FPS 3014 | D 89 | rR:μσmM 0.74 0.21 0.00 0.91 | F:μσmM 91.8 69.8 33.0 324.0 | H 1.687 | V 0.363 | pL -0.015 | vL 0.019 | ∇ 0.127\n",
      "U 215 | F 440320 | FPS 3122 | D 89 | rR:μσmM 0.71 0.24 0.00 0.93 | F:μσmM 101.0 79.2 27.0 324.0 | H 1.679 | V 0.347 | pL -0.000 | vL 0.022 | ∇ 0.141\n",
      "U 216 | F 442368 | FPS 3000 | D 90 | rR:μσmM 0.60 0.31 0.00 0.93 | F:μσmM 139.3 100.5 25.0 324.0 | H 1.643 | V 0.330 | pL 0.009 | vL 0.021 | ∇ 0.123\n",
      "U 217 | F 444416 | FPS 3227 | D 91 | rR:μσmM 0.74 0.24 0.00 0.93 | F:μσmM 92.6 83.1 26.0 324.0 | H 1.567 | V 0.404 | pL -0.056 | vL 0.027 | ∇ 0.153\n",
      "U 218 | F 446464 | FPS 3183 | D 91 | rR:μσmM 0.84 0.10 0.54 0.96 | F:μσmM 58.7 35.8 16.0 167.0 | H 1.531 | V 0.475 | pL -0.062 | vL 0.027 | ∇ 0.170\n",
      "U 219 | F 448512 | FPS 3018 | D 92 | rR:μσmM 0.81 0.20 0.00 0.96 | F:μσmM 68.0 66.0 16.0 324.0 | H 1.496 | V 0.470 | pL 0.025 | vL 0.024 | ∇ 0.136\n",
      "U 220 | F 450560 | FPS 2983 | D 93 | rR:μσmM 0.74 0.25 0.00 0.96 | F:μσmM 92.9 83.9 16.0 324.0 | H 1.593 | V 0.381 | pL 0.031 | vL 0.019 | ∇ 0.125\n",
      "Status saved\n",
      "U 221 | F 452608 | FPS 2968 | D 93 | rR:μσmM 0.73 0.26 0.00 0.95 | F:μσmM 96.2 87.0 19.0 324.0 | H 1.563 | V 0.412 | pL 0.017 | vL 0.023 | ∇ 0.150\n",
      "U 222 | F 454656 | FPS 2777 | D 94 | rR:μσmM 0.80 0.17 0.21 0.94 | F:μσmM 73.8 59.9 21.0 284.0 | H 1.565 | V 0.460 | pL -0.059 | vL 0.025 | ∇ 0.129\n",
      "U 223 | F 456704 | FPS 2969 | D 95 | rR:μσmM 0.79 0.18 0.00 0.94 | F:μσmM 75.6 60.9 21.0 324.0 | H 1.577 | V 0.486 | pL -0.032 | vL 0.021 | ∇ 0.123\n",
      "U 224 | F 458752 | FPS 2817 | D 95 | rR:μσmM 0.79 0.17 0.20 0.93 | F:μσmM 74.6 62.0 25.0 289.0 | H 1.569 | V 0.492 | pL 0.008 | vL 0.018 | ∇ 0.126\n",
      "U 225 | F 460800 | FPS 2728 | D 96 | rR:μσmM 0.79 0.17 0.24 0.94 | F:μσmM 74.2 62.6 22.0 272.0 | H 1.587 | V 0.450 | pL 0.036 | vL 0.020 | ∇ 0.141\n",
      "U 226 | F 462848 | FPS 2810 | D 97 | rR:μσmM 0.78 0.19 0.26 0.95 | F:μσmM 80.4 66.8 19.0 268.0 | H 1.562 | V 0.460 | pL 0.003 | vL 0.019 | ∇ 0.129\n",
      "U 227 | F 464896 | FPS 2822 | D 98 | rR:μσmM 0.74 0.22 0.00 0.94 | F:μσmM 90.7 75.6 22.0 324.0 | H 1.579 | V 0.436 | pL 0.009 | vL 0.021 | ∇ 0.109\n",
      "U 228 | F 466944 | FPS 3007 | D 98 | rR:μσmM 0.76 0.19 0.00 0.92 | F:μσmM 85.0 64.7 28.0 324.0 | H 1.555 | V 0.466 | pL -0.014 | vL 0.020 | ∇ 0.120\n",
      "U 229 | F 468992 | FPS 3101 | D 99 | rR:μσmM 0.83 0.14 0.32 0.95 | F:μσmM 61.4 48.8 19.0 246.0 | H 1.572 | V 0.448 | pL -0.008 | vL 0.022 | ∇ 0.128\n",
      "U 230 | F 471040 | FPS 3204 | D 100 | rR:μσmM 0.74 0.26 0.00 0.95 | F:μσmM 91.0 85.4 18.0 324.0 | H 1.600 | V 0.389 | pL 0.043 | vL 0.022 | ∇ 0.125\n",
      "Status saved\n",
      "U 231 | F 473088 | FPS 3003 | D 100 | rR:μσmM 0.69 0.26 0.00 0.93 | F:μσmM 108.1 85.1 25.0 324.0 | H 1.597 | V 0.427 | pL -0.002 | vL 0.021 | ∇ 0.132\n",
      "U 232 | F 475136 | FPS 3256 | D 101 | rR:μσmM 0.78 0.17 0.20 0.94 | F:μσmM 80.0 59.9 21.0 287.0 | H 1.618 | V 0.413 | pL -0.004 | vL 0.021 | ∇ 0.113\n",
      "U 233 | F 477184 | FPS 3280 | D 102 | rR:μσmM 0.72 0.23 0.00 0.91 | F:μσmM 101.0 80.5 31.0 324.0 | H 1.604 | V 0.445 | pL -0.038 | vL 0.023 | ∇ 0.116\n",
      "U 234 | F 479232 | FPS 1953 | D 103 | rR:μσmM 0.84 0.08 0.56 0.93 | F:μσmM 56.6 29.0 25.0 160.0 | H 1.581 | V 0.541 | pL -0.059 | vL 0.014 | ∇ 0.098\n",
      "U 235 | F 481280 | FPS 2826 | D 103 | rR:μσmM 0.85 0.08 0.64 0.93 | F:μσmM 55.5 28.4 26.0 128.0 | H 1.558 | V 0.537 | pL -0.004 | vL 0.015 | ∇ 0.093\n",
      "U 236 | F 483328 | FPS 2579 | D 104 | rR:μσmM 0.79 0.18 0.29 0.94 | F:μσmM 74.7 65.1 22.0 254.0 | H 1.550 | V 0.492 | pL 0.025 | vL 0.022 | ∇ 0.110\n",
      "U 237 | F 485376 | FPS 2425 | D 105 | rR:μσmM 0.80 0.13 0.53 0.96 | F:μσmM 71.8 45.0 16.0 170.0 | H 1.590 | V 0.464 | pL 0.006 | vL 0.018 | ∇ 0.104\n",
      "U 238 | F 487424 | FPS 2810 | D 106 | rR:μσmM 0.77 0.21 0.00 0.94 | F:μσmM 82.9 70.9 20.0 324.0 | H 1.529 | V 0.503 | pL -0.027 | vL 0.019 | ∇ 0.113\n",
      "U 239 | F 489472 | FPS 2892 | D 107 | rR:μσmM 0.80 0.15 0.19 0.93 | F:μσmM 71.9 55.4 27.0 293.0 | H 1.580 | V 0.484 | pL 0.030 | vL 0.017 | ∇ 0.112\n",
      "U 240 | F 491520 | FPS 3011 | D 107 | rR:μσmM 0.79 0.20 0.00 0.93 | F:μσmM 72.9 65.9 26.0 324.0 | H 1.579 | V 0.484 | pL -0.015 | vL 0.018 | ∇ 0.118\n",
      "Status saved\n",
      "U 241 | F 493568 | FPS 3105 | D 108 | rR:μσmM 0.74 0.24 0.00 0.92 | F:μσmM 92.4 76.4 30.0 324.0 | H 1.641 | V 0.440 | pL 0.013 | vL 0.018 | ∇ 0.104\n",
      "U 242 | F 495616 | FPS 3342 | D 109 | rR:μσmM 0.78 0.17 0.21 0.93 | F:μσmM 78.2 61.8 26.0 286.0 | H 1.608 | V 0.450 | pL 0.025 | vL 0.020 | ∇ 0.111\n",
      "U 243 | F 497664 | FPS 3312 | D 109 | rR:μσmM 0.74 0.25 0.00 0.95 | F:μσmM 92.5 84.3 19.0 324.0 | H 1.643 | V 0.379 | pL 0.038 | vL 0.020 | ∇ 0.120\n",
      "U 244 | F 499712 | FPS 3122 | D 110 | rR:μσmM 0.74 0.22 0.19 0.90 | F:μσmM 92.5 78.1 36.0 293.0 | H 1.633 | V 0.382 | pL 0.020 | vL 0.021 | ∇ 0.129\n",
      "U 245 | F 501760 | FPS 3112 | D 110 | rR:μσmM 0.68 0.30 0.00 0.91 | F:μσmM 110.8 94.7 33.0 324.0 | H 1.630 | V 0.367 | pL -0.006 | vL 0.022 | ∇ 0.125\n",
      "U 246 | F 503808 | FPS 3147 | D 111 | rR:μσmM 0.78 0.24 0.00 0.94 | F:μσmM 77.2 81.9 22.0 324.0 | H 1.591 | V 0.461 | pL -0.034 | vL 0.028 | ∇ 0.155\n",
      "U 247 | F 505856 | FPS 3076 | D 112 | rR:μσmM 0.80 0.16 0.23 0.94 | F:μσmM 72.2 56.5 23.0 277.0 | H 1.573 | V 0.513 | pL -0.037 | vL 0.025 | ∇ 0.137\n",
      "U 248 | F 507904 | FPS 3098 | D 112 | rR:μσmM 0.81 0.15 0.34 0.94 | F:μσmM 68.6 55.4 23.0 237.0 | H 1.553 | V 0.526 | pL -0.036 | vL 0.020 | ∇ 0.124\n",
      "U 249 | F 509952 | FPS 3067 | D 113 | rR:μσmM 0.81 0.16 0.00 0.92 | F:μσmM 66.2 51.4 29.0 324.0 | H 1.561 | V 0.533 | pL -0.001 | vL 0.017 | ∇ 0.122\n",
      "U 250 | F 512000 | FPS 3015 | D 114 | rR:μσmM 0.80 0.12 0.40 0.91 | F:μσmM 70.8 44.7 31.0 215.0 | H 1.594 | V 0.481 | pL 0.042 | vL 0.016 | ∇ 0.108\n",
      "Status saved\n",
      "U 251 | F 514048 | FPS 3120 | D 114 | rR:μσmM 0.73 0.18 0.35 0.90 | F:μσmM 95.9 65.5 36.0 235.0 | H 1.661 | V 0.427 | pL 0.044 | vL 0.016 | ∇ 0.099\n",
      "U 252 | F 516096 | FPS 3194 | D 115 | rR:μσmM 0.76 0.13 0.38 0.90 | F:μσmM 85.9 45.4 36.0 225.0 | H 1.723 | V 0.367 | pL 0.045 | vL 0.011 | ∇ 0.083\n",
      "U 253 | F 518144 | FPS 3139 | D 116 | rR:μσmM 0.55 0.31 0.00 0.91 | F:μσmM 156.0 103.1 33.0 324.0 | H 1.704 | V 0.371 | pL 0.032 | vL 0.020 | ∇ 0.108\n",
      "U 254 | F 520192 | FPS 3141 | D 116 | rR:μσmM 0.73 0.21 0.00 0.91 | F:μσmM 95.2 69.6 31.0 324.0 | H 1.691 | V 0.417 | pL -0.029 | vL 0.018 | ∇ 0.091\n",
      "U 255 | F 522240 | FPS 3081 | D 117 | rR:μσmM 0.80 0.13 0.35 0.92 | F:μσmM 72.4 46.7 30.0 233.0 | H 1.677 | V 0.467 | pL -0.058 | vL 0.015 | ∇ 0.104\n",
      "U 256 | F 524288 | FPS 2632 | D 118 | rR:μσmM 0.79 0.13 0.41 0.92 | F:μσmM 76.0 47.6 30.0 211.0 | H 1.704 | V 0.421 | pL 0.022 | vL 0.012 | ∇ 0.089\n",
      "U 257 | F 526336 | FPS 3115 | D 119 | rR:μσmM 0.73 0.22 0.00 0.94 | F:μσmM 96.6 75.5 22.0 324.0 | H 1.710 | V 0.421 | pL 0.027 | vL 0.020 | ∇ 0.116\n",
      "U 258 | F 528384 | FPS 2446 | D 119 | rR:μσmM 0.70 0.27 0.00 0.94 | F:μσmM 105.0 87.9 20.0 324.0 | H 1.705 | V 0.383 | pL 0.029 | vL 0.022 | ∇ 0.100\n",
      "U 259 | F 530432 | FPS 3050 | D 120 | rR:μσmM 0.65 0.24 0.00 0.91 | F:μσmM 122.2 80.7 34.0 324.0 | H 1.727 | V 0.310 | pL 0.052 | vL 0.011 | ∇ 0.090\n",
      "U 260 | F 532480 | FPS 3027 | D 121 | rR:μσmM 0.56 0.28 0.00 0.94 | F:μσmM 154.6 98.1 23.0 324.0 | H 1.733 | V 0.290 | pL 0.037 | vL 0.016 | ∇ 0.092\n",
      "Status saved\n",
      "U 261 | F 534528 | FPS 3091 | D 121 | rR:μσmM 0.74 0.23 0.00 0.91 | F:μσmM 90.5 77.1 31.0 324.0 | H 1.704 | V 0.345 | pL -0.053 | vL 0.023 | ∇ 0.122\n",
      "U 262 | F 536576 | FPS 3229 | D 122 | rR:μσmM 0.62 0.27 0.00 0.91 | F:μσmM 135.1 91.4 33.0 324.0 | H 1.727 | V 0.291 | pL 0.026 | vL 0.015 | ∇ 0.091\n",
      "U 263 | F 538624 | FPS 3145 | D 123 | rR:μσmM 0.66 0.21 0.28 0.92 | F:μσmM 122.8 74.4 28.0 260.0 | H 1.760 | V 0.275 | pL 0.025 | vL 0.011 | ∇ 0.080\n",
      "U 264 | F 540672 | FPS 3250 | D 123 | rR:μσmM 0.45 0.36 0.00 0.91 | F:μσmM 188.3 114.9 33.0 324.0 | H 1.755 | V 0.228 | pL 0.039 | vL 0.014 | ∇ 0.093\n",
      "U 265 | F 542720 | FPS 3294 | D 124 | rR:μσmM 0.72 0.23 0.00 0.87 | F:μσmM 99.6 77.3 47.0 324.0 | H 1.742 | V 0.279 | pL -0.044 | vL 0.019 | ∇ 0.123\n",
      "U 266 | F 544768 | FPS 3270 | D 125 | rR:μσmM 0.62 0.33 0.00 0.93 | F:μσmM 130.8 106.1 26.0 324.0 | H 1.705 | V 0.320 | pL -0.012 | vL 0.022 | ∇ 0.114\n",
      "U 267 | F 546816 | FPS 3222 | D 125 | rR:μσmM 0.76 0.21 0.00 0.92 | F:μσmM 83.8 68.7 30.0 324.0 | H 1.734 | V 0.291 | pL -0.005 | vL 0.018 | ∇ 0.110\n",
      "U 268 | F 548864 | FPS 3198 | D 126 | rR:μσmM 0.60 0.35 0.00 0.94 | F:μσmM 135.2 111.2 21.0 324.0 | H 1.689 | V 0.314 | pL -0.010 | vL 0.023 | ∇ 0.118\n",
      "U 269 | F 550912 | FPS 3237 | D 127 | rR:μσmM 0.61 0.34 0.00 0.93 | F:μσmM 135.2 111.2 25.0 324.0 | H 1.718 | V 0.301 | pL 0.002 | vL 0.020 | ∇ 0.110\n",
      "U 270 | F 552960 | FPS 3240 | D 127 | rR:μσmM 0.69 0.26 0.00 0.93 | F:μσmM 109.1 88.2 26.0 324.0 | H 1.715 | V 0.310 | pL 0.002 | vL 0.020 | ∇ 0.118\n",
      "Status saved\n",
      "U 271 | F 555008 | FPS 3291 | D 128 | rR:μσmM 0.65 0.27 0.00 0.92 | F:μσmM 121.4 88.5 29.0 324.0 | H 1.668 | V 0.355 | pL -0.029 | vL 0.021 | ∇ 0.133\n",
      "U 272 | F 557056 | FPS 3163 | D 128 | rR:μσmM 0.79 0.20 0.00 0.94 | F:μσmM 75.9 66.3 23.0 324.0 | H 1.608 | V 0.425 | pL -0.080 | vL 0.025 | ∇ 0.147\n",
      "U 273 | F 559104 | FPS 3337 | D 129 | rR:μσmM 0.75 0.25 0.00 0.95 | F:μσmM 89.1 82.0 18.0 324.0 | H 1.649 | V 0.364 | pL 0.033 | vL 0.019 | ∇ 0.109\n",
      "U 274 | F 561152 | FPS 3221 | D 130 | rR:μσmM 0.67 0.31 0.00 0.94 | F:μσmM 114.9 103.0 23.0 324.0 | H 1.643 | V 0.314 | pL 0.042 | vL 0.023 | ∇ 0.131\n",
      "U 275 | F 563200 | FPS 2920 | D 130 | rR:μσmM 0.66 0.32 0.00 0.93 | F:μσmM 118.4 104.6 25.0 324.0 | H 1.665 | V 0.318 | pL -0.003 | vL 0.023 | ∇ 0.130\n",
      "U 276 | F 565248 | FPS 3074 | D 131 | rR:μσmM 0.63 0.34 0.00 0.94 | F:μσmM 125.9 111.0 21.0 324.0 | H 1.662 | V 0.302 | pL 0.001 | vL 0.019 | ∇ 0.127\n",
      "U 277 | F 567296 | FPS 3105 | D 132 | rR:μσmM 0.63 0.27 0.00 0.95 | F:μσmM 131.8 91.5 17.0 324.0 | H 1.627 | V 0.277 | pL 0.026 | vL 0.021 | ∇ 0.119\n",
      "U 278 | F 569344 | FPS 3243 | D 132 | rR:μσmM 0.61 0.33 0.00 0.95 | F:μσmM 136.4 111.9 19.0 324.0 | H 1.631 | V 0.287 | pL -0.000 | vL 0.024 | ∇ 0.113\n",
      "U 279 | F 571392 | FPS 3235 | D 133 | rR:μσmM 0.81 0.12 0.50 0.94 | F:μσmM 67.9 44.9 23.0 179.0 | H 1.578 | V 0.372 | pL -0.073 | vL 0.027 | ∇ 0.152\n",
      "U 280 | F 573440 | FPS 3341 | D 134 | rR:μσmM 0.72 0.30 0.00 0.93 | F:μσmM 99.3 104.6 26.0 324.0 | H 1.572 | V 0.390 | pL -0.019 | vL 0.034 | ∇ 0.146\n",
      "Status saved\n",
      "U 281 | F 575488 | FPS 3298 | D 134 | rR:μσmM 0.84 0.14 0.33 0.95 | F:μσmM 58.0 50.8 18.0 241.0 | H 1.518 | V 0.453 | pL -0.030 | vL 0.028 | ∇ 0.129\n",
      "U 282 | F 577536 | FPS 3344 | D 135 | rR:μσmM 0.80 0.23 0.00 0.95 | F:μσmM 68.1 73.7 19.0 324.0 | H 1.521 | V 0.464 | pL -0.029 | vL 0.027 | ∇ 0.138\n",
      "U 283 | F 579584 | FPS 3302 | D 135 | rR:μσmM 0.74 0.22 0.00 0.94 | F:μσmM 91.6 73.2 22.0 324.0 | H 1.569 | V 0.448 | pL -0.027 | vL 0.025 | ∇ 0.132\n",
      "U 284 | F 581632 | FPS 3263 | D 136 | rR:μσmM 0.82 0.13 0.40 0.95 | F:μσmM 64.4 46.6 18.0 216.0 | H 1.514 | V 0.537 | pL -0.055 | vL 0.022 | ∇ 0.152\n",
      "U 285 | F 583680 | FPS 3209 | D 137 | rR:μσmM 0.84 0.13 0.35 0.96 | F:μσmM 57.3 45.8 15.0 233.0 | H 1.426 | V 0.574 | pL -0.036 | vL 0.021 | ∇ 0.118\n",
      "U 286 | F 585728 | FPS 3196 | D 137 | rR:μσmM 0.86 0.12 0.30 0.95 | F:μσmM 52.1 42.3 19.0 253.0 | H 1.470 | V 0.573 | pL -0.017 | vL 0.020 | ∇ 0.118\n",
      "U 287 | F 587776 | FPS 3182 | D 138 | rR:μσmM 0.86 0.07 0.71 0.96 | F:μσmM 49.1 24.3 15.0 104.0 | H 1.512 | V 0.524 | pL 0.011 | vL 0.017 | ∇ 0.109\n",
      "U 288 | F 589824 | FPS 3237 | D 139 | rR:μσmM 0.81 0.19 0.00 0.95 | F:μσmM 66.3 65.0 17.0 324.0 | H 1.485 | V 0.512 | pL 0.026 | vL 0.026 | ∇ 0.130\n",
      "U 289 | F 591872 | FPS 3196 | D 139 | rR:μσmM 0.76 0.23 0.00 0.95 | F:μσmM 86.7 79.5 19.0 324.0 | H 1.530 | V 0.490 | pL 0.052 | vL 0.023 | ∇ 0.114\n",
      "U 290 | F 593920 | FPS 3321 | D 140 | rR:μσmM 0.85 0.10 0.55 0.94 | F:μσmM 52.7 34.9 22.0 162.0 | H 1.478 | V 0.522 | pL -0.018 | vL 0.020 | ∇ 0.137\n",
      "Status saved\n",
      "U 291 | F 595968 | FPS 3307 | D 141 | rR:μσmM 0.81 0.19 0.00 0.95 | F:μσmM 69.0 64.9 19.0 324.0 | H 1.477 | V 0.558 | pL -0.020 | vL 0.022 | ∇ 0.110\n",
      "U 292 | F 598016 | FPS 3331 | D 141 | rR:μσmM 0.84 0.10 0.52 0.96 | F:μσmM 56.2 36.8 16.0 172.0 | H 1.465 | V 0.597 | pL -0.018 | vL 0.016 | ∇ 0.115\n",
      "U 293 | F 600064 | FPS 3364 | D 142 | rR:μσmM 0.87 0.09 0.50 0.95 | F:μσmM 48.4 32.4 18.0 179.0 | H 1.472 | V 0.619 | pL -0.007 | vL 0.016 | ∇ 0.109\n",
      "Number of frames:  600064\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 3rd environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-SimpleCrossingS9N2-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 4490.0 | FPS 3467 | D 1.0 | R:μσmM 0.86 0.11 0.30 0.96 | F:μσmM 49.5 38.3 16.0 252.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 2214.0 | FPS 3750 | D 0.0 | R:μσmM 0.86 0.12 0.43 0.98 | F:μσmM 22.1 18.6 3.0 92.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 2nd environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 19824.0 | FPS 4294 | D 4.0 | R:μσmM 0.48 0.33 0.00 0.93 | F:μσmM 198.2 117.9 29.0 360.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
