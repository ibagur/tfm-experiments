{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper, FullyObsWrapper, ViewSizeWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2739,)\n",
      "Box([0 0 0 ... 0 0 0], [255 255 255 ... 255 255 255], (2739,), uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);\n",
    "#eval_env = ImgObsWrapper(RGBImgPartialObsWrapper(eval_env))\n",
    "#eval_env = ViewSizeWrapper(eval_env, 7)\n",
    "eval_env = FlatObsWrapper(eval_env)\n",
    "print(eval_env._observation_space.shape)\n",
    "print(eval_env._observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Standard PPO learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "\n",
    "seed = 1\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#model = 'MiniGrid-WallGapS6-v0_PPO_frames_600k_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "processes = 16\n",
    "frames = 300000\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1 | F 002048 | FPS 2774 | D 0 | rR:μσmM 0.11 0.23 0.00 0.75 | F:μσmM 13.2 29.1 0.0 94.0 | H 1.912 | V -0.071 | pL -0.089 | vL 0.016 | ∇ 0.056\n",
      "U 2 | F 004096 | FPS 2965 | D 1 | rR:μσmM 0.01 0.03 0.00 0.14 | F:μσmM 143.6 1.7 137.0 144.0 | H 1.925 | V -0.026 | pL -0.024 | vL 0.000 | ∇ 0.008\n",
      "U 3 | F 006144 | FPS 2745 | D 2 | rR:μσmM 0.07 0.19 0.00 0.61 | F:μσmM 135.2 25.0 62.0 144.0 | H 1.915 | V 0.008 | pL -0.035 | vL 0.008 | ∇ 0.026\n",
      "U 4 | F 008192 | FPS 2979 | D 2 | rR:μσmM 0.07 0.19 0.00 0.71 | F:μσmM 135.0 25.5 46.0 144.0 | H 1.927 | V 0.022 | pL -0.011 | vL 0.006 | ∇ 0.049\n",
      "U 5 | F 010240 | FPS 2492 | D 3 | rR:μσmM 0.09 0.23 0.00 0.77 | F:μσmM 131.9 31.8 37.0 144.0 | H 1.927 | V 0.031 | pL -0.016 | vL 0.008 | ∇ 0.040\n",
      "U 6 | F 012288 | FPS 2590 | D 4 | rR:μσmM 0.16 0.26 0.00 0.72 | F:μσmM 122.8 34.4 45.0 144.0 | H 1.918 | V 0.039 | pL -0.035 | vL 0.012 | ∇ 0.094\n",
      "U 7 | F 014336 | FPS 2757 | D 5 | rR:μσmM 0.21 0.32 0.00 0.84 | F:μσmM 115.8 44.6 26.0 144.0 | H 1.902 | V 0.072 | pL -0.022 | vL 0.019 | ∇ 0.089\n",
      "U 8 | F 016384 | FPS 3037 | D 5 | rR:μσmM 0.28 0.30 0.00 0.95 | F:μσmM 107.3 41.1 8.0 144.0 | H 1.899 | V 0.099 | pL -0.023 | vL 0.012 | ∇ 0.060\n",
      "U 9 | F 018432 | FPS 2997 | D 6 | rR:μσmM 0.14 0.24 0.00 0.84 | F:μσmM 126.9 32.4 26.0 144.0 | H 1.893 | V 0.083 | pL 0.022 | vL 0.009 | ∇ 0.080\n",
      "U 10 | F 020480 | FPS 3119 | D 7 | rR:μσmM 0.26 0.34 0.00 0.84 | F:μσmM 108.6 47.5 26.0 144.0 | H 1.883 | V 0.075 | pL -0.008 | vL 0.012 | ∇ 0.070\n",
      "Status saved\n",
      "U 11 | F 022528 | FPS 3097 | D 7 | rR:μσmM 0.45 0.36 0.00 0.94 | F:μσmM 83.8 52.7 10.0 144.0 | H 1.872 | V 0.165 | pL -0.074 | vL 0.024 | ∇ 0.093\n",
      "U 12 | F 024576 | FPS 2961 | D 8 | rR:μσmM 0.48 0.35 0.00 0.94 | F:μσmM 78.2 50.2 10.0 144.0 | H 1.845 | V 0.187 | pL -0.040 | vL 0.021 | ∇ 0.074\n",
      "U 13 | F 026624 | FPS 3048 | D 9 | rR:μσmM 0.39 0.34 0.00 0.99 | F:μσmM 92.6 48.3 2.0 144.0 | H 1.799 | V 0.205 | pL 0.022 | vL 0.021 | ∇ 0.101\n",
      "U 14 | F 028672 | FPS 2829 | D 10 | rR:μσmM 0.37 0.36 0.00 0.98 | F:μσmM 94.6 50.1 4.0 144.0 | H 1.861 | V 0.164 | pL 0.018 | vL 0.018 | ∇ 0.082\n",
      "U 15 | F 030720 | FPS 3022 | D 10 | rR:μσmM 0.46 0.34 0.00 0.94 | F:μσmM 83.2 48.9 10.0 144.0 | H 1.821 | V 0.221 | pL -0.022 | vL 0.025 | ∇ 0.118\n",
      "U 16 | F 032768 | FPS 3057 | D 11 | rR:μσmM 0.40 0.34 0.00 0.91 | F:μσmM 90.1 47.5 14.0 144.0 | H 1.831 | V 0.230 | pL 0.017 | vL 0.018 | ∇ 0.099\n",
      "U 17 | F 034816 | FPS 3035 | D 12 | rR:μσmM 0.57 0.29 0.00 0.93 | F:μσmM 66.5 42.1 12.0 144.0 | H 1.800 | V 0.296 | pL -0.073 | vL 0.032 | ∇ 0.129\n",
      "U 18 | F 036864 | FPS 3104 | D 12 | rR:μσmM 0.51 0.30 0.00 0.84 | F:μσmM 75.8 42.5 26.0 144.0 | H 1.790 | V 0.304 | pL -0.009 | vL 0.030 | ∇ 0.100\n",
      "U 19 | F 038912 | FPS 3149 | D 13 | rR:μσmM 0.59 0.26 0.00 0.95 | F:μσmM 64.5 39.6 8.0 144.0 | H 1.771 | V 0.320 | pL -0.032 | vL 0.027 | ∇ 0.166\n",
      "U 20 | F 040960 | FPS 3102 | D 14 | rR:μσmM 0.59 0.31 0.00 0.96 | F:μσmM 62.8 45.5 7.0 144.0 | H 1.769 | V 0.350 | pL 0.009 | vL 0.027 | ∇ 0.126\n",
      "Status saved\n",
      "U 21 | F 043008 | FPS 3083 | D 14 | rR:μσmM 0.68 0.28 0.00 0.98 | F:μσmM 48.9 41.1 4.0 144.0 | H 1.727 | V 0.369 | pL -0.032 | vL 0.033 | ∇ 0.168\n",
      "U 22 | F 045056 | FPS 3046 | D 15 | rR:μσmM 0.63 0.32 0.00 0.97 | F:μσmM 56.5 46.9 5.0 144.0 | H 1.731 | V 0.378 | pL -0.015 | vL 0.036 | ∇ 0.192\n",
      "U 23 | F 047104 | FPS 2990 | D 16 | rR:μσmM 0.70 0.23 0.00 0.96 | F:μσmM 47.7 35.0 6.0 144.0 | H 1.709 | V 0.452 | pL -0.044 | vL 0.028 | ∇ 0.113\n",
      "U 24 | F 049152 | FPS 2953 | D 16 | rR:μσmM 0.72 0.23 0.00 0.99 | F:μσmM 44.7 35.2 2.0 144.0 | H 1.659 | V 0.491 | pL 0.018 | vL 0.026 | ∇ 0.131\n",
      "U 25 | F 051200 | FPS 3035 | D 17 | rR:μσmM 0.74 0.22 0.00 0.96 | F:μσmM 40.2 32.7 6.0 144.0 | H 1.689 | V 0.495 | pL 0.013 | vL 0.026 | ∇ 0.156\n",
      "U 26 | F 053248 | FPS 2750 | D 18 | rR:μσmM 0.75 0.21 0.00 0.98 | F:μσmM 40.4 33.1 3.0 144.0 | H 1.657 | V 0.515 | pL -0.005 | vL 0.026 | ∇ 0.161\n",
      "U 27 | F 055296 | FPS 2997 | D 18 | rR:μσmM 0.76 0.19 0.29 0.98 | F:μσmM 38.3 30.5 4.0 114.0 | H 1.624 | V 0.532 | pL -0.011 | vL 0.025 | ∇ 0.172\n",
      "U 28 | F 057344 | FPS 3039 | D 19 | rR:μσmM 0.82 0.14 0.35 0.97 | F:μσmM 28.8 21.7 5.0 104.0 | H 1.555 | V 0.618 | pL -0.109 | vL 0.018 | ∇ 0.167\n",
      "U 29 | F 059392 | FPS 3058 | D 20 | rR:μσmM 0.83 0.11 0.54 0.97 | F:μσmM 26.8 18.2 5.0 74.0 | H 1.492 | V 0.620 | pL -0.064 | vL 0.017 | ∇ 0.135\n",
      "U 30 | F 061440 | FPS 3033 | D 20 | rR:μσmM 0.84 0.11 0.42 0.98 | F:μσmM 25.4 18.4 4.0 93.0 | H 1.498 | V 0.664 | pL -0.021 | vL 0.015 | ∇ 0.142\n",
      "Status saved\n",
      "U 31 | F 063488 | FPS 2974 | D 21 | rR:μσmM 0.83 0.13 0.37 0.98 | F:μσmM 27.8 20.0 4.0 101.0 | H 1.504 | V 0.657 | pL 0.020 | vL 0.014 | ∇ 0.136\n",
      "U 32 | F 065536 | FPS 2958 | D 22 | rR:μσmM 0.84 0.10 0.51 0.98 | F:μσmM 25.2 16.8 3.0 78.0 | H 1.479 | V 0.671 | pL -0.056 | vL 0.014 | ∇ 0.199\n",
      "U 33 | F 067584 | FPS 2988 | D 23 | rR:μσmM 0.87 0.08 0.68 0.98 | F:μσmM 21.4 12.5 4.0 52.0 | H 1.405 | V 0.731 | pL -0.001 | vL 0.009 | ∇ 0.139\n",
      "U 34 | F 069632 | FPS 2969 | D 23 | rR:μσmM 0.87 0.08 0.56 0.98 | F:μσmM 21.2 12.8 3.0 70.0 | H 1.409 | V 0.729 | pL -0.029 | vL 0.009 | ∇ 0.112\n",
      "U 35 | F 071680 | FPS 2971 | D 24 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.6 3.0 75.0 | H 1.366 | V 0.750 | pL -0.015 | vL 0.011 | ∇ 0.174\n",
      "U 36 | F 073728 | FPS 2963 | D 25 | rR:μσmM 0.88 0.07 0.49 0.98 | F:μσmM 19.0 12.0 3.0 81.0 | H 1.339 | V 0.765 | pL -0.004 | vL 0.008 | ∇ 0.096\n",
      "U 37 | F 075776 | FPS 2974 | D 25 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.7 3.0 75.0 | H 1.334 | V 0.760 | pL 0.018 | vL 0.010 | ∇ 0.161\n",
      "U 38 | F 077824 | FPS 2950 | D 26 | rR:μσmM 0.88 0.06 0.66 0.98 | F:μσmM 19.1 10.2 3.0 55.0 | H 1.411 | V 0.771 | pL 0.031 | vL 0.005 | ∇ 0.100\n",
      "U 39 | F 079872 | FPS 2946 | D 27 | rR:μσmM 0.89 0.06 0.68 0.98 | F:μσmM 16.9 9.6 3.0 51.0 | H 1.323 | V 0.783 | pL -0.025 | vL 0.011 | ∇ 0.202\n",
      "U 40 | F 081920 | FPS 2951 | D 27 | rR:μσmM 0.89 0.05 0.68 0.98 | F:μσmM 17.8 8.6 3.0 51.0 | H 1.339 | V 0.780 | pL -0.009 | vL 0.006 | ∇ 0.118\n",
      "Status saved\n",
      "U 41 | F 083968 | FPS 2919 | D 28 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.5 4.0 45.0 | H 1.274 | V 0.792 | pL -0.047 | vL 0.005 | ∇ 0.114\n",
      "U 42 | F 086016 | FPS 2822 | D 29 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.1 5.8 3.0 34.0 | H 1.206 | V 0.823 | pL -0.061 | vL 0.003 | ∇ 0.098\n",
      "U 43 | F 088064 | FPS 2860 | D 30 | rR:μσmM 0.91 0.04 0.73 0.98 | F:μσmM 13.8 6.5 3.0 43.0 | H 1.260 | V 0.837 | pL 0.021 | vL 0.003 | ∇ 0.097\n",
      "U 44 | F 090112 | FPS 2891 | D 30 | rR:μσmM 0.89 0.06 0.74 0.98 | F:μσmM 17.4 9.3 3.0 42.0 | H 1.367 | V 0.781 | pL 0.048 | vL 0.004 | ∇ 0.094\n",
      "U 45 | F 092160 | FPS 2870 | D 31 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.0 3.0 45.0 | H 1.378 | V 0.805 | pL 0.018 | vL 0.003 | ∇ 0.062\n",
      "U 46 | F 094208 | FPS 2800 | D 32 | rR:μσmM 0.89 0.06 0.66 0.98 | F:μσmM 16.9 9.2 3.0 55.0 | H 1.358 | V 0.787 | pL 0.014 | vL 0.009 | ∇ 0.182\n",
      "U 47 | F 096256 | FPS 2859 | D 32 | rR:μσmM 0.90 0.06 0.41 0.98 | F:μσmM 16.5 10.0 4.0 95.0 | H 1.372 | V 0.805 | pL 0.038 | vL 0.006 | ∇ 0.084\n",
      "U 48 | F 098304 | FPS 2851 | D 33 | rR:μσmM 0.88 0.07 0.68 0.98 | F:μσmM 19.8 10.9 4.0 52.0 | H 1.365 | V 0.752 | pL 0.019 | vL 0.006 | ∇ 0.097\n",
      "U 49 | F 100352 | FPS 2763 | D 34 | rR:μσmM 0.89 0.06 0.68 0.96 | F:μσmM 17.6 9.5 6.0 52.0 | H 1.262 | V 0.775 | pL -0.033 | vL 0.005 | ∇ 0.077\n",
      "U 50 | F 102400 | FPS 2160 | D 35 | rR:μσmM 0.89 0.06 0.68 0.99 | F:μσmM 17.3 9.3 2.0 51.0 | H 1.256 | V 0.784 | pL -0.025 | vL 0.005 | ∇ 0.094\n",
      "Status saved\n",
      "U 51 | F 104448 | FPS 2859 | D 36 | rR:μσmM 0.90 0.05 0.75 0.97 | F:μσmM 16.1 7.5 5.0 40.0 | H 1.230 | V 0.798 | pL -0.059 | vL 0.004 | ∇ 0.092\n",
      "U 52 | F 106496 | FPS 2374 | D 36 | rR:μσmM 0.90 0.04 0.77 0.98 | F:μσmM 15.3 6.2 4.0 37.0 | H 1.217 | V 0.823 | pL -0.027 | vL 0.003 | ∇ 0.072\n",
      "U 53 | F 108544 | FPS 2459 | D 37 | rR:μσmM 0.91 0.04 0.71 0.98 | F:μσmM 14.0 6.7 3.0 46.0 | H 1.177 | V 0.821 | pL -0.046 | vL 0.004 | ∇ 0.099\n",
      "U 54 | F 110592 | FPS 2523 | D 38 | rR:μσmM 0.92 0.03 0.78 0.98 | F:μσmM 12.2 5.4 3.0 35.0 | H 1.055 | V 0.846 | pL -0.067 | vL 0.002 | ∇ 0.097\n",
      "U 55 | F 112640 | FPS 2833 | D 39 | rR:μσmM 0.92 0.03 0.79 0.99 | F:μσmM 13.0 5.5 2.0 33.0 | H 1.118 | V 0.840 | pL -0.019 | vL 0.002 | ∇ 0.066\n",
      "U 56 | F 114688 | FPS 2722 | D 40 | rR:μσmM 0.92 0.03 0.79 0.98 | F:μσmM 13.0 5.1 3.0 34.0 | H 1.238 | V 0.853 | pL 0.035 | vL 0.002 | ∇ 0.055\n",
      "U 57 | F 116736 | FPS 2881 | D 40 | rR:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 13.9 6.2 3.0 35.0 | H 1.268 | V 0.831 | pL -0.000 | vL 0.004 | ∇ 0.115\n",
      "U 58 | F 118784 | FPS 2865 | D 41 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.9 6.7 3.0 34.0 | H 1.333 | V 0.822 | pL 0.045 | vL 0.003 | ∇ 0.066\n",
      "U 59 | F 120832 | FPS 2896 | D 42 | rR:μσmM 0.90 0.05 0.68 0.98 | F:μσmM 16.5 8.6 3.0 51.0 | H 1.295 | V 0.802 | pL 0.011 | vL 0.005 | ∇ 0.106\n",
      "Number of frames:  122880\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 1439.0 | FPS 3977 | D 0.0 | R:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 14.4 6.3 3.0 35.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim, num_units = args.num_units, k = args.k)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status (TEST for CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "envs = make_envs(args.env, args.procs, args.seed)\n",
    "\n",
    "algo.env = envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 51 | F 104448 | FPS 2588 | D 0 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.509 | V 0.490 | pL 0.217 | vL 0.010 | ∇ 0.239\n",
      "U 52 | F 106496 | FPS 3027 | D 1 | rR:μσmM 0.03 0.10 0.00 0.43 | F:μσmM 14.4 55.7 0.0 230.0 | H 1.523 | V 0.365 | pL 0.173 | vL 0.005 | ∇ 0.132\n",
      "U 53 | F 108544 | FPS 2680 | D 2 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 345.4 38.8 230.0 360.0 | H 1.705 | V 0.162 | pL 0.196 | vL 0.009 | ∇ 0.151\n",
      "U 54 | F 110592 | FPS 2925 | D 2 | rR:μσmM 0.07 0.18 0.00 0.70 | F:μσmM 338.6 61.5 121.0 360.0 | H 1.784 | V 0.130 | pL 0.047 | vL 0.003 | ∇ 0.050\n",
      "U 55 | F 112640 | FPS 2558 | D 3 | rR:μσmM 0.07 0.19 0.00 0.70 | F:μσmM 336.8 64.2 121.0 360.0 | H 1.839 | V 0.089 | pL 0.040 | vL 0.001 | ∇ 0.029\n",
      "U 56 | F 114688 | FPS 3023 | D 4 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 346.1 37.5 228.0 360.0 | H 1.870 | V 0.054 | pL 0.037 | vL 0.001 | ∇ 0.024\n",
      "U 57 | F 116736 | FPS 2580 | D 5 | rR:μσmM 0.09 0.20 0.00 0.71 | F:μσmM 330.8 67.2 114.0 360.0 | H 1.873 | V 0.066 | pL -0.006 | vL 0.004 | ∇ 0.043\n",
      "U 58 | F 118784 | FPS 2783 | D 5 | rR:μσmM 0.21 0.24 0.00 0.71 | F:μσmM 294.8 76.4 114.0 360.0 | H 1.893 | V 0.063 | pL 0.003 | vL 0.003 | ∇ 0.042\n",
      "U 59 | F 120832 | FPS 3068 | D 6 | rR:μσmM 0.23 0.29 0.00 0.94 | F:μσmM 286.1 100.3 26.0 360.0 | H 1.885 | V 0.043 | pL 0.018 | vL 0.005 | ∇ 0.059\n",
      "U 60 | F 122880 | FPS 3192 | D 7 | rR:μσmM 0.20 0.28 0.00 0.94 | F:μσmM 300.9 97.1 26.0 360.0 | H 1.903 | V 0.053 | pL -0.011 | vL 0.005 | ∇ 0.044\n",
      "Status saved\n",
      "U 61 | F 124928 | FPS 3163 | D 7 | rR:μσmM 0.20 0.29 0.00 0.94 | F:μσmM 299.1 101.2 26.0 360.0 | H 1.918 | V 0.043 | pL 0.002 | vL 0.002 | ∇ 0.039\n",
      "U 62 | F 126976 | FPS 3109 | D 8 | rR:μσmM 0.27 0.30 0.00 0.75 | F:μσmM 273.9 101.1 98.0 360.0 | H 1.909 | V 0.100 | pL -0.047 | vL 0.011 | ∇ 0.077\n",
      "U 63 | F 129024 | FPS 3308 | D 9 | rR:μσmM 0.35 0.31 0.00 0.76 | F:μσmM 244.1 106.7 94.0 360.0 | H 1.895 | V 0.108 | pL 0.001 | vL 0.008 | ∇ 0.065\n",
      "U 64 | F 131072 | FPS 3268 | D 9 | rR:μσmM 0.54 0.31 0.00 0.88 | F:μσmM 180.8 114.8 46.0 360.0 | H 1.859 | V 0.161 | pL -0.054 | vL 0.022 | ∇ 0.097\n",
      "U 65 | F 133120 | FPS 3290 | D 10 | rR:μσmM 0.47 0.35 0.00 0.88 | F:μσmM 205.5 129.0 46.0 360.0 | H 1.886 | V 0.147 | pL 0.005 | vL 0.011 | ∇ 0.072\n",
      "U 66 | F 135168 | FPS 2980 | D 11 | rR:μσmM 0.44 0.33 0.00 0.93 | F:μσmM 218.2 121.7 30.0 360.0 | H 1.868 | V 0.140 | pL 0.007 | vL 0.012 | ∇ 0.078\n",
      "U 67 | F 137216 | FPS 3352 | D 11 | rR:μσmM 0.34 0.33 0.00 0.93 | F:μσmM 250.4 115.3 30.0 360.0 | H 1.860 | V 0.141 | pL 0.033 | vL 0.009 | ∇ 0.078\n",
      "U 68 | F 139264 | FPS 3286 | D 12 | rR:μσmM 0.50 0.35 0.00 0.93 | F:μσmM 191.2 125.2 28.0 360.0 | H 1.849 | V 0.166 | pL -0.010 | vL 0.013 | ∇ 0.110\n",
      "U 69 | F 141312 | FPS 3231 | D 13 | rR:μσmM 0.54 0.31 0.00 0.93 | F:μσmM 176.3 110.3 29.0 360.0 | H 1.801 | V 0.204 | pL -0.032 | vL 0.016 | ∇ 0.115\n",
      "U 70 | F 143360 | FPS 3211 | D 13 | rR:μσmM 0.60 0.28 0.00 0.89 | F:μσmM 153.9 102.6 45.0 360.0 | H 1.815 | V 0.210 | pL -0.039 | vL 0.018 | ∇ 0.149\n",
      "Status saved\n",
      "U 71 | F 145408 | FPS 3197 | D 14 | rR:μσmM 0.60 0.30 0.00 0.93 | F:μσmM 155.9 108.5 27.0 360.0 | H 1.806 | V 0.262 | pL -0.014 | vL 0.015 | ∇ 0.130\n",
      "U 72 | F 147456 | FPS 3215 | D 15 | rR:μσmM 0.55 0.29 0.00 0.94 | F:μσmM 173.8 108.1 23.0 360.0 | H 1.801 | V 0.248 | pL 0.022 | vL 0.014 | ∇ 0.119\n",
      "U 73 | F 149504 | FPS 3235 | D 15 | rR:μσmM 0.55 0.34 0.00 0.89 | F:μσmM 170.3 121.2 42.0 360.0 | H 1.771 | V 0.314 | pL 0.021 | vL 0.020 | ∇ 0.142\n",
      "U 74 | F 151552 | FPS 3259 | D 16 | rR:μσmM 0.66 0.27 0.00 0.94 | F:μσmM 131.6 102.5 22.0 360.0 | H 1.742 | V 0.306 | pL -0.008 | vL 0.016 | ∇ 0.099\n",
      "U 75 | F 153600 | FPS 3020 | D 16 | rR:μσmM 0.74 0.21 0.00 0.93 | F:μσmM 101.8 78.1 30.0 360.0 | H 1.739 | V 0.378 | pL -0.074 | vL 0.022 | ∇ 0.186\n",
      "U 76 | F 155648 | FPS 3174 | D 17 | rR:μσmM 0.74 0.21 0.00 0.97 | F:μσmM 101.7 79.4 13.0 360.0 | H 1.713 | V 0.408 | pL -0.011 | vL 0.024 | ∇ 0.137\n",
      "U 77 | F 157696 | FPS 3180 | D 18 | rR:μσmM 0.83 0.12 0.49 0.95 | F:μσmM 69.0 48.5 19.0 206.0 | H 1.693 | V 0.443 | pL -0.036 | vL 0.018 | ∇ 0.151\n",
      "U 78 | F 159744 | FPS 2693 | D 19 | rR:μσmM 0.75 0.24 0.00 0.95 | F:μσmM 97.1 89.7 18.0 360.0 | H 1.681 | V 0.461 | pL 0.010 | vL 0.023 | ∇ 0.154\n",
      "U 79 | F 161792 | FPS 2871 | D 19 | rR:μσmM 0.79 0.13 0.36 0.94 | F:μσmM 83.7 53.7 25.0 255.0 | H 1.648 | V 0.483 | pL -0.026 | vL 0.013 | ∇ 0.104\n",
      "U 80 | F 163840 | FPS 2931 | D 20 | rR:μσmM 0.83 0.13 0.29 0.96 | F:μσmM 69.1 52.1 14.0 285.0 | H 1.590 | V 0.509 | pL -0.035 | vL 0.016 | ∇ 0.151\n",
      "Status saved\n",
      "U 81 | F 165888 | FPS 3028 | D 21 | rR:μσmM 0.84 0.08 0.66 0.96 | F:μσmM 64.1 30.0 17.0 137.0 | H 1.620 | V 0.519 | pL -0.026 | vL 0.016 | ∇ 0.158\n",
      "U 82 | F 167936 | FPS 2507 | D 21 | rR:μσmM 0.83 0.10 0.58 0.96 | F:μσmM 69.0 41.8 16.0 166.0 | H 1.650 | V 0.537 | pL -0.033 | vL 0.012 | ∇ 0.174\n",
      "U 83 | F 169984 | FPS 2630 | D 22 | rR:μσmM 0.83 0.10 0.56 0.94 | F:μσmM 66.2 38.5 22.0 178.0 | H 1.594 | V 0.569 | pL -0.005 | vL 0.014 | ∇ 0.126\n",
      "U 84 | F 172032 | FPS 2977 | D 23 | rR:μσmM 0.88 0.07 0.57 0.97 | F:μσmM 49.6 29.8 12.0 171.0 | H 1.642 | V 0.617 | pL -0.018 | vL 0.012 | ∇ 0.173\n",
      "U 85 | F 174080 | FPS 2920 | D 24 | rR:μσmM 0.86 0.10 0.48 0.97 | F:μσmM 55.2 41.6 12.0 208.0 | H 1.568 | V 0.599 | pL -0.004 | vL 0.016 | ∇ 0.154\n",
      "U 86 | F 176128 | FPS 3135 | D 24 | rR:μσmM 0.86 0.08 0.57 0.97 | F:μσmM 55.0 32.1 12.0 173.0 | H 1.584 | V 0.618 | pL -0.073 | vL 0.011 | ∇ 0.151\n",
      "U 87 | F 178176 | FPS 3100 | D 25 | rR:μσmM 0.89 0.05 0.76 0.96 | F:μσmM 45.6 19.4 17.0 95.0 | H 1.481 | V 0.680 | pL -0.009 | vL 0.008 | ∇ 0.134\n",
      "U 88 | F 180224 | FPS 3202 | D 26 | rR:μσmM 0.89 0.06 0.76 0.98 | F:μσmM 43.7 23.4 10.0 97.0 | H 1.531 | V 0.667 | pL 0.020 | vL 0.007 | ∇ 0.098\n",
      "U 89 | F 182272 | FPS 3248 | D 26 | rR:μσmM 0.89 0.06 0.69 0.95 | F:μσmM 45.1 25.9 18.0 122.0 | H 1.528 | V 0.673 | pL 0.001 | vL 0.009 | ∇ 0.134\n",
      "U 90 | F 184320 | FPS 3244 | D 27 | rR:μσmM 0.89 0.07 0.63 0.98 | F:μσmM 42.4 28.8 10.0 146.0 | H 1.550 | V 0.689 | pL 0.022 | vL 0.009 | ∇ 0.136\n",
      "Status saved\n",
      "U 91 | F 186368 | FPS 3229 | D 28 | rR:μσmM 0.89 0.05 0.74 0.96 | F:μσmM 43.3 19.6 14.0 104.0 | H 1.536 | V 0.731 | pL 0.019 | vL 0.004 | ∇ 0.074\n",
      "U 92 | F 188416 | FPS 2948 | D 28 | rR:μσmM 0.90 0.05 0.67 0.97 | F:μσmM 42.0 20.7 11.0 134.0 | H 1.544 | V 0.671 | pL 0.035 | vL 0.011 | ∇ 0.134\n",
      "U 93 | F 190464 | FPS 3098 | D 29 | rR:μσmM 0.90 0.05 0.72 0.98 | F:μσmM 38.2 20.2 10.0 112.0 | H 1.539 | V 0.644 | pL 0.002 | vL 0.010 | ∇ 0.115\n",
      "U 94 | F 192512 | FPS 3155 | D 30 | rR:μσmM 0.86 0.17 0.00 0.97 | F:μσmM 54.6 63.1 11.0 360.0 | H 1.535 | V 0.638 | pL 0.001 | vL 0.015 | ∇ 0.187\n",
      "U 95 | F 194560 | FPS 3110 | D 30 | rR:μσmM 0.90 0.06 0.56 0.96 | F:μσmM 39.6 25.7 17.0 178.0 | H 1.515 | V 0.676 | pL 0.009 | vL 0.009 | ∇ 0.120\n",
      "U 96 | F 196608 | FPS 3222 | D 31 | rR:μσmM 0.90 0.08 0.43 0.96 | F:μσmM 39.2 31.2 15.0 228.0 | H 1.502 | V 0.695 | pL -0.002 | vL 0.010 | ∇ 0.126\n",
      "U 97 | F 198656 | FPS 1984 | D 32 | rR:μσmM 0.91 0.05 0.69 0.98 | F:μσmM 35.6 21.4 10.0 126.0 | H 1.439 | V 0.704 | pL -0.023 | vL 0.008 | ∇ 0.101\n",
      "U 98 | F 200704 | FPS 2849 | D 33 | rR:μσmM 0.91 0.08 0.33 0.97 | F:μσmM 35.4 31.5 12.0 269.0 | H 1.382 | V 0.750 | pL -0.048 | vL 0.007 | ∇ 0.124\n",
      "U 99 | F 202752 | FPS 2904 | D 33 | rR:μσmM 0.93 0.04 0.78 0.97 | F:μσmM 29.8 14.4 12.0 87.0 | H 1.358 | V 0.752 | pL -0.043 | vL 0.006 | ∇ 0.104\n",
      "Number of frames:  204800\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "args.env = env_id\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 3686.0 | FPS 2420 | D 1.0 | R:μσmM 0.91 0.04 0.73 0.97 | F:μσmM 36.9 16.9 12.0 107.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 5632.0 | FPS 3792 | D 1.0 | R:μσmM 0.65 0.37 0.00 0.98 | F:μσmM 52.2 53.7 3.0 144.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 3rd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 91 | F 186368 | FPS 2537 | D 0 | rR:μσmM 0.31 0.41 0.00 0.93 | F:μσmM 21.8 33.9 0.0 121.0 | H 1.700 | V 0.490 | pL 0.162 | vL 0.016 | ∇ 0.172\n",
      "U 92 | F 188416 | FPS 3129 | D 1 | rR:μσmM 0.45 0.38 0.00 0.93 | F:μσmM 64.0 75.4 0.0 252.0 | H 1.712 | V 0.366 | pL 0.161 | vL 0.008 | ∇ 0.150\n",
      "U 93 | F 190464 | FPS 3103 | D 2 | rR:μσmM 0.17 0.27 0.00 0.78 | F:μσmM 272.6 83.4 78.0 324.0 | H 1.752 | V 0.213 | pL 0.151 | vL 0.012 | ∇ 0.146\n",
      "U 94 | F 192512 | FPS 3132 | D 2 | rR:μσmM 0.24 0.27 0.00 0.63 | F:μσmM 254.1 80.6 134.0 324.0 | H 1.712 | V 0.207 | pL 0.025 | vL 0.005 | ∇ 0.064\n",
      "U 95 | F 194560 | FPS 3132 | D 3 | rR:μσmM 0.30 0.28 0.00 0.71 | F:μσmM 235.4 83.4 104.0 324.0 | H 1.755 | V 0.140 | pL 0.058 | vL 0.003 | ∇ 0.059\n",
      "U 96 | F 196608 | FPS 3109 | D 4 | rR:μσmM 0.21 0.25 0.00 0.71 | F:μσmM 266.6 73.5 104.0 324.0 | H 1.801 | V 0.136 | pL 0.012 | vL 0.007 | ∇ 0.061\n",
      "U 97 | F 198656 | FPS 3052 | D 4 | rR:μσmM 0.42 0.31 0.00 0.90 | F:μσmM 200.2 98.0 36.0 324.0 | H 1.790 | V 0.145 | pL -0.003 | vL 0.011 | ∇ 0.083\n",
      "U 98 | F 200704 | FPS 2894 | D 5 | rR:μσmM 0.39 0.33 0.00 0.90 | F:μσmM 208.8 106.2 36.0 324.0 | H 1.805 | V 0.117 | pL 0.016 | vL 0.006 | ∇ 0.054\n",
      "U 99 | F 202752 | FPS 3106 | D 6 | rR:μσmM 0.31 0.31 0.00 0.79 | F:μσmM 233.8 97.1 75.0 324.0 | H 1.792 | V 0.127 | pL -0.010 | vL 0.011 | ∇ 0.071\n",
      "U 100 | F 204800 | FPS 3148 | D 6 | rR:μσmM 0.34 0.32 0.00 0.77 | F:μσmM 223.2 99.9 84.0 324.0 | H 1.781 | V 0.117 | pL 0.008 | vL 0.007 | ∇ 0.066\n",
      "Status saved\n",
      "U 101 | F 206848 | FPS 3120 | D 7 | rR:μσmM 0.36 0.29 0.00 0.74 | F:μσmM 218.8 91.2 94.0 324.0 | H 1.822 | V 0.071 | pL 0.029 | vL 0.002 | ∇ 0.038\n",
      "U 102 | F 208896 | FPS 3072 | D 8 | rR:μσmM 0.21 0.27 0.00 0.80 | F:μσmM 263.8 80.4 71.0 324.0 | H 1.847 | V 0.074 | pL -0.000 | vL 0.008 | ∇ 0.060\n",
      "U 103 | F 210944 | FPS 3104 | D 8 | rR:μσmM 0.27 0.30 0.00 0.80 | F:μσmM 245.6 90.6 71.0 324.0 | H 1.839 | V 0.073 | pL -0.003 | vL 0.007 | ∇ 0.053\n",
      "U 104 | F 212992 | FPS 3113 | D 9 | rR:μσmM 0.29 0.26 0.00 0.71 | F:μσmM 240.5 78.2 105.0 324.0 | H 1.860 | V 0.073 | pL 0.002 | vL 0.004 | ∇ 0.044\n",
      "U 105 | F 215040 | FPS 3138 | D 10 | rR:μσmM 0.30 0.28 0.00 0.82 | F:μσmM 236.1 86.2 65.0 324.0 | H 1.866 | V 0.094 | pL -0.019 | vL 0.007 | ∇ 0.052\n",
      "U 106 | F 217088 | FPS 3115 | D 10 | rR:μσmM 0.24 0.28 0.00 0.82 | F:μσmM 254.0 85.8 65.0 324.0 | H 1.880 | V 0.081 | pL 0.013 | vL 0.004 | ∇ 0.038\n",
      "U 107 | F 219136 | FPS 3106 | D 11 | rR:μσmM 0.23 0.29 0.00 0.86 | F:μσmM 255.6 90.2 52.0 324.0 | H 1.875 | V 0.071 | pL 0.015 | vL 0.005 | ∇ 0.053\n",
      "U 108 | F 221184 | FPS 3046 | D 12 | rR:μσmM 0.18 0.29 0.00 0.86 | F:μσmM 269.6 91.1 52.0 324.0 | H 1.882 | V 0.050 | pL -0.008 | vL 0.004 | ∇ 0.042\n",
      "U 109 | F 223232 | FPS 3102 | D 12 | rR:μσmM 0.29 0.27 0.00 0.81 | F:μσmM 240.6 80.9 70.0 324.0 | H 1.849 | V 0.097 | pL -0.024 | vL 0.009 | ∇ 0.068\n",
      "U 110 | F 225280 | FPS 3145 | D 13 | rR:μσmM 0.38 0.27 0.00 0.81 | F:μσmM 215.0 84.0 70.0 324.0 | H 1.860 | V 0.104 | pL 0.005 | vL 0.006 | ∇ 0.058\n",
      "Status saved\n",
      "U 111 | F 227328 | FPS 3140 | D 14 | rR:μσmM 0.28 0.30 0.00 0.78 | F:μσmM 244.1 94.5 79.0 324.0 | H 1.847 | V 0.097 | pL -0.007 | vL 0.011 | ∇ 0.065\n",
      "U 112 | F 229376 | FPS 3021 | D 14 | rR:μσmM 0.31 0.29 0.00 0.78 | F:μσmM 233.3 91.2 79.0 324.0 | H 1.849 | V 0.102 | pL -0.003 | vL 0.006 | ∇ 0.053\n",
      "U 113 | F 231424 | FPS 2490 | D 15 | rR:μσmM 0.35 0.27 0.00 0.72 | F:μσmM 223.3 84.2 102.0 324.0 | H 1.863 | V 0.106 | pL 0.005 | vL 0.006 | ∇ 0.051\n",
      "U 114 | F 233472 | FPS 2585 | D 16 | rR:μσmM 0.35 0.30 0.00 0.88 | F:μσmM 219.1 93.2 45.0 324.0 | H 1.875 | V 0.080 | pL 0.006 | vL 0.007 | ∇ 0.048\n",
      "U 115 | F 235520 | FPS 2715 | D 17 | rR:μσmM 0.30 0.36 0.00 0.93 | F:μσmM 232.6 114.4 24.0 324.0 | H 1.869 | V 0.098 | pL -0.009 | vL 0.012 | ∇ 0.054\n",
      "U 116 | F 237568 | FPS 1575 | D 18 | rR:μσmM 0.28 0.34 0.00 0.93 | F:μσmM 242.2 106.4 24.0 324.0 | H 1.878 | V 0.080 | pL 0.013 | vL 0.003 | ∇ 0.039\n",
      "U 117 | F 239616 | FPS 2600 | D 19 | rR:μσmM 0.17 0.21 0.00 0.57 | F:μσmM 279.6 61.5 153.0 324.0 | H 1.886 | V 0.067 | pL 0.016 | vL 0.003 | ∇ 0.042\n",
      "U 118 | F 241664 | FPS 2229 | D 20 | rR:μσmM 0.31 0.32 0.00 0.85 | F:μσmM 231.2 100.4 53.0 324.0 | H 1.854 | V 0.108 | pL -0.026 | vL 0.011 | ∇ 0.071\n",
      "U 119 | F 243712 | FPS 2463 | D 21 | rR:μσmM 0.31 0.34 0.00 0.85 | F:μσmM 229.0 107.2 53.0 324.0 | H 1.872 | V 0.085 | pL 0.003 | vL 0.006 | ∇ 0.057\n",
      "U 120 | F 245760 | FPS 2843 | D 21 | rR:μσmM 0.27 0.30 0.00 0.79 | F:μσmM 246.0 92.5 74.0 324.0 | H 1.875 | V 0.081 | pL 0.010 | vL 0.005 | ∇ 0.047\n",
      "Status saved\n",
      "U 121 | F 247808 | FPS 3000 | D 22 | rR:μσmM 0.22 0.29 0.00 0.78 | F:μσmM 261.0 89.2 80.0 324.0 | H 1.885 | V 0.072 | pL 0.006 | vL 0.003 | ∇ 0.041\n",
      "U 122 | F 249856 | FPS 3083 | D 23 | rR:μσmM 0.15 0.25 0.00 0.74 | F:μσmM 280.4 75.3 95.0 324.0 | H 1.885 | V 0.045 | pL 0.015 | vL 0.001 | ∇ 0.037\n",
      "U 123 | F 251904 | FPS 3027 | D 23 | rR:μσmM 0.16 0.25 0.00 0.74 | F:μσmM 279.4 74.2 95.0 324.0 | H 1.887 | V 0.068 | pL -0.003 | vL 0.005 | ∇ 0.040\n",
      "U 124 | F 253952 | FPS 2508 | D 24 | rR:μσmM 0.12 0.20 0.00 0.58 | F:μσmM 292.5 58.2 150.0 324.0 | H 1.898 | V 0.049 | pL 0.008 | vL 0.001 | ∇ 0.023\n",
      "U 125 | F 256000 | FPS 2228 | D 25 | rR:μσmM 0.20 0.26 0.00 0.82 | F:μσmM 269.4 81.2 64.0 324.0 | H 1.883 | V 0.054 | pL -0.007 | vL 0.004 | ∇ 0.038\n",
      "U 126 | F 258048 | FPS 2726 | D 26 | rR:μσmM 0.26 0.28 0.00 0.87 | F:μσmM 251.9 88.3 47.0 324.0 | H 1.877 | V 0.078 | pL -0.020 | vL 0.010 | ∇ 0.057\n",
      "U 127 | F 260096 | FPS 3039 | D 27 | rR:μσmM 0.35 0.37 0.00 0.88 | F:μσmM 215.3 118.3 43.0 324.0 | H 1.868 | V 0.068 | pL -0.024 | vL 0.012 | ∇ 0.059\n",
      "U 128 | F 262144 | FPS 3120 | D 27 | rR:μσmM 0.34 0.36 0.00 0.88 | F:μσmM 217.9 113.3 43.0 324.0 | H 1.891 | V 0.051 | pL 0.009 | vL 0.002 | ∇ 0.029\n",
      "U 129 | F 264192 | FPS 3209 | D 28 | rR:μσmM 0.20 0.29 0.00 0.78 | F:μσmM 265.1 87.1 80.0 324.0 | H 1.882 | V 0.059 | pL -0.006 | vL 0.007 | ∇ 0.047\n",
      "U 130 | F 266240 | FPS 2635 | D 29 | rR:μσmM 0.22 0.27 0.00 0.78 | F:μσmM 259.6 82.4 80.0 324.0 | H 1.868 | V 0.083 | pL -0.015 | vL 0.007 | ∇ 0.051\n",
      "Status saved\n",
      "U 131 | F 268288 | FPS 3019 | D 29 | rR:μσmM 0.28 0.28 0.00 0.78 | F:μσmM 243.3 84.2 80.0 324.0 | H 1.875 | V 0.076 | pL -0.013 | vL 0.005 | ∇ 0.046\n",
      "U 132 | F 270336 | FPS 3075 | D 30 | rR:μσmM 0.37 0.31 0.00 0.85 | F:μσmM 217.0 97.9 53.0 324.0 | H 1.861 | V 0.109 | pL -0.038 | vL 0.013 | ∇ 0.074\n",
      "U 133 | F 272384 | FPS 3060 | D 31 | rR:μσmM 0.34 0.36 0.00 0.85 | F:μσmM 220.1 112.9 53.0 324.0 | H 1.857 | V 0.096 | pL 0.005 | vL 0.008 | ∇ 0.057\n",
      "U 134 | F 274432 | FPS 3001 | D 31 | rR:μσmM 0.34 0.33 0.00 0.82 | F:μσmM 220.9 100.9 63.0 324.0 | H 1.842 | V 0.125 | pL -0.030 | vL 0.011 | ∇ 0.074\n",
      "U 135 | F 276480 | FPS 2487 | D 32 | rR:μσmM 0.38 0.32 0.00 0.82 | F:μσmM 208.0 98.1 63.0 324.0 | H 1.848 | V 0.122 | pL -0.006 | vL 0.009 | ∇ 0.077\n",
      "U 136 | F 278528 | FPS 2184 | D 33 | rR:μσmM 0.39 0.31 0.00 0.84 | F:μσmM 208.7 98.7 56.0 324.0 | H 1.829 | V 0.117 | pL 0.002 | vL 0.013 | ∇ 0.077\n",
      "U 137 | F 280576 | FPS 2514 | D 34 | rR:μσmM 0.38 0.32 0.00 0.84 | F:μσmM 211.1 101.5 56.0 324.0 | H 1.834 | V 0.130 | pL -0.018 | vL 0.011 | ∇ 0.061\n",
      "U 138 | F 282624 | FPS 2362 | D 35 | rR:μσmM 0.43 0.33 0.00 0.89 | F:μσmM 192.6 105.7 38.0 324.0 | H 1.837 | V 0.137 | pL -0.007 | vL 0.012 | ∇ 0.081\n",
      "U 139 | F 284672 | FPS 2785 | D 36 | rR:μσmM 0.53 0.22 0.00 0.89 | F:μσmM 165.2 73.3 39.0 324.0 | H 1.813 | V 0.212 | pL -0.043 | vL 0.023 | ∇ 0.102\n",
      "U 140 | F 286720 | FPS 3023 | D 36 | rR:μσmM 0.59 0.28 0.00 0.89 | F:μσmM 142.1 90.3 39.0 324.0 | H 1.803 | V 0.204 | pL 0.001 | vL 0.013 | ∇ 0.089\n",
      "Status saved\n",
      "U 141 | F 288768 | FPS 3136 | D 37 | rR:μσmM 0.54 0.25 0.00 0.89 | F:μσmM 165.1 86.1 40.0 324.0 | H 1.781 | V 0.253 | pL -0.037 | vL 0.016 | ∇ 0.101\n",
      "U 142 | F 290816 | FPS 3061 | D 38 | rR:μσmM 0.68 0.17 0.20 0.90 | F:μσmM 114.9 61.1 37.0 287.0 | H 1.787 | V 0.254 | pL -0.020 | vL 0.016 | ∇ 0.083\n",
      "U 143 | F 292864 | FPS 2740 | D 38 | rR:μσmM 0.54 0.35 0.00 0.92 | F:μσmM 154.9 112.3 29.0 324.0 | H 1.783 | V 0.230 | pL 0.021 | vL 0.017 | ∇ 0.093\n",
      "U 144 | F 294912 | FPS 2543 | D 39 | rR:μσmM 0.62 0.30 0.00 0.92 | F:μσmM 132.1 97.7 30.0 324.0 | H 1.793 | V 0.207 | pL -0.001 | vL 0.012 | ∇ 0.081\n",
      "U 145 | F 296960 | FPS 2696 | D 40 | rR:μσmM 0.38 0.31 0.00 0.86 | F:μσmM 213.2 99.0 49.0 324.0 | H 1.811 | V 0.184 | pL 0.017 | vL 0.015 | ∇ 0.078\n",
      "U 146 | F 299008 | FPS 2174 | D 41 | rR:μσmM 0.60 0.29 0.00 0.88 | F:μσmM 140.4 93.9 42.0 324.0 | H 1.794 | V 0.194 | pL 0.006 | vL 0.013 | ∇ 0.088\n",
      "U 147 | F 301056 | FPS 2351 | D 42 | rR:μσmM 0.43 0.33 0.00 0.88 | F:μσmM 195.1 106.0 42.0 324.0 | H 1.807 | V 0.165 | pL 0.010 | vL 0.015 | ∇ 0.087\n",
      "U 148 | F 303104 | FPS 3050 | D 42 | rR:μσmM 0.47 0.36 0.00 0.91 | F:μσmM 179.6 114.5 32.0 324.0 | H 1.772 | V 0.185 | pL 0.003 | vL 0.015 | ∇ 0.093\n",
      "U 149 | F 305152 | FPS 3033 | D 43 | rR:μσmM 0.41 0.34 0.00 0.78 | F:μσmM 199.6 108.1 80.0 324.0 | H 1.763 | V 0.183 | pL 0.004 | vL 0.016 | ∇ 0.092\n",
      "U 150 | F 307200 | FPS 3055 | D 44 | rR:μσmM 0.53 0.34 0.00 0.93 | F:μσmM 160.9 111.2 25.0 324.0 | H 1.760 | V 0.215 | pL -0.044 | vL 0.021 | ∇ 0.104\n",
      "Status saved\n",
      "U 151 | F 309248 | FPS 3065 | D 44 | rR:μσmM 0.63 0.25 0.00 0.92 | F:μσmM 130.9 85.4 30.0 324.0 | H 1.753 | V 0.259 | pL -0.062 | vL 0.026 | ∇ 0.140\n",
      "U 152 | F 311296 | FPS 2699 | D 45 | rR:μσmM 0.64 0.31 0.00 0.90 | F:μσmM 123.9 99.7 37.0 324.0 | H 1.767 | V 0.287 | pL 0.003 | vL 0.020 | ∇ 0.107\n",
      "U 153 | F 313344 | FPS 2799 | D 46 | rR:μσmM 0.56 0.32 0.00 0.90 | F:μσmM 152.7 103.8 37.0 324.0 | H 1.764 | V 0.263 | pL 0.014 | vL 0.016 | ∇ 0.098\n",
      "U 154 | F 315392 | FPS 3044 | D 47 | rR:μσmM 0.62 0.27 0.00 0.92 | F:μσmM 132.1 87.9 28.0 324.0 | H 1.783 | V 0.232 | pL 0.018 | vL 0.011 | ∇ 0.085\n",
      "U 155 | F 317440 | FPS 2987 | D 47 | rR:μσmM 0.46 0.33 0.00 0.86 | F:μσmM 185.3 104.9 52.0 324.0 | H 1.818 | V 0.206 | pL 0.020 | vL 0.015 | ∇ 0.084\n",
      "U 156 | F 319488 | FPS 2900 | D 48 | rR:μσmM 0.54 0.31 0.00 0.86 | F:μσmM 158.9 96.8 51.0 324.0 | H 1.775 | V 0.291 | pL -0.033 | vL 0.016 | ∇ 0.102\n",
      "U 157 | F 321536 | FPS 2896 | D 49 | rR:μσmM 0.59 0.26 0.00 0.83 | F:μσmM 143.0 84.5 60.0 324.0 | H 1.798 | V 0.228 | pL 0.022 | vL 0.011 | ∇ 0.070\n",
      "U 158 | F 323584 | FPS 2804 | D 49 | rR:μσmM 0.49 0.26 0.00 0.86 | F:μσmM 178.4 85.6 52.0 324.0 | H 1.802 | V 0.217 | pL 0.004 | vL 0.015 | ∇ 0.080\n",
      "U 159 | F 325632 | FPS 2957 | D 50 | rR:μσmM 0.54 0.32 0.00 0.91 | F:μσmM 159.4 103.2 33.0 324.0 | H 1.773 | V 0.238 | pL -0.022 | vL 0.019 | ∇ 0.101\n",
      "U 160 | F 327680 | FPS 3108 | D 51 | rR:μσmM 0.67 0.22 0.00 0.89 | F:μσmM 117.3 74.5 38.0 324.0 | H 1.747 | V 0.255 | pL -0.020 | vL 0.014 | ∇ 0.100\n",
      "Status saved\n",
      "U 161 | F 329728 | FPS 3019 | D 51 | rR:μσmM 0.60 0.25 0.00 0.85 | F:μσmM 139.0 78.5 55.0 324.0 | H 1.755 | V 0.248 | pL 0.007 | vL 0.017 | ∇ 0.136\n",
      "U 162 | F 331776 | FPS 2993 | D 52 | rR:μσmM 0.61 0.28 0.00 0.94 | F:μσmM 136.8 94.3 23.0 324.0 | H 1.730 | V 0.308 | pL -0.007 | vL 0.019 | ∇ 0.120\n",
      "U 163 | F 333824 | FPS 2775 | D 53 | rR:μσmM 0.60 0.28 0.00 0.93 | F:μσmM 141.2 92.6 27.0 324.0 | H 1.748 | V 0.295 | pL -0.005 | vL 0.015 | ∇ 0.096\n",
      "U 164 | F 335872 | FPS 2322 | D 54 | rR:μσmM 0.71 0.14 0.38 0.88 | F:μσmM 103.7 51.8 42.0 224.0 | H 1.738 | V 0.320 | pL -0.014 | vL 0.018 | ∇ 0.117\n",
      "U 165 | F 337920 | FPS 2591 | D 55 | rR:μσmM 0.65 0.31 0.00 0.93 | F:μσmM 121.9 102.6 27.0 324.0 | H 1.732 | V 0.314 | pL -0.013 | vL 0.024 | ∇ 0.135\n",
      "U 166 | F 339968 | FPS 2941 | D 55 | rR:μσmM 0.66 0.25 0.00 0.91 | F:μσmM 120.3 84.1 33.0 324.0 | H 1.714 | V 0.338 | pL -0.010 | vL 0.025 | ∇ 0.158\n",
      "U 167 | F 342016 | FPS 3081 | D 56 | rR:μσmM 0.59 0.28 0.00 0.91 | F:μσmM 142.1 91.3 33.0 324.0 | H 1.755 | V 0.255 | pL 0.041 | vL 0.013 | ∇ 0.099\n",
      "U 168 | F 344064 | FPS 3003 | D 57 | rR:μσmM 0.56 0.29 0.00 0.90 | F:μσmM 154.7 96.6 35.0 324.0 | H 1.714 | V 0.283 | pL -0.009 | vL 0.017 | ∇ 0.105\n",
      "U 169 | F 346112 | FPS 3122 | D 57 | rR:μσmM 0.65 0.24 0.00 0.91 | F:μσmM 125.2 80.4 34.0 324.0 | H 1.725 | V 0.290 | pL -0.017 | vL 0.020 | ∇ 0.102\n",
      "U 170 | F 348160 | FPS 2715 | D 58 | rR:μσmM 0.67 0.24 0.00 0.95 | F:μσmM 118.0 81.5 17.0 324.0 | H 1.709 | V 0.260 | pL 0.007 | vL 0.015 | ∇ 0.101\n",
      "Status saved\n",
      "U 171 | F 350208 | FPS 3107 | D 59 | rR:μσmM 0.54 0.36 0.00 0.95 | F:μσmM 158.4 118.7 17.0 324.0 | H 1.775 | V 0.205 | pL 0.050 | vL 0.011 | ∇ 0.071\n",
      "U 172 | F 352256 | FPS 3118 | D 59 | rR:μσmM 0.50 0.33 0.00 0.94 | F:μσmM 174.2 107.6 22.0 324.0 | H 1.763 | V 0.210 | pL -0.008 | vL 0.015 | ∇ 0.108\n",
      "U 173 | F 354304 | FPS 3121 | D 60 | rR:μσmM 0.64 0.32 0.00 0.93 | F:μσmM 126.9 106.2 25.0 324.0 | H 1.698 | V 0.319 | pL -0.053 | vL 0.033 | ∇ 0.180\n",
      "U 174 | F 356352 | FPS 3053 | D 61 | rR:μσmM 0.71 0.17 0.28 0.94 | F:μσmM 103.1 60.7 22.0 258.0 | H 1.743 | V 0.287 | pL 0.009 | vL 0.013 | ∇ 0.097\n",
      "U 175 | F 358400 | FPS 2527 | D 62 | rR:μσmM 0.59 0.29 0.00 0.93 | F:μσmM 143.9 99.0 25.0 324.0 | H 1.753 | V 0.252 | pL 0.021 | vL 0.017 | ∇ 0.097\n",
      "U 176 | F 360448 | FPS 2333 | D 62 | rR:μσmM 0.49 0.31 0.00 0.84 | F:μσmM 175.9 101.8 59.0 324.0 | H 1.756 | V 0.251 | pL 0.027 | vL 0.010 | ∇ 0.096\n",
      "U 177 | F 362496 | FPS 1766 | D 64 | rR:μσmM 0.62 0.32 0.00 0.94 | F:μσmM 131.5 108.8 20.0 324.0 | H 1.720 | V 0.269 | pL -0.018 | vL 0.026 | ∇ 0.125\n",
      "U 178 | F 364544 | FPS 2986 | D 64 | rR:μσmM 0.61 0.28 0.00 0.93 | F:μσmM 139.6 97.1 27.0 324.0 | H 1.738 | V 0.247 | pL 0.000 | vL 0.018 | ∇ 0.117\n",
      "U 179 | F 366592 | FPS 3086 | D 65 | rR:μσmM 0.59 0.22 0.00 0.88 | F:μσmM 144.1 74.5 44.0 324.0 | H 1.722 | V 0.287 | pL -0.022 | vL 0.017 | ∇ 0.106\n",
      "U 180 | F 368640 | FPS 2764 | D 66 | rR:μσmM 0.71 0.24 0.22 0.91 | F:μσmM 106.1 85.4 34.0 280.0 | H 1.737 | V 0.252 | pL 0.007 | vL 0.016 | ∇ 0.093\n",
      "Status saved\n",
      "U 181 | F 370688 | FPS 3022 | D 66 | rR:μσmM 0.51 0.34 0.00 0.89 | F:μσmM 169.4 111.0 40.0 324.0 | H 1.775 | V 0.191 | pL 0.039 | vL 0.012 | ∇ 0.088\n",
      "U 182 | F 372736 | FPS 2773 | D 67 | rR:μσmM 0.56 0.36 0.00 0.92 | F:μσmM 149.3 115.7 29.0 324.0 | H 1.741 | V 0.273 | pL -0.046 | vL 0.022 | ∇ 0.119\n",
      "U 183 | F 374784 | FPS 2942 | D 68 | rR:μσmM 0.70 0.24 0.00 0.94 | F:μσmM 104.1 81.3 22.0 324.0 | H 1.728 | V 0.295 | pL -0.029 | vL 0.023 | ∇ 0.123\n",
      "U 184 | F 376832 | FPS 3114 | D 68 | rR:μσmM 0.55 0.31 0.00 0.93 | F:μσmM 159.2 103.8 27.0 324.0 | H 1.731 | V 0.244 | pL 0.012 | vL 0.017 | ∇ 0.106\n",
      "U 185 | F 378880 | FPS 3098 | D 69 | rR:μσmM 0.61 0.29 0.00 0.89 | F:μσmM 135.3 96.3 40.0 324.0 | H 1.723 | V 0.220 | pL -0.000 | vL 0.019 | ∇ 0.112\n",
      "U 186 | F 380928 | FPS 3147 | D 70 | rR:μσmM 0.57 0.36 0.00 0.94 | F:μσmM 147.2 115.3 20.0 324.0 | H 1.726 | V 0.226 | pL 0.014 | vL 0.017 | ∇ 0.101\n",
      "U 187 | F 382976 | FPS 3140 | D 70 | rR:μσmM 0.54 0.34 0.00 0.89 | F:μσmM 159.8 115.0 39.0 324.0 | H 1.708 | V 0.246 | pL -0.008 | vL 0.022 | ∇ 0.113\n",
      "U 188 | F 385024 | FPS 3086 | D 71 | rR:μσmM 0.71 0.26 0.00 0.93 | F:μσmM 103.6 88.4 26.0 324.0 | H 1.703 | V 0.233 | pL -0.013 | vL 0.021 | ∇ 0.115\n",
      "U 189 | F 387072 | FPS 3130 | D 72 | rR:μσmM 0.59 0.27 0.00 0.93 | F:μσmM 144.6 93.7 27.0 324.0 | H 1.661 | V 0.250 | pL -0.017 | vL 0.021 | ∇ 0.111\n",
      "U 190 | F 389120 | FPS 3140 | D 72 | rR:μσmM 0.71 0.26 0.00 0.95 | F:μσmM 102.2 90.2 19.0 324.0 | H 1.615 | V 0.366 | pL -0.096 | vL 0.032 | ∇ 0.173\n",
      "Status saved\n",
      "U 191 | F 391168 | FPS 3199 | D 73 | rR:μσmM 0.78 0.17 0.25 0.96 | F:μσmM 79.8 61.6 16.0 271.0 | H 1.608 | V 0.392 | pL -0.031 | vL 0.023 | ∇ 0.125\n",
      "U 192 | F 393216 | FPS 3156 | D 74 | rR:μσmM 0.73 0.24 0.00 0.95 | F:μσmM 95.6 81.3 17.0 324.0 | H 1.625 | V 0.397 | pL -0.017 | vL 0.021 | ∇ 0.122\n",
      "U 193 | F 395264 | FPS 3135 | D 74 | rR:μσmM 0.75 0.22 0.00 0.95 | F:μσmM 86.9 74.0 17.0 324.0 | H 1.596 | V 0.422 | pL -0.003 | vL 0.027 | ∇ 0.161\n",
      "U 194 | F 397312 | FPS 3195 | D 75 | rR:μσmM 0.78 0.22 0.00 0.95 | F:μσmM 79.1 74.8 17.0 324.0 | H 1.560 | V 0.455 | pL -0.019 | vL 0.025 | ∇ 0.138\n",
      "U 195 | F 399360 | FPS 3163 | D 76 | rR:μσmM 0.78 0.20 0.00 0.94 | F:μσmM 78.3 68.7 21.0 324.0 | H 1.571 | V 0.469 | pL -0.040 | vL 0.019 | ∇ 0.124\n",
      "U 196 | F 401408 | FPS 3206 | D 76 | rR:μσmM 0.81 0.16 0.40 0.94 | F:μσmM 68.0 57.9 20.0 217.0 | H 1.606 | V 0.427 | pL 0.033 | vL 0.020 | ∇ 0.123\n",
      "U 197 | F 403456 | FPS 3187 | D 77 | rR:μσmM 0.73 0.25 0.00 0.95 | F:μσmM 92.9 83.5 17.0 324.0 | H 1.580 | V 0.410 | pL 0.032 | vL 0.026 | ∇ 0.155\n",
      "U 198 | F 405504 | FPS 3065 | D 78 | rR:μσmM 0.79 0.19 0.00 0.96 | F:μσmM 73.9 65.7 16.0 324.0 | H 1.532 | V 0.483 | pL -0.040 | vL 0.024 | ∇ 0.116\n",
      "U 199 | F 407552 | FPS 3118 | D 78 | rR:μσmM 0.77 0.22 0.00 0.95 | F:μσmM 81.3 73.2 19.0 324.0 | H 1.583 | V 0.435 | pL 0.024 | vL 0.023 | ∇ 0.131\n",
      "U 200 | F 409600 | FPS 3198 | D 79 | rR:μσmM 0.78 0.23 0.00 0.94 | F:μσmM 79.4 77.8 22.0 324.0 | H 1.611 | V 0.443 | pL 0.007 | vL 0.027 | ∇ 0.128\n",
      "Status saved\n",
      "U 201 | F 411648 | FPS 3120 | D 80 | rR:μσmM 0.78 0.17 0.31 0.94 | F:μσmM 79.6 59.4 22.0 247.0 | H 1.594 | V 0.420 | pL 0.015 | vL 0.020 | ∇ 0.120\n",
      "U 202 | F 413696 | FPS 3196 | D 80 | rR:μσmM 0.75 0.24 0.00 0.93 | F:μσmM 89.2 81.9 25.0 324.0 | H 1.605 | V 0.377 | pL 0.034 | vL 0.023 | ∇ 0.124\n",
      "U 203 | F 415744 | FPS 2839 | D 81 | rR:μσmM 0.75 0.17 0.16 0.94 | F:μσmM 91.6 60.0 21.0 302.0 | H 1.573 | V 0.469 | pL -0.045 | vL 0.022 | ∇ 0.133\n",
      "U 204 | F 417792 | FPS 2961 | D 82 | rR:μσmM 0.82 0.19 0.00 0.95 | F:μσmM 63.6 62.4 19.0 324.0 | H 1.594 | V 0.455 | pL -0.004 | vL 0.026 | ∇ 0.140\n",
      "U 205 | F 419840 | FPS 3005 | D 82 | rR:μσmM 0.72 0.20 0.23 0.94 | F:μσmM 99.3 73.6 23.0 276.0 | H 1.666 | V 0.412 | pL 0.020 | vL 0.018 | ∇ 0.142\n",
      "U 206 | F 421888 | FPS 2863 | D 83 | rR:μσmM 0.78 0.18 0.00 0.93 | F:μσmM 77.6 58.6 24.0 324.0 | H 1.626 | V 0.455 | pL -0.034 | vL 0.023 | ∇ 0.148\n",
      "U 207 | F 423936 | FPS 2963 | D 84 | rR:μσmM 0.71 0.25 0.00 0.94 | F:μσmM 103.5 83.8 22.0 324.0 | H 1.669 | V 0.413 | pL 0.035 | vL 0.019 | ∇ 0.130\n",
      "U 208 | F 425984 | FPS 2939 | D 85 | rR:μσmM 0.72 0.18 0.35 0.93 | F:μσmM 100.1 63.7 26.0 234.0 | H 1.694 | V 0.354 | pL 0.053 | vL 0.013 | ∇ 0.103\n",
      "U 209 | F 428032 | FPS 3103 | D 85 | rR:μσmM 0.60 0.28 0.00 0.93 | F:μσmM 142.3 97.9 25.0 324.0 | H 1.706 | V 0.331 | pL 0.023 | vL 0.019 | ∇ 0.129\n",
      "U 210 | F 430080 | FPS 3040 | D 86 | rR:μσmM 0.72 0.24 0.00 0.94 | F:μσmM 98.9 79.6 20.0 324.0 | H 1.670 | V 0.337 | pL 0.003 | vL 0.023 | ∇ 0.133\n",
      "Status saved\n",
      "U 211 | F 432128 | FPS 3095 | D 87 | rR:μσmM 0.68 0.20 0.11 0.91 | F:μσmM 114.1 72.7 33.0 322.0 | H 1.675 | V 0.359 | pL -0.016 | vL 0.019 | ∇ 0.102\n",
      "U 212 | F 434176 | FPS 3001 | D 87 | rR:μσmM 0.67 0.25 0.00 0.90 | F:μσmM 116.6 83.3 35.0 324.0 | H 1.671 | V 0.352 | pL -0.007 | vL 0.020 | ∇ 0.117\n",
      "U 213 | F 436224 | FPS 2960 | D 88 | rR:μσmM 0.71 0.26 0.00 0.92 | F:μσmM 103.6 87.6 30.0 324.0 | H 1.680 | V 0.354 | pL -0.020 | vL 0.025 | ∇ 0.129\n",
      "U 214 | F 438272 | FPS 3014 | D 89 | rR:μσmM 0.74 0.21 0.00 0.91 | F:μσmM 91.8 69.8 33.0 324.0 | H 1.687 | V 0.363 | pL -0.015 | vL 0.019 | ∇ 0.127\n",
      "U 215 | F 440320 | FPS 3122 | D 89 | rR:μσmM 0.71 0.24 0.00 0.93 | F:μσmM 101.0 79.2 27.0 324.0 | H 1.679 | V 0.347 | pL -0.000 | vL 0.022 | ∇ 0.141\n",
      "U 216 | F 442368 | FPS 3000 | D 90 | rR:μσmM 0.60 0.31 0.00 0.93 | F:μσmM 139.3 100.5 25.0 324.0 | H 1.643 | V 0.330 | pL 0.009 | vL 0.021 | ∇ 0.123\n",
      "U 217 | F 444416 | FPS 3227 | D 91 | rR:μσmM 0.74 0.24 0.00 0.93 | F:μσmM 92.6 83.1 26.0 324.0 | H 1.567 | V 0.404 | pL -0.056 | vL 0.027 | ∇ 0.153\n",
      "U 218 | F 446464 | FPS 3183 | D 91 | rR:μσmM 0.84 0.10 0.54 0.96 | F:μσmM 58.7 35.8 16.0 167.0 | H 1.531 | V 0.475 | pL -0.062 | vL 0.027 | ∇ 0.170\n",
      "U 219 | F 448512 | FPS 3018 | D 92 | rR:μσmM 0.81 0.20 0.00 0.96 | F:μσmM 68.0 66.0 16.0 324.0 | H 1.496 | V 0.470 | pL 0.025 | vL 0.024 | ∇ 0.136\n",
      "U 220 | F 450560 | FPS 2983 | D 93 | rR:μσmM 0.74 0.25 0.00 0.96 | F:μσmM 92.9 83.9 16.0 324.0 | H 1.593 | V 0.381 | pL 0.031 | vL 0.019 | ∇ 0.125\n",
      "Status saved\n",
      "U 221 | F 452608 | FPS 2968 | D 93 | rR:μσmM 0.73 0.26 0.00 0.95 | F:μσmM 96.2 87.0 19.0 324.0 | H 1.563 | V 0.412 | pL 0.017 | vL 0.023 | ∇ 0.150\n",
      "U 222 | F 454656 | FPS 2777 | D 94 | rR:μσmM 0.80 0.17 0.21 0.94 | F:μσmM 73.8 59.9 21.0 284.0 | H 1.565 | V 0.460 | pL -0.059 | vL 0.025 | ∇ 0.129\n",
      "U 223 | F 456704 | FPS 2969 | D 95 | rR:μσmM 0.79 0.18 0.00 0.94 | F:μσmM 75.6 60.9 21.0 324.0 | H 1.577 | V 0.486 | pL -0.032 | vL 0.021 | ∇ 0.123\n",
      "U 224 | F 458752 | FPS 2817 | D 95 | rR:μσmM 0.79 0.17 0.20 0.93 | F:μσmM 74.6 62.0 25.0 289.0 | H 1.569 | V 0.492 | pL 0.008 | vL 0.018 | ∇ 0.126\n",
      "U 225 | F 460800 | FPS 2728 | D 96 | rR:μσmM 0.79 0.17 0.24 0.94 | F:μσmM 74.2 62.6 22.0 272.0 | H 1.587 | V 0.450 | pL 0.036 | vL 0.020 | ∇ 0.141\n",
      "U 226 | F 462848 | FPS 2810 | D 97 | rR:μσmM 0.78 0.19 0.26 0.95 | F:μσmM 80.4 66.8 19.0 268.0 | H 1.562 | V 0.460 | pL 0.003 | vL 0.019 | ∇ 0.129\n",
      "U 227 | F 464896 | FPS 2822 | D 98 | rR:μσmM 0.74 0.22 0.00 0.94 | F:μσmM 90.7 75.6 22.0 324.0 | H 1.579 | V 0.436 | pL 0.009 | vL 0.021 | ∇ 0.109\n",
      "U 228 | F 466944 | FPS 3007 | D 98 | rR:μσmM 0.76 0.19 0.00 0.92 | F:μσmM 85.0 64.7 28.0 324.0 | H 1.555 | V 0.466 | pL -0.014 | vL 0.020 | ∇ 0.120\n",
      "U 229 | F 468992 | FPS 3101 | D 99 | rR:μσmM 0.83 0.14 0.32 0.95 | F:μσmM 61.4 48.8 19.0 246.0 | H 1.572 | V 0.448 | pL -0.008 | vL 0.022 | ∇ 0.128\n",
      "U 230 | F 471040 | FPS 3204 | D 100 | rR:μσmM 0.74 0.26 0.00 0.95 | F:μσmM 91.0 85.4 18.0 324.0 | H 1.600 | V 0.389 | pL 0.043 | vL 0.022 | ∇ 0.125\n",
      "Status saved\n",
      "U 231 | F 473088 | FPS 3003 | D 100 | rR:μσmM 0.69 0.26 0.00 0.93 | F:μσmM 108.1 85.1 25.0 324.0 | H 1.597 | V 0.427 | pL -0.002 | vL 0.021 | ∇ 0.132\n",
      "U 232 | F 475136 | FPS 3256 | D 101 | rR:μσmM 0.78 0.17 0.20 0.94 | F:μσmM 80.0 59.9 21.0 287.0 | H 1.618 | V 0.413 | pL -0.004 | vL 0.021 | ∇ 0.113\n",
      "U 233 | F 477184 | FPS 3280 | D 102 | rR:μσmM 0.72 0.23 0.00 0.91 | F:μσmM 101.0 80.5 31.0 324.0 | H 1.604 | V 0.445 | pL -0.038 | vL 0.023 | ∇ 0.116\n",
      "U 234 | F 479232 | FPS 1953 | D 103 | rR:μσmM 0.84 0.08 0.56 0.93 | F:μσmM 56.6 29.0 25.0 160.0 | H 1.581 | V 0.541 | pL -0.059 | vL 0.014 | ∇ 0.098\n",
      "U 235 | F 481280 | FPS 2826 | D 103 | rR:μσmM 0.85 0.08 0.64 0.93 | F:μσmM 55.5 28.4 26.0 128.0 | H 1.558 | V 0.537 | pL -0.004 | vL 0.015 | ∇ 0.093\n",
      "U 236 | F 483328 | FPS 2579 | D 104 | rR:μσmM 0.79 0.18 0.29 0.94 | F:μσmM 74.7 65.1 22.0 254.0 | H 1.550 | V 0.492 | pL 0.025 | vL 0.022 | ∇ 0.110\n",
      "U 237 | F 485376 | FPS 2425 | D 105 | rR:μσmM 0.80 0.13 0.53 0.96 | F:μσmM 71.8 45.0 16.0 170.0 | H 1.590 | V 0.464 | pL 0.006 | vL 0.018 | ∇ 0.104\n",
      "U 238 | F 487424 | FPS 2810 | D 106 | rR:μσmM 0.77 0.21 0.00 0.94 | F:μσmM 82.9 70.9 20.0 324.0 | H 1.529 | V 0.503 | pL -0.027 | vL 0.019 | ∇ 0.113\n",
      "U 239 | F 489472 | FPS 2892 | D 107 | rR:μσmM 0.80 0.15 0.19 0.93 | F:μσmM 71.9 55.4 27.0 293.0 | H 1.580 | V 0.484 | pL 0.030 | vL 0.017 | ∇ 0.112\n",
      "U 240 | F 491520 | FPS 3011 | D 107 | rR:μσmM 0.79 0.20 0.00 0.93 | F:μσmM 72.9 65.9 26.0 324.0 | H 1.579 | V 0.484 | pL -0.015 | vL 0.018 | ∇ 0.118\n",
      "Status saved\n",
      "U 241 | F 493568 | FPS 3105 | D 108 | rR:μσmM 0.74 0.24 0.00 0.92 | F:μσmM 92.4 76.4 30.0 324.0 | H 1.641 | V 0.440 | pL 0.013 | vL 0.018 | ∇ 0.104\n",
      "U 242 | F 495616 | FPS 3342 | D 109 | rR:μσmM 0.78 0.17 0.21 0.93 | F:μσmM 78.2 61.8 26.0 286.0 | H 1.608 | V 0.450 | pL 0.025 | vL 0.020 | ∇ 0.111\n",
      "U 243 | F 497664 | FPS 3312 | D 109 | rR:μσmM 0.74 0.25 0.00 0.95 | F:μσmM 92.5 84.3 19.0 324.0 | H 1.643 | V 0.379 | pL 0.038 | vL 0.020 | ∇ 0.120\n",
      "U 244 | F 499712 | FPS 3122 | D 110 | rR:μσmM 0.74 0.22 0.19 0.90 | F:μσmM 92.5 78.1 36.0 293.0 | H 1.633 | V 0.382 | pL 0.020 | vL 0.021 | ∇ 0.129\n",
      "U 245 | F 501760 | FPS 3112 | D 110 | rR:μσmM 0.68 0.30 0.00 0.91 | F:μσmM 110.8 94.7 33.0 324.0 | H 1.630 | V 0.367 | pL -0.006 | vL 0.022 | ∇ 0.125\n",
      "U 246 | F 503808 | FPS 3147 | D 111 | rR:μσmM 0.78 0.24 0.00 0.94 | F:μσmM 77.2 81.9 22.0 324.0 | H 1.591 | V 0.461 | pL -0.034 | vL 0.028 | ∇ 0.155\n",
      "U 247 | F 505856 | FPS 3076 | D 112 | rR:μσmM 0.80 0.16 0.23 0.94 | F:μσmM 72.2 56.5 23.0 277.0 | H 1.573 | V 0.513 | pL -0.037 | vL 0.025 | ∇ 0.137\n",
      "U 248 | F 507904 | FPS 3098 | D 112 | rR:μσmM 0.81 0.15 0.34 0.94 | F:μσmM 68.6 55.4 23.0 237.0 | H 1.553 | V 0.526 | pL -0.036 | vL 0.020 | ∇ 0.124\n",
      "U 249 | F 509952 | FPS 3067 | D 113 | rR:μσmM 0.81 0.16 0.00 0.92 | F:μσmM 66.2 51.4 29.0 324.0 | H 1.561 | V 0.533 | pL -0.001 | vL 0.017 | ∇ 0.122\n",
      "U 250 | F 512000 | FPS 3015 | D 114 | rR:μσmM 0.80 0.12 0.40 0.91 | F:μσmM 70.8 44.7 31.0 215.0 | H 1.594 | V 0.481 | pL 0.042 | vL 0.016 | ∇ 0.108\n",
      "Status saved\n",
      "U 251 | F 514048 | FPS 3120 | D 114 | rR:μσmM 0.73 0.18 0.35 0.90 | F:μσmM 95.9 65.5 36.0 235.0 | H 1.661 | V 0.427 | pL 0.044 | vL 0.016 | ∇ 0.099\n",
      "U 252 | F 516096 | FPS 3194 | D 115 | rR:μσmM 0.76 0.13 0.38 0.90 | F:μσmM 85.9 45.4 36.0 225.0 | H 1.723 | V 0.367 | pL 0.045 | vL 0.011 | ∇ 0.083\n",
      "U 253 | F 518144 | FPS 3139 | D 116 | rR:μσmM 0.55 0.31 0.00 0.91 | F:μσmM 156.0 103.1 33.0 324.0 | H 1.704 | V 0.371 | pL 0.032 | vL 0.020 | ∇ 0.108\n",
      "U 254 | F 520192 | FPS 3141 | D 116 | rR:μσmM 0.73 0.21 0.00 0.91 | F:μσmM 95.2 69.6 31.0 324.0 | H 1.691 | V 0.417 | pL -0.029 | vL 0.018 | ∇ 0.091\n",
      "U 255 | F 522240 | FPS 3081 | D 117 | rR:μσmM 0.80 0.13 0.35 0.92 | F:μσmM 72.4 46.7 30.0 233.0 | H 1.677 | V 0.467 | pL -0.058 | vL 0.015 | ∇ 0.104\n",
      "U 256 | F 524288 | FPS 2632 | D 118 | rR:μσmM 0.79 0.13 0.41 0.92 | F:μσmM 76.0 47.6 30.0 211.0 | H 1.704 | V 0.421 | pL 0.022 | vL 0.012 | ∇ 0.089\n",
      "U 257 | F 526336 | FPS 3115 | D 119 | rR:μσmM 0.73 0.22 0.00 0.94 | F:μσmM 96.6 75.5 22.0 324.0 | H 1.710 | V 0.421 | pL 0.027 | vL 0.020 | ∇ 0.116\n",
      "U 258 | F 528384 | FPS 2446 | D 119 | rR:μσmM 0.70 0.27 0.00 0.94 | F:μσmM 105.0 87.9 20.0 324.0 | H 1.705 | V 0.383 | pL 0.029 | vL 0.022 | ∇ 0.100\n",
      "U 259 | F 530432 | FPS 3050 | D 120 | rR:μσmM 0.65 0.24 0.00 0.91 | F:μσmM 122.2 80.7 34.0 324.0 | H 1.727 | V 0.310 | pL 0.052 | vL 0.011 | ∇ 0.090\n",
      "U 260 | F 532480 | FPS 3027 | D 121 | rR:μσmM 0.56 0.28 0.00 0.94 | F:μσmM 154.6 98.1 23.0 324.0 | H 1.733 | V 0.290 | pL 0.037 | vL 0.016 | ∇ 0.092\n",
      "Status saved\n",
      "U 261 | F 534528 | FPS 3091 | D 121 | rR:μσmM 0.74 0.23 0.00 0.91 | F:μσmM 90.5 77.1 31.0 324.0 | H 1.704 | V 0.345 | pL -0.053 | vL 0.023 | ∇ 0.122\n",
      "U 262 | F 536576 | FPS 3229 | D 122 | rR:μσmM 0.62 0.27 0.00 0.91 | F:μσmM 135.1 91.4 33.0 324.0 | H 1.727 | V 0.291 | pL 0.026 | vL 0.015 | ∇ 0.091\n",
      "U 263 | F 538624 | FPS 3145 | D 123 | rR:μσmM 0.66 0.21 0.28 0.92 | F:μσmM 122.8 74.4 28.0 260.0 | H 1.760 | V 0.275 | pL 0.025 | vL 0.011 | ∇ 0.080\n",
      "U 264 | F 540672 | FPS 3250 | D 123 | rR:μσmM 0.45 0.36 0.00 0.91 | F:μσmM 188.3 114.9 33.0 324.0 | H 1.755 | V 0.228 | pL 0.039 | vL 0.014 | ∇ 0.093\n",
      "U 265 | F 542720 | FPS 3294 | D 124 | rR:μσmM 0.72 0.23 0.00 0.87 | F:μσmM 99.6 77.3 47.0 324.0 | H 1.742 | V 0.279 | pL -0.044 | vL 0.019 | ∇ 0.123\n",
      "U 266 | F 544768 | FPS 3270 | D 125 | rR:μσmM 0.62 0.33 0.00 0.93 | F:μσmM 130.8 106.1 26.0 324.0 | H 1.705 | V 0.320 | pL -0.012 | vL 0.022 | ∇ 0.114\n",
      "U 267 | F 546816 | FPS 3222 | D 125 | rR:μσmM 0.76 0.21 0.00 0.92 | F:μσmM 83.8 68.7 30.0 324.0 | H 1.734 | V 0.291 | pL -0.005 | vL 0.018 | ∇ 0.110\n",
      "U 268 | F 548864 | FPS 3198 | D 126 | rR:μσmM 0.60 0.35 0.00 0.94 | F:μσmM 135.2 111.2 21.0 324.0 | H 1.689 | V 0.314 | pL -0.010 | vL 0.023 | ∇ 0.118\n",
      "U 269 | F 550912 | FPS 3237 | D 127 | rR:μσmM 0.61 0.34 0.00 0.93 | F:μσmM 135.2 111.2 25.0 324.0 | H 1.718 | V 0.301 | pL 0.002 | vL 0.020 | ∇ 0.110\n",
      "U 270 | F 552960 | FPS 3240 | D 127 | rR:μσmM 0.69 0.26 0.00 0.93 | F:μσmM 109.1 88.2 26.0 324.0 | H 1.715 | V 0.310 | pL 0.002 | vL 0.020 | ∇ 0.118\n",
      "Status saved\n",
      "U 271 | F 555008 | FPS 3291 | D 128 | rR:μσmM 0.65 0.27 0.00 0.92 | F:μσmM 121.4 88.5 29.0 324.0 | H 1.668 | V 0.355 | pL -0.029 | vL 0.021 | ∇ 0.133\n",
      "U 272 | F 557056 | FPS 3163 | D 128 | rR:μσmM 0.79 0.20 0.00 0.94 | F:μσmM 75.9 66.3 23.0 324.0 | H 1.608 | V 0.425 | pL -0.080 | vL 0.025 | ∇ 0.147\n",
      "U 273 | F 559104 | FPS 3337 | D 129 | rR:μσmM 0.75 0.25 0.00 0.95 | F:μσmM 89.1 82.0 18.0 324.0 | H 1.649 | V 0.364 | pL 0.033 | vL 0.019 | ∇ 0.109\n",
      "U 274 | F 561152 | FPS 3221 | D 130 | rR:μσmM 0.67 0.31 0.00 0.94 | F:μσmM 114.9 103.0 23.0 324.0 | H 1.643 | V 0.314 | pL 0.042 | vL 0.023 | ∇ 0.131\n",
      "U 275 | F 563200 | FPS 2920 | D 130 | rR:μσmM 0.66 0.32 0.00 0.93 | F:μσmM 118.4 104.6 25.0 324.0 | H 1.665 | V 0.318 | pL -0.003 | vL 0.023 | ∇ 0.130\n",
      "U 276 | F 565248 | FPS 3074 | D 131 | rR:μσmM 0.63 0.34 0.00 0.94 | F:μσmM 125.9 111.0 21.0 324.0 | H 1.662 | V 0.302 | pL 0.001 | vL 0.019 | ∇ 0.127\n",
      "U 277 | F 567296 | FPS 3105 | D 132 | rR:μσmM 0.63 0.27 0.00 0.95 | F:μσmM 131.8 91.5 17.0 324.0 | H 1.627 | V 0.277 | pL 0.026 | vL 0.021 | ∇ 0.119\n",
      "U 278 | F 569344 | FPS 3243 | D 132 | rR:μσmM 0.61 0.33 0.00 0.95 | F:μσmM 136.4 111.9 19.0 324.0 | H 1.631 | V 0.287 | pL -0.000 | vL 0.024 | ∇ 0.113\n",
      "U 279 | F 571392 | FPS 3235 | D 133 | rR:μσmM 0.81 0.12 0.50 0.94 | F:μσmM 67.9 44.9 23.0 179.0 | H 1.578 | V 0.372 | pL -0.073 | vL 0.027 | ∇ 0.152\n",
      "U 280 | F 573440 | FPS 3341 | D 134 | rR:μσmM 0.72 0.30 0.00 0.93 | F:μσmM 99.3 104.6 26.0 324.0 | H 1.572 | V 0.390 | pL -0.019 | vL 0.034 | ∇ 0.146\n",
      "Status saved\n",
      "U 281 | F 575488 | FPS 3298 | D 134 | rR:μσmM 0.84 0.14 0.33 0.95 | F:μσmM 58.0 50.8 18.0 241.0 | H 1.518 | V 0.453 | pL -0.030 | vL 0.028 | ∇ 0.129\n",
      "U 282 | F 577536 | FPS 3344 | D 135 | rR:μσmM 0.80 0.23 0.00 0.95 | F:μσmM 68.1 73.7 19.0 324.0 | H 1.521 | V 0.464 | pL -0.029 | vL 0.027 | ∇ 0.138\n",
      "U 283 | F 579584 | FPS 3302 | D 135 | rR:μσmM 0.74 0.22 0.00 0.94 | F:μσmM 91.6 73.2 22.0 324.0 | H 1.569 | V 0.448 | pL -0.027 | vL 0.025 | ∇ 0.132\n",
      "U 284 | F 581632 | FPS 3263 | D 136 | rR:μσmM 0.82 0.13 0.40 0.95 | F:μσmM 64.4 46.6 18.0 216.0 | H 1.514 | V 0.537 | pL -0.055 | vL 0.022 | ∇ 0.152\n",
      "U 285 | F 583680 | FPS 3209 | D 137 | rR:μσmM 0.84 0.13 0.35 0.96 | F:μσmM 57.3 45.8 15.0 233.0 | H 1.426 | V 0.574 | pL -0.036 | vL 0.021 | ∇ 0.118\n",
      "U 286 | F 585728 | FPS 3196 | D 137 | rR:μσmM 0.86 0.12 0.30 0.95 | F:μσmM 52.1 42.3 19.0 253.0 | H 1.470 | V 0.573 | pL -0.017 | vL 0.020 | ∇ 0.118\n",
      "U 287 | F 587776 | FPS 3182 | D 138 | rR:μσmM 0.86 0.07 0.71 0.96 | F:μσmM 49.1 24.3 15.0 104.0 | H 1.512 | V 0.524 | pL 0.011 | vL 0.017 | ∇ 0.109\n",
      "U 288 | F 589824 | FPS 3237 | D 139 | rR:μσmM 0.81 0.19 0.00 0.95 | F:μσmM 66.3 65.0 17.0 324.0 | H 1.485 | V 0.512 | pL 0.026 | vL 0.026 | ∇ 0.130\n",
      "U 289 | F 591872 | FPS 3196 | D 139 | rR:μσmM 0.76 0.23 0.00 0.95 | F:μσmM 86.7 79.5 19.0 324.0 | H 1.530 | V 0.490 | pL 0.052 | vL 0.023 | ∇ 0.114\n",
      "U 290 | F 593920 | FPS 3321 | D 140 | rR:μσmM 0.85 0.10 0.55 0.94 | F:μσmM 52.7 34.9 22.0 162.0 | H 1.478 | V 0.522 | pL -0.018 | vL 0.020 | ∇ 0.137\n",
      "Status saved\n",
      "U 291 | F 595968 | FPS 3307 | D 141 | rR:μσmM 0.81 0.19 0.00 0.95 | F:μσmM 69.0 64.9 19.0 324.0 | H 1.477 | V 0.558 | pL -0.020 | vL 0.022 | ∇ 0.110\n",
      "U 292 | F 598016 | FPS 3331 | D 141 | rR:μσmM 0.84 0.10 0.52 0.96 | F:μσmM 56.2 36.8 16.0 172.0 | H 1.465 | V 0.597 | pL -0.018 | vL 0.016 | ∇ 0.115\n",
      "U 293 | F 600064 | FPS 3364 | D 142 | rR:μσmM 0.87 0.09 0.50 0.95 | F:μσmM 48.4 32.4 18.0 179.0 | H 1.472 | V 0.619 | pL -0.007 | vL 0.016 | ∇ 0.109\n",
      "Number of frames:  600064\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 3rd environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-SimpleCrossingS9N2-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 4490.0 | FPS 3467 | D 1.0 | R:μσmM 0.86 0.11 0.30 0.96 | F:μσmM 49.5 38.3 16.0 252.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 2214.0 | FPS 3750 | D 0.0 | R:μσmM 0.86 0.12 0.43 0.98 | F:μσmM 22.1 18.6 3.0 92.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 2nd environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 19824.0 | FPS 4294 | D 4.0 | R:μσmM 0.48 0.33 0.00 0.93 | F:μσmM 198.2 117.9 29.0 360.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
