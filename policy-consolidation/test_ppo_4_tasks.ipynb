{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Policy Consolidation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppopc', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'wallgap-doorkey-redblue-crossing', 'early_stop': False, 'seed': 123456, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 500000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 1048, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'cascade_depth': 4, 'flow_factor': 1.0, 'mesh_factor': 4.0, 'lr_decay': True, 'imp_sampling': 'clipped', 'imp_clips': [-5, 5], 'dynamic_neglogpacs': False, 'optimizer_type': 'rmsprop', 'scheduler_flag': False, 'var_init': 'equal', 'reshape_reward': True, 'date': datetime.date(2023, 11, 11), 'mem': False, 'lrs': [0.0007, 0.000175, 4.375e-05, 1.09375e-05], 'lrs_fn': <function decayfn_arr_2.<locals>.f at 0x7f7cc77498c0>, 'clipranges': [0.2, 0.05, 0.0125, 0.003125]}\n",
      "\n",
      "Device: cpu\n",
      "\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden models loaded\n",
      "\n",
      "U 1 | F 016768 | FPS 1896 | D 8 | rR:μσmM 0.05 0.16 0.00 0.81 | F:μσmM 137.1 21.5 30.0 144.0 | H 1.931 | V -0.431 | pL 32.075 | vL 1216.101 | ∇ 6.892\n",
      "U 2 | F 033536 | FPS 2019 | D 17 | rR:μσmM 0.07 0.18 0.00 0.81 | F:μσmM 135.6 24.1 31.0 144.0 | H 1.917 | V -0.820 | pL 31.256 | vL 1170.026 | ∇ 7.194\n",
      "U 3 | F 050304 | FPS 2007 | D 25 | rR:μσmM 0.11 0.24 0.00 0.94 | F:μσmM 129.6 32.9 9.0 144.0 | H 1.907 | V -1.165 | pL 30.785 | vL 1140.584 | ∇ 7.550\n",
      "U 4 | F 067072 | FPS 2046 | D 33 | rR:μσmM 0.14 0.26 0.00 0.92 | F:μσmM 126.0 35.5 13.0 144.0 | H 1.880 | V -1.499 | pL 30.212 | vL 1106.829 | ∇ 8.946\n",
      "U 5 | F 083840 | FPS 2046 | D 41 | rR:μσmM 0.16 0.28 0.00 0.87 | F:μσmM 122.8 38.3 21.0 144.0 | H 1.870 | V -1.790 | pL 29.919 | vL 1090.962 | ∇ 8.993\n",
      "U 6 | F 100608 | FPS 1925 | D 50 | rR:μσmM 0.22 0.31 0.00 0.98 | F:μσmM 115.3 42.9 3.0 144.0 | H 1.861 | V -2.145 | pL 29.232 | vL 1051.527 | ∇ 9.145\n",
      "U 7 | F 117376 | FPS 2088 | D 58 | rR:μσmM 0.32 0.36 0.00 0.98 | F:μσmM 100.9 50.3 3.0 144.0 | H 1.867 | V -2.601 | pL 27.935 | vL 984.965 | ∇ 9.211\n",
      "U 8 | F 134144 | FPS 2060 | D 66 | rR:μσmM 0.35 0.34 0.00 0.98 | F:μσmM 97.2 48.4 3.0 144.0 | H 1.845 | V -3.147 | pL 26.846 | vL 932.681 | ∇ 10.123\n",
      "U 9 | F 150912 | FPS 2069 | D 74 | rR:μσmM 0.33 0.35 0.00 0.96 | F:μσmM 99.6 48.6 6.0 144.0 | H 1.795 | V -3.660 | pL 26.874 | vL 928.873 | ∇ 12.316\n",
      "U 10 | F 167680 | FPS 2051 | D 83 | rR:μσmM 0.38 0.37 0.00 0.98 | F:μσmM 93.1 52.5 3.0 144.0 | H 1.788 | V -4.051 | pL 26.589 | vL 917.408 | ∇ 13.036\n",
      "Status saved\n",
      "U 11 | F 184448 | FPS 2064 | D 91 | rR:μσmM 0.47 0.36 0.00 0.99 | F:μσmM 80.7 52.4 2.0 144.0 | H 1.741 | V -4.554 | pL 25.123 | vL 849.566 | ∇ 13.779\n",
      "U 12 | F 201216 | FPS 2050 | D 99 | rR:μσmM 0.58 0.32 0.00 0.98 | F:μσmM 65.3 47.3 3.0 144.0 | H 1.682 | V -5.079 | pL 21.719 | vL 695.245 | ∇ 14.082\n",
      "U 13 | F 217984 | FPS 1958 | D 107 | rR:μσmM 0.70 0.25 0.00 0.99 | F:μσmM 46.6 37.9 2.0 144.0 | H 1.608 | V -5.483 | pL 17.475 | vL 512.569 | ∇ 14.727\n",
      "U 14 | F 234752 | FPS 2075 | D 116 | rR:μσmM 0.78 0.19 0.00 0.99 | F:μσmM 34.6 29.7 2.0 144.0 | H 1.501 | V -5.658 | pL 12.823 | vL 331.961 | ∇ 12.842\n",
      "U 15 | F 251520 | FPS 1688 | D 126 | rR:μσmM 0.86 0.10 0.39 0.99 | F:μσmM 22.4 16.1 2.0 98.0 | H 1.316 | V -5.778 | pL 6.370 | vL 125.206 | ∇ 11.302\n",
      "U 16 | F 268288 | FPS 1987 | D 134 | rR:μσmM 0.89 0.07 0.51 0.99 | F:μσmM 17.4 11.1 2.0 79.0 | H 1.098 | V -5.807 | pL 3.316 | vL 58.054 | ∇ 10.295\n",
      "U 17 | F 285056 | FPS 2059 | D 142 | rR:μσmM 0.92 0.05 0.67 0.99 | F:μσmM 13.4 7.2 2.0 53.0 | H 0.852 | V -5.450 | pL 1.063 | vL 22.462 | ∇ 8.107\n",
      "U 18 | F 301824 | FPS 2028 | D 150 | rR:μσmM 0.93 0.03 0.70 0.99 | F:μσmM 11.3 5.5 2.0 48.0 | H 0.640 | V -4.912 | pL 0.147 | vL 10.290 | ∇ 6.574\n",
      "U 19 | F 318592 | FPS 2044 | D 159 | rR:μσmM 0.94 0.03 0.77 0.99 | F:μσmM 10.2 4.3 2.0 37.0 | H 0.478 | V -4.400 | pL -0.223 | vL 5.022 | ∇ 5.425\n",
      "U 20 | F 335360 | FPS 1909 | D 167 | rR:μσmM 0.94 0.02 0.81 0.99 | F:μσmM 9.3 3.5 2.0 30.0 | H 0.335 | V -3.857 | pL -0.276 | vL 2.513 | ∇ 3.987\n",
      "Status saved\n",
      "U 21 | F 352128 | FPS 2011 | D 176 | rR:μσmM 0.94 0.02 0.85 0.99 | F:μσmM 8.9 3.0 2.0 24.0 | H 0.258 | V -3.577 | pL -0.384 | vL 1.384 | ∇ 3.408\n",
      "U 22 | F 368896 | FPS 2016 | D 184 | rR:μσmM 0.95 0.02 0.86 0.99 | F:μσmM 8.6 2.6 2.0 23.0 | H 0.169 | V -3.261 | pL -0.250 | vL 0.791 | ∇ 2.287\n",
      "U 23 | F 385664 | FPS 1997 | D 192 | rR:μσmM 0.95 0.02 0.84 0.99 | F:μσmM 8.4 2.5 2.0 26.0 | H 0.131 | V -3.114 | pL -0.285 | vL 0.727 | ∇ 1.974\n",
      "U 24 | F 402432 | FPS 2010 | D 201 | rR:μσmM 0.95 0.01 0.86 0.99 | F:μσmM 8.2 2.4 2.0 23.0 | H 0.085 | V -2.967 | pL -0.215 | vL 0.509 | ∇ 1.815\n",
      "U 25 | F 419200 | FPS 2031 | D 209 | rR:μσmM 0.95 0.01 0.89 0.99 | F:μσmM 8.2 2.3 2.0 18.0 | H 0.065 | V -2.901 | pL -0.218 | vL 0.373 | ∇ 1.521\n",
      "U 26 | F 435968 | FPS 2016 | D 217 | rR:μσmM 0.95 0.01 0.87 0.99 | F:μσmM 8.2 2.3 2.0 21.0 | H 0.047 | V -2.909 | pL -0.184 | vL 0.356 | ∇ 1.327\n",
      "U 27 | F 452736 | FPS 1919 | D 226 | rR:μσmM 0.95 0.01 0.88 0.99 | F:μσmM 8.2 2.2 2.0 20.0 | H 0.044 | V -2.882 | pL -0.097 | vL 0.305 | ∇ 1.311\n",
      "U 28 | F 469504 | FPS 2028 | D 234 | rR:μσmM 0.95 0.01 0.88 0.99 | F:μσmM 8.2 2.3 2.0 20.0 | H 0.042 | V -2.853 | pL 0.064 | vL 0.312 | ∇ 1.143\n",
      "U 29 | F 486272 | FPS 1682 | D 244 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.2 2.1 2.0 15.0 | H 0.031 | V -2.837 | pL 0.030 | vL 0.255 | ∇ 1.090\n",
      "U 30 | F 503040 | FPS 1887 | D 253 | rR:μσmM 0.95 0.01 0.89 0.99 | F:μσmM 8.1 2.2 2.0 17.0 | H 0.026 | V -2.799 | pL -0.035 | vL 0.226 | ∇ 0.944\n",
      "Status saved\n",
      "Number of frames:  503040\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 31 | F 519808 | FPS 2019 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.776 | V -7.292 | pL 39.163 | vL 1734.600 | ∇ 115.433\n",
      "U 32 | F 536576 | FPS 2315 | D 15 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.817 | V -7.962 | pL 37.765 | vL 1593.332 | ∇ 47.313\n",
      "U 33 | F 553344 | FPS 2302 | D 22 | rR:μσmM 0.01 0.06 0.00 0.44 | F:μσmM 357.2 19.4 223.0 360.0 | H 0.882 | V -8.361 | pL 36.773 | vL 1522.228 | ∇ 39.386\n",
      "U 34 | F 570112 | FPS 1977 | D 31 | rR:μσmM 0.01 0.06 0.00 0.40 | F:μσmM 357.5 17.3 239.0 360.0 | H 1.114 | V -9.009 | pL 35.821 | vL 1480.934 | ∇ 43.113\n",
      "U 35 | F 586880 | FPS 2091 | D 39 | rR:μσmM 0.02 0.07 0.00 0.41 | F:μσmM 355.4 21.9 238.0 360.0 | H 1.277 | V -9.383 | pL 35.807 | vL 1464.701 | ∇ 30.321\n",
      "U 36 | F 603648 | FPS 2027 | D 47 | rR:μσmM 0.03 0.15 0.00 0.80 | F:μσmM 349.3 51.8 82.0 360.0 | H 1.342 | V -9.716 | pL 35.268 | vL 1438.319 | ∇ 27.576\n",
      "U 37 | F 620416 | FPS 2093 | D 55 | rR:μσmM 0.02 0.08 0.00 0.50 | F:μσmM 355.4 23.5 200.0 360.0 | H 1.402 | V -10.039 | pL 35.239 | vL 1435.204 | ∇ 25.090\n",
      "U 38 | F 637184 | FPS 1996 | D 64 | rR:μσmM 0.00 0.02 0.00 0.15 | F:μσmM 359.6 2.7 341.0 360.0 | H 1.480 | V -10.482 | pL 35.219 | vL 1425.413 | ∇ 22.119\n",
      "U 39 | F 653952 | FPS 2042 | D 72 | rR:μσmM 0.00 0.02 0.00 0.15 | F:μσmM 359.6 2.9 340.0 360.0 | H 1.495 | V -10.901 | pL 35.294 | vL 1421.012 | ∇ 19.208\n",
      "U 40 | F 670720 | FPS 2036 | D 80 | rR:μσmM 0.00 0.03 0.00 0.22 | F:μσmM 359.0 7.0 311.0 360.0 | H 1.678 | V -11.271 | pL 34.526 | vL 1418.092 | ∇ 21.423\n",
      "Status saved\n",
      "U 41 | F 687488 | FPS 2056 | D 88 | rR:μσmM 0.14 0.26 0.00 0.89 | F:μσmM 313.6 90.6 43.0 360.0 | H 1.717 | V -11.819 | pL 34.068 | vL 1359.037 | ∇ 20.037\n",
      "U 42 | F 704256 | FPS 1935 | D 97 | rR:μσmM 0.22 0.30 0.00 0.94 | F:μσmM 286.7 103.1 24.0 360.0 | H 1.693 | V -12.137 | pL 33.191 | vL 1299.336 | ∇ 20.501\n",
      "U 43 | F 721024 | FPS 2040 | D 105 | rR:μσmM 0.20 0.28 0.00 0.79 | F:μσmM 294.1 93.8 84.0 360.0 | H 1.722 | V -12.538 | pL 33.221 | vL 1301.665 | ∇ 18.735\n",
      "U 44 | F 737792 | FPS 1690 | D 115 | rR:μσmM 0.23 0.30 0.00 0.92 | F:μσmM 286.5 103.1 32.0 360.0 | H 1.714 | V -12.773 | pL 32.737 | vL 1280.671 | ∇ 20.387\n",
      "U 45 | F 754560 | FPS 2066 | D 123 | rR:μσmM 0.20 0.31 0.00 0.91 | F:μσmM 293.8 106.4 36.0 360.0 | H 1.697 | V -13.097 | pL 33.032 | vL 1291.434 | ∇ 22.186\n",
      "U 46 | F 771328 | FPS 2034 | D 131 | rR:μσmM 0.21 0.30 0.00 0.82 | F:μσmM 291.5 101.3 71.0 360.0 | H 1.730 | V -13.473 | pL 32.416 | vL 1247.560 | ∇ 19.546\n",
      "U 47 | F 788096 | FPS 2062 | D 140 | rR:μσmM 0.30 0.32 0.00 0.90 | F:μσmM 260.9 112.0 38.0 360.0 | H 1.703 | V -13.748 | pL 31.337 | vL 1187.210 | ∇ 18.762\n",
      "U 48 | F 804864 | FPS 2057 | D 148 | rR:μσmM 0.27 0.32 0.00 0.96 | F:μσmM 271.3 111.4 15.0 360.0 | H 1.737 | V -14.044 | pL 32.006 | vL 1232.078 | ∇ 17.702\n",
      "U 49 | F 821632 | FPS 1966 | D 156 | rR:μσmM 0.32 0.33 0.00 0.90 | F:μσmM 253.6 116.0 40.0 360.0 | H 1.718 | V -14.310 | pL 30.705 | vL 1156.441 | ∇ 19.245\n",
      "U 50 | F 838400 | FPS 2065 | D 164 | rR:μσmM 0.53 0.34 0.00 0.95 | F:μσmM 177.6 123.9 18.0 360.0 | H 1.690 | V -14.428 | pL 27.450 | vL 1000.422 | ∇ 20.290\n",
      "Status saved\n",
      "U 51 | F 855168 | FPS 2073 | D 172 | rR:μσmM 0.46 0.33 0.00 0.96 | F:μσmM 205.1 116.6 15.0 360.0 | H 1.726 | V -14.787 | pL 29.035 | vL 1074.881 | ∇ 17.966\n",
      "U 52 | F 871936 | FPS 2057 | D 181 | rR:μσmM 0.56 0.32 0.00 0.97 | F:μσmM 169.2 118.5 12.0 360.0 | H 1.694 | V -14.880 | pL 26.382 | vL 954.176 | ∇ 18.884\n",
      "U 53 | F 888704 | FPS 2036 | D 189 | rR:μσmM 0.64 0.27 0.00 0.97 | F:μσmM 139.2 103.2 13.0 360.0 | H 1.700 | V -15.239 | pL 24.724 | vL 881.603 | ∇ 17.994\n",
      "U 54 | F 905472 | FPS 2043 | D 197 | rR:μσmM 0.77 0.19 0.00 0.98 | F:μσmM 91.8 71.5 10.0 360.0 | H 1.580 | V -14.840 | pL 17.992 | vL 582.225 | ∇ 19.825\n",
      "U 55 | F 922240 | FPS 2066 | D 205 | rR:μσmM 0.83 0.16 0.00 0.98 | F:μσmM 69.1 60.6 10.0 360.0 | H 1.550 | V -14.591 | pL 15.173 | vL 491.513 | ∇ 22.045\n",
      "U 56 | F 939008 | FPS 1936 | D 214 | rR:μσmM 0.87 0.11 0.00 0.97 | F:μσmM 53.0 42.7 11.0 360.0 | H 1.477 | V -14.614 | pL 10.365 | vL 307.252 | ∇ 15.957\n",
      "U 57 | F 955776 | FPS 2067 | D 222 | rR:μσmM 0.90 0.08 0.43 0.98 | F:μσmM 41.5 31.0 9.0 229.0 | H 1.339 | V -14.252 | pL 6.674 | vL 203.427 | ∇ 19.063\n",
      "U 58 | F 972544 | FPS 1702 | D 232 | rR:μσmM 0.92 0.06 0.00 0.98 | F:μσmM 30.4 24.8 8.0 360.0 | H 1.170 | V -13.125 | pL 3.264 | vL 147.588 | ∇ 17.832\n",
      "U 59 | F 989312 | FPS 1946 | D 240 | rR:μσmM 0.94 0.03 0.68 0.98 | F:μσmM 23.9 13.0 8.0 130.0 | H 1.002 | V -12.468 | pL -0.635 | vL 49.949 | ∇ 12.455\n",
      "U 60 | F 1006080 | FPS 2047 | D 249 | rR:μσmM 0.95 0.03 0.74 0.98 | F:μσmM 20.9 10.1 8.0 105.0 | H 0.858 | V -11.834 | pL -1.775 | vL 36.070 | ∇ 12.165\n",
      "Status saved\n",
      "Number of frames:  1006080\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 61 | F 1022848 | FPS 2125 | D 7 | rR:μσmM 0.56 0.44 0.00 0.98 | F:μσmM 68.4 116.0 1.0 720.0 | H 1.109 | V -13.094 | pL 24.646 | vL 1023.804 | ∇ 46.483\n",
      "U 62 | F 1039616 | FPS 2356 | D 15 | rR:μσmM 0.49 0.45 0.00 0.99 | F:μσmM 55.9 86.4 1.0 678.0 | H 1.170 | V -14.397 | pL 17.297 | vL 670.458 | ∇ 35.757\n",
      "U 63 | F 1056384 | FPS 1923 | D 23 | rR:μσmM 0.43 0.45 0.00 0.99 | F:μσmM 46.3 71.7 1.0 653.0 | H 1.204 | V -14.413 | pL 14.542 | vL 586.823 | ∇ 36.908\n",
      "U 64 | F 1073152 | FPS 2037 | D 31 | rR:μσmM 0.40 0.46 0.00 0.99 | F:μσmM 36.8 64.9 1.0 720.0 | H 1.170 | V -14.891 | pL 13.021 | vL 554.445 | ∇ 31.985\n",
      "U 65 | F 1089920 | FPS 2051 | D 40 | rR:μσmM 0.46 0.47 0.00 0.99 | F:μσmM 29.9 39.3 1.0 370.0 | H 1.123 | V -14.843 | pL 6.727 | vL 325.376 | ∇ 31.156\n",
      "U 66 | F 1106688 | FPS 2056 | D 48 | rR:μσmM 0.41 0.47 0.00 0.99 | F:μσmM 23.8 27.5 1.0 237.0 | H 1.048 | V -14.957 | pL 3.568 | vL 249.804 | ∇ 27.841\n",
      "U 67 | F 1123456 | FPS 2024 | D 56 | rR:μσmM 0.36 0.47 0.00 0.99 | F:μσmM 17.5 18.4 1.0 172.0 | H 0.906 | V -14.724 | pL -1.512 | vL 148.173 | ∇ 23.916\n",
      "U 68 | F 1140224 | FPS 2028 | D 64 | rR:μσmM 0.35 0.47 0.00 0.99 | F:μσmM 14.5 11.8 1.0 109.0 | H 0.787 | V -14.098 | pL -4.533 | vL 100.544 | ∇ 18.619\n",
      "U 69 | F 1156992 | FPS 1995 | D 73 | rR:μσmM 0.32 0.46 0.00 0.99 | F:μσmM 11.6 8.4 1.0 58.0 | H 0.591 | V -13.131 | pL -6.477 | vL 81.218 | ∇ 14.402\n",
      "U 70 | F 1173760 | FPS 1896 | D 82 | rR:μσmM 0.25 0.43 0.00 0.99 | F:μσmM 9.3 6.1 1.0 45.0 | H 0.396 | V -12.003 | pL -7.628 | vL 78.795 | ∇ 8.990\n",
      "Status saved\n",
      "U 71 | F 1190528 | FPS 1980 | D 90 | rR:μσmM 0.24 0.42 0.00 0.99 | F:μσmM 8.7 5.2 1.0 51.0 | H 0.303 | V -11.143 | pL -7.424 | vL 70.989 | ∇ 8.406\n",
      "U 72 | F 1207296 | FPS 1759 | D 100 | rR:μσmM 0.24 0.42 0.00 0.99 | F:μσmM 8.3 4.7 1.0 67.0 | H 0.241 | V -10.374 | pL -7.093 | vL 65.169 | ∇ 8.034\n",
      "U 73 | F 1224064 | FPS 1791 | D 109 | rR:μσmM 0.22 0.41 0.00 0.99 | F:μσmM 8.0 4.4 1.0 36.0 | H 0.181 | V -9.363 | pL -6.360 | vL 54.392 | ∇ 7.183\n",
      "U 74 | F 1240832 | FPS 1978 | D 118 | rR:μσmM 0.20 0.40 0.00 0.99 | F:μσmM 7.8 4.5 1.0 59.0 | H 0.157 | V -8.531 | pL -5.333 | vL 43.836 | ∇ 8.037\n",
      "U 75 | F 1257600 | FPS 1991 | D 126 | rR:μσmM 0.23 0.42 0.00 0.99 | F:μσmM 7.9 4.6 1.0 58.0 | H 0.120 | V -7.697 | pL -4.654 | vL 35.411 | ∇ 6.045\n",
      "U 76 | F 1274368 | FPS 1982 | D 134 | rR:μσmM 0.23 0.42 0.00 0.99 | F:μσmM 7.9 4.0 1.0 27.0 | H 0.110 | V -7.100 | pL -4.344 | vL 29.346 | ∇ 5.962\n",
      "U 77 | F 1291136 | FPS 1854 | D 143 | rR:μσmM 0.22 0.41 0.00 0.99 | F:μσmM 7.9 5.0 1.0 126.0 | H 0.098 | V -6.286 | pL -3.144 | vL 25.846 | ∇ 6.342\n",
      "U 78 | F 1307904 | FPS 1979 | D 152 | rR:μσmM 0.19 0.39 0.00 0.99 | F:μσmM 7.4 3.8 1.0 29.0 | H 0.073 | V -5.331 | pL -2.729 | vL 15.453 | ∇ 5.838\n",
      "U 79 | F 1324672 | FPS 1978 | D 160 | rR:μσmM 0.18 0.38 0.00 0.99 | F:μσmM 7.5 4.2 1.0 62.0 | H 0.069 | V -4.946 | pL -2.087 | vL 12.458 | ∇ 5.792\n",
      "U 80 | F 1341440 | FPS 1990 | D 169 | rR:μσmM 0.19 0.39 0.00 0.99 | F:μσmM 7.4 4.0 1.0 41.0 | H 0.058 | V -4.292 | pL -1.339 | vL 7.685 | ∇ 6.626\n",
      "Status saved\n",
      "U 81 | F 1358208 | FPS 1977 | D 177 | rR:μσmM 0.17 0.37 0.00 0.99 | F:μσmM 7.5 4.0 1.0 50.0 | H 0.051 | V -3.955 | pL -0.920 | vL 6.269 | ∇ 5.390\n",
      "U 82 | F 1374976 | FPS 1983 | D 186 | rR:μσmM 0.17 0.37 0.00 0.99 | F:μσmM 7.2 3.5 1.0 23.0 | H 0.044 | V -3.562 | pL -0.947 | vL 4.271 | ∇ 4.458\n",
      "U 83 | F 1391744 | FPS 1976 | D 194 | rR:μσmM 0.17 0.37 0.00 0.99 | F:μσmM 7.3 3.6 1.0 31.0 | H 0.042 | V -3.447 | pL -0.758 | vL 3.267 | ∇ 4.380\n",
      "U 84 | F 1408512 | FPS 1888 | D 203 | rR:μσmM 0.15 0.35 0.00 0.99 | F:μσmM 7.2 3.9 1.0 75.0 | H 0.046 | V -3.283 | pL -0.241 | vL 4.088 | ∇ 4.816\n",
      "U 85 | F 1425280 | FPS 1957 | D 212 | rR:μσmM 0.15 0.36 0.00 0.99 | F:μσmM 7.1 3.5 1.0 37.0 | H 0.036 | V -3.077 | pL -0.279 | vL 2.023 | ∇ 4.303\n",
      "U 86 | F 1442048 | FPS 1865 | D 221 | rR:μσmM 0.15 0.35 0.00 0.99 | F:μσmM 7.0 3.5 1.0 27.0 | H 0.033 | V -2.989 | pL -0.237 | vL 1.692 | ∇ 3.935\n",
      "U 87 | F 1458816 | FPS 1777 | D 230 | rR:μσmM 0.17 0.37 0.00 0.99 | F:μσmM 7.1 3.5 1.0 31.0 | H 0.029 | V -3.019 | pL -0.307 | vL 1.516 | ∇ 3.726\n",
      "U 88 | F 1475584 | FPS 1952 | D 239 | rR:μσmM 0.13 0.34 0.00 0.99 | F:μσmM 7.0 3.4 1.0 34.0 | H 0.027 | V -2.896 | pL -0.246 | vL 1.534 | ∇ 3.692\n",
      "U 89 | F 1492352 | FPS 1976 | D 247 | rR:μσmM 0.13 0.33 0.00 0.99 | F:μσmM 7.0 3.3 1.0 22.0 | H 0.026 | V -2.834 | pL -0.127 | vL 1.131 | ∇ 2.950\n",
      "U 90 | F 1509120 | FPS 1967 | D 256 | rR:μσmM 0.12 0.33 0.00 0.99 | F:μσmM 6.8 3.2 1.0 18.0 | H 0.025 | V -2.711 | pL -0.079 | vL 0.960 | ∇ 2.725\n",
      "Status saved\n",
      "Number of frames:  1509120\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 91 | F 1525888 | FPS 1974 | D 8 | rR:μσmM 0.03 0.16 0.00 0.83 | F:μσmM 313.6 50.9 62.0 324.0 | H 0.783 | V -7.295 | pL 32.355 | vL 1566.168 | ∇ 129.486\n",
      "U 92 | F 1542656 | FPS 2354 | D 15 | rR:μσmM 0.03 0.13 0.00 0.63 | F:μσmM 314.5 38.4 132.0 324.0 | H 0.881 | V -7.993 | pL 36.220 | vL 1490.179 | ∇ 67.766\n",
      "U 93 | F 1559424 | FPS 2303 | D 22 | rR:μσmM 0.10 0.21 0.00 0.76 | F:μσmM 296.2 61.9 85.0 324.0 | H 0.880 | V -8.004 | pL 35.737 | vL 1464.911 | ∇ 51.488\n",
      "U 94 | F 1576192 | FPS 2040 | D 31 | rR:μσmM 0.15 0.27 0.00 0.88 | F:μσmM 280.9 83.0 42.0 324.0 | H 1.081 | V -9.093 | pL 34.079 | vL 1404.821 | ∇ 51.936\n",
      "U 95 | F 1592960 | FPS 2045 | D 39 | rR:μσmM 0.27 0.33 0.00 0.89 | F:μσmM 243.2 102.9 41.0 324.0 | H 1.273 | V -9.951 | pL 32.963 | vL 1306.105 | ∇ 41.658\n",
      "U 96 | F 1609728 | FPS 2046 | D 47 | rR:μσmM 0.27 0.35 0.00 0.93 | F:μσmM 241.8 108.8 24.0 324.0 | H 1.316 | V -10.241 | pL 33.133 | vL 1315.288 | ∇ 35.542\n",
      "U 97 | F 1626496 | FPS 2051 | D 55 | rR:μσmM 0.33 0.35 0.00 0.93 | F:μσmM 225.3 110.6 25.0 324.0 | H 1.426 | V -10.925 | pL 31.350 | vL 1225.196 | ∇ 33.924\n",
      "U 98 | F 1643264 | FPS 1942 | D 64 | rR:μσmM 0.40 0.37 0.00 0.95 | F:μσmM 200.5 117.5 19.0 324.0 | H 1.545 | V -11.363 | pL 30.123 | vL 1161.660 | ∇ 33.572\n",
      "U 99 | F 1660032 | FPS 2059 | D 72 | rR:μσmM 0.38 0.35 0.00 0.93 | F:μσmM 210.7 111.6 25.0 324.0 | H 1.621 | V -12.075 | pL 31.061 | vL 1195.295 | ∇ 28.334\n",
      "U 100 | F 1676800 | FPS 2011 | D 80 | rR:μσmM 0.38 0.33 0.00 0.93 | F:μσmM 209.7 107.0 27.0 324.0 | H 1.638 | V -12.217 | pL 29.953 | vL 1130.717 | ∇ 27.980\n",
      "Status saved\n",
      "U 101 | F 1693568 | FPS 1823 | D 90 | rR:μσmM 0.43 0.35 0.00 0.94 | F:μσmM 191.3 110.2 23.0 324.0 | H 1.661 | V -12.700 | pL 29.126 | vL 1086.074 | ∇ 27.573\n",
      "U 102 | F 1710336 | FPS 2012 | D 98 | rR:μσmM 0.45 0.33 0.00 0.90 | F:μσmM 190.3 106.5 36.0 324.0 | H 1.678 | V -13.110 | pL 28.580 | vL 1059.904 | ∇ 25.312\n",
      "U 103 | F 1727104 | FPS 2052 | D 106 | rR:μσmM 0.47 0.33 0.00 0.93 | F:μσmM 181.4 106.3 25.0 324.0 | H 1.698 | V -13.640 | pL 28.357 | vL 1047.229 | ∇ 26.014\n",
      "U 104 | F 1743872 | FPS 2065 | D 114 | rR:μσmM 0.51 0.32 0.00 0.95 | F:μσmM 170.4 104.3 18.0 324.0 | H 1.701 | V -13.840 | pL 26.611 | vL 959.938 | ∇ 25.360\n",
      "U 105 | F 1760640 | FPS 1972 | D 123 | rR:μσmM 0.50 0.33 0.00 0.93 | F:μσmM 173.5 106.0 26.0 324.0 | H 1.709 | V -14.280 | pL 27.243 | vL 993.508 | ∇ 24.467\n",
      "U 106 | F 1777408 | FPS 2007 | D 131 | rR:μσmM 0.60 0.29 0.00 0.93 | F:μσmM 139.6 95.5 25.0 324.0 | H 1.711 | V -14.650 | pL 24.561 | vL 858.425 | ∇ 25.209\n",
      "U 107 | F 1794176 | FPS 2026 | D 139 | rR:μσmM 0.64 0.28 0.00 0.95 | F:μσmM 125.1 91.9 17.0 324.0 | H 1.675 | V -14.920 | pL 22.269 | vL 758.385 | ∇ 24.691\n",
      "U 108 | F 1810944 | FPS 2060 | D 148 | rR:μσmM 0.71 0.22 0.00 0.96 | F:μσmM 103.9 78.6 16.0 324.0 | H 1.634 | V -15.071 | pL 20.598 | vL 693.453 | ∇ 25.093\n",
      "U 109 | F 1827712 | FPS 2040 | D 156 | rR:μσmM 0.70 0.23 0.00 0.95 | F:μσmM 105.3 78.0 17.0 324.0 | H 1.648 | V -15.486 | pL 20.994 | vL 704.159 | ∇ 24.074\n",
      "U 110 | F 1844480 | FPS 2069 | D 164 | rR:μσmM 0.74 0.22 0.00 0.95 | F:μσmM 93.1 74.6 19.0 324.0 | H 1.610 | V -15.657 | pL 17.919 | vL 577.926 | ∇ 23.564\n",
      "Status saved\n",
      "U 111 | F 1861248 | FPS 2046 | D 172 | rR:μσmM 0.77 0.22 0.00 0.96 | F:μσmM 81.6 74.2 14.0 324.0 | H 1.555 | V -15.767 | pL 16.531 | vL 532.741 | ∇ 30.495\n",
      "U 112 | F 1878016 | FPS 2038 | D 180 | rR:μσmM 0.81 0.16 0.13 0.96 | F:μσmM 69.0 57.8 13.0 313.0 | H 1.477 | V -15.787 | pL 13.884 | vL 436.800 | ∇ 28.558\n",
      "U 113 | F 1894784 | FPS 1944 | D 189 | rR:μσmM 0.84 0.15 0.00 0.96 | F:μσmM 56.0 52.0 14.0 324.0 | H 1.405 | V -15.593 | pL 11.410 | vL 373.134 | ∇ 32.378\n",
      "U 114 | F 1911552 | FPS 2047 | D 197 | rR:μσmM 0.86 0.12 0.26 0.96 | F:μσmM 51.2 43.2 13.0 268.0 | H 1.358 | V -15.795 | pL 9.395 | vL 299.906 | ∇ 28.545\n",
      "U 115 | F 1928320 | FPS 2056 | D 205 | rR:μσmM 0.87 0.10 0.11 0.96 | F:μσmM 47.7 37.8 14.0 319.0 | H 1.307 | V -15.955 | pL 8.435 | vL 275.009 | ∇ 29.059\n",
      "U 116 | F 1945088 | FPS 1812 | D 215 | rR:μσmM 0.90 0.09 0.00 0.96 | F:μσmM 37.1 29.8 14.0 324.0 | H 1.195 | V -15.416 | pL 4.460 | vL 175.563 | ∇ 24.387\n",
      "U 117 | F 1961856 | FPS 1899 | D 223 | rR:μσmM 0.90 0.08 0.00 0.96 | F:μσmM 35.2 29.4 13.0 324.0 | H 1.110 | V -15.214 | pL 3.363 | vL 158.336 | ∇ 27.524\n",
      "U 118 | F 1978624 | FPS 2035 | D 232 | rR:μσmM 0.92 0.06 0.54 0.96 | F:μσmM 30.0 20.4 13.0 167.0 | H 0.990 | V -14.747 | pL 1.480 | vL 110.661 | ∇ 23.121\n",
      "U 119 | F 1995392 | FPS 2049 | D 240 | rR:μσmM 0.93 0.05 0.49 0.96 | F:μσmM 26.1 17.5 13.0 185.0 | H 0.824 | V -14.093 | pL 0.144 | vL 88.915 | ∇ 22.094\n",
      "U 120 | F 2012160 | FPS 1959 | D 248 | rR:μσmM 0.94 0.04 0.76 0.96 | F:μσmM 23.2 13.2 13.0 87.0 | H 0.735 | V -13.445 | pL -1.408 | vL 60.745 | ∇ 18.956\n",
      "Status saved\n",
      "Number of frames:  2012160\n",
      "{'algo': 'ppopc', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'wallgap-doorkey-redblue-crossing', 'early_stop': False, 'seed': 789012, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 500000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 1048, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'cascade_depth': 4, 'flow_factor': 1.0, 'mesh_factor': 4.0, 'lr_decay': True, 'imp_sampling': 'clipped', 'imp_clips': [-5, 5], 'dynamic_neglogpacs': False, 'optimizer_type': 'rmsprop', 'scheduler_flag': False, 'var_init': 'equal', 'reshape_reward': True, 'date': datetime.date(2023, 11, 11), 'mem': False, 'lrs': [0.0007, 0.000175, 4.375e-05, 1.09375e-05], 'lrs_fn': <function decayfn_arr_2.<locals>.f at 0x7f7c2ffb84d0>, 'clipranges': [0.2, 0.05, 0.0125, 0.003125]}\n",
      "\n",
      "Device: cpu\n",
      "\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden models loaded\n",
      "\n",
      "U 1 | F 016768 | FPS 2098 | D 7 | rR:μσmM 0.12 0.24 0.00 0.96 | F:μσmM 128.7 32.9 7.0 144.0 | H 1.919 | V -0.187 | pL 31.845 | vL 1199.651 | ∇ 7.027\n",
      "U 2 | F 033536 | FPS 2333 | D 15 | rR:μσmM 0.12 0.25 0.00 0.96 | F:μσmM 128.3 34.2 6.0 144.0 | H 1.899 | V -0.569 | pL 30.989 | vL 1148.376 | ∇ 7.564\n",
      "U 3 | F 050304 | FPS 2243 | D 22 | rR:μσmM 0.15 0.27 0.00 0.91 | F:μσmM 124.0 37.5 14.0 144.0 | H 1.903 | V -0.953 | pL 30.557 | vL 1120.843 | ∇ 7.505\n",
      "U 4 | F 067072 | FPS 2049 | D 30 | rR:μσmM 0.14 0.26 0.00 0.96 | F:μσmM 126.0 35.7 7.0 144.0 | H 1.898 | V -1.355 | pL 30.509 | vL 1123.089 | ∇ 7.944\n",
      "U 5 | F 083840 | FPS 2064 | D 39 | rR:μσmM 0.11 0.24 0.00 0.98 | F:μσmM 129.4 32.6 3.0 144.0 | H 1.908 | V -1.775 | pL 30.589 | vL 1123.825 | ∇ 7.618\n",
      "U 6 | F 100608 | FPS 2060 | D 47 | rR:μσmM 0.11 0.24 0.00 0.91 | F:μσmM 129.5 32.4 15.0 144.0 | H 1.899 | V -2.070 | pL 30.362 | vL 1115.859 | ∇ 8.393\n",
      "U 7 | F 117376 | FPS 1952 | D 55 | rR:μσmM 0.15 0.29 0.00 0.96 | F:μσmM 123.8 39.8 6.0 144.0 | H 1.884 | V -2.383 | pL 29.885 | vL 1094.115 | ∇ 10.208\n",
      "U 8 | F 134144 | FPS 2064 | D 63 | rR:μσmM 0.19 0.29 0.00 0.95 | F:μσmM 119.5 40.5 8.0 144.0 | H 1.883 | V -2.750 | pL 29.322 | vL 1059.129 | ∇ 9.000\n",
      "U 9 | F 150912 | FPS 2066 | D 71 | rR:μσmM 0.22 0.33 0.00 0.97 | F:μσmM 114.4 45.6 5.0 144.0 | H 1.868 | V -3.197 | pL 28.542 | vL 1022.216 | ∇ 10.330\n",
      "U 10 | F 167680 | FPS 2053 | D 80 | rR:μσmM 0.29 0.34 0.00 0.96 | F:μσmM 105.4 47.6 7.0 144.0 | H 1.857 | V -3.496 | pL 27.680 | vL 968.783 | ∇ 11.030\n",
      "Status saved\n",
      "U 11 | F 184448 | FPS 2017 | D 88 | rR:μσmM 0.28 0.36 0.00 0.98 | F:μσmM 106.3 50.5 3.0 144.0 | H 1.840 | V -3.985 | pL 27.654 | vL 978.934 | ∇ 12.974\n",
      "U 12 | F 201216 | FPS 2078 | D 96 | rR:μσmM 0.34 0.35 0.00 0.99 | F:μσmM 99.4 49.6 2.0 144.0 | H 1.819 | V -4.464 | pL 26.725 | vL 924.173 | ∇ 12.991\n",
      "U 13 | F 217984 | FPS 2053 | D 104 | rR:μσmM 0.45 0.37 0.00 0.98 | F:μσmM 82.1 53.5 3.0 144.0 | H 1.774 | V -4.951 | pL 24.859 | vL 847.566 | ∇ 16.265\n",
      "U 14 | F 234752 | FPS 2086 | D 112 | rR:μσmM 0.55 0.32 0.00 0.99 | F:μσmM 68.7 46.7 2.0 144.0 | H 1.700 | V -5.448 | pL 21.591 | vL 684.507 | ∇ 15.309\n",
      "U 15 | F 251520 | FPS 1903 | D 121 | rR:μσmM 0.66 0.29 0.00 0.98 | F:μσmM 53.5 43.9 3.0 144.0 | H 1.591 | V -6.033 | pL 19.053 | vL 591.566 | ∇ 17.999\n",
      "U 16 | F 268288 | FPS 2066 | D 129 | rR:μσmM 0.78 0.20 0.00 0.99 | F:μσmM 35.3 30.6 2.0 144.0 | H 1.429 | V -6.394 | pL 12.914 | vL 348.831 | ∇ 16.103\n",
      "U 17 | F 285056 | FPS 2032 | D 137 | rR:μσmM 0.84 0.13 0.00 0.99 | F:μσmM 25.6 20.8 2.0 144.0 | H 1.264 | V -6.388 | pL 8.273 | vL 192.657 | ∇ 14.497\n",
      "U 18 | F 301824 | FPS 2048 | D 146 | rR:μσmM 0.89 0.08 0.39 0.99 | F:μσmM 17.3 12.3 2.0 98.0 | H 1.027 | V -6.309 | pL 3.208 | vL 69.208 | ∇ 14.920\n",
      "U 19 | F 318592 | FPS 2033 | D 154 | rR:μσmM 0.91 0.06 0.56 0.99 | F:μσmM 14.2 9.1 2.0 71.0 | H 0.845 | V -6.192 | pL 1.329 | vL 37.480 | ∇ 11.706\n",
      "U 20 | F 335360 | FPS 2038 | D 162 | rR:μσmM 0.93 0.03 0.73 0.99 | F:μσmM 11.3 5.5 2.0 44.0 | H 0.570 | V -5.632 | pL -0.798 | vL 11.751 | ∇ 8.073\n",
      "Status saved\n",
      "U 21 | F 352128 | FPS 2053 | D 170 | rR:μσmM 0.94 0.03 0.76 0.99 | F:μσmM 10.1 4.2 2.0 38.0 | H 0.394 | V -5.191 | pL -1.343 | vL 6.845 | ∇ 5.651\n",
      "U 22 | F 368896 | FPS 1897 | D 179 | rR:μσmM 0.94 0.02 0.80 0.99 | F:μσmM 9.0 3.2 2.0 32.0 | H 0.249 | V -4.480 | pL -1.495 | vL 4.364 | ∇ 4.025\n",
      "U 23 | F 385664 | FPS 2029 | D 187 | rR:μσmM 0.95 0.02 0.86 0.99 | F:μσmM 8.7 2.8 2.0 22.0 | H 0.162 | V -3.974 | pL -1.186 | vL 2.654 | ∇ 3.257\n",
      "U 24 | F 402432 | FPS 2017 | D 196 | rR:μσmM 0.95 0.02 0.88 0.99 | F:μσmM 8.4 2.4 2.0 20.0 | H 0.098 | V -3.425 | pL -0.639 | vL 1.328 | ∇ 2.853\n",
      "U 25 | F 419200 | FPS 2008 | D 204 | rR:μσmM 0.95 0.02 0.87 0.99 | F:μσmM 8.2 2.4 2.0 21.0 | H 0.068 | V -3.264 | pL -0.664 | vL 0.986 | ∇ 2.311\n",
      "U 26 | F 435968 | FPS 1967 | D 213 | rR:μσmM 0.95 0.01 0.90 0.99 | F:μσmM 8.2 2.2 2.0 16.0 | H 0.050 | V -3.048 | pL -0.244 | vL 0.567 | ∇ 2.208\n",
      "U 27 | F 452736 | FPS 2015 | D 221 | rR:μσmM 0.95 0.01 0.90 0.99 | F:μσmM 8.2 2.2 2.0 16.0 | H 0.033 | V -2.980 | pL -0.314 | vL 0.384 | ∇ 1.959\n",
      "U 28 | F 469504 | FPS 1999 | D 229 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.1 2.2 2.0 15.0 | H 0.021 | V -2.898 | pL -0.215 | vL 0.323 | ∇ 1.745\n",
      "U 29 | F 486272 | FPS 1899 | D 238 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.1 2.2 2.0 15.0 | H 0.015 | V -2.815 | pL 0.004 | vL 0.267 | ∇ 1.528\n",
      "U 30 | F 503040 | FPS 1981 | D 247 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.1 2.2 2.0 14.0 | H 0.011 | V -2.826 | pL -0.126 | vL 0.244 | ∇ 1.408\n",
      "Status saved\n",
      "Number of frames:  503040\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 31 | F 519808 | FPS 2095 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.778 | V -6.635 | pL 36.144 | vL 1773.404 | ∇ 103.019\n",
      "U 32 | F 536576 | FPS 2359 | D 15 | rR:μσmM 0.02 0.12 0.00 0.86 | F:μσmM 353.8 43.0 56.0 360.0 | H 0.899 | V -7.490 | pL 37.883 | vL 1604.160 | ∇ 54.647\n",
      "U 33 | F 553344 | FPS 2222 | D 22 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 1.016 | V -7.890 | pL 37.092 | vL 1545.120 | ∇ 50.705\n",
      "U 34 | F 570112 | FPS 2060 | D 30 | rR:μσmM 0.01 0.07 0.00 0.50 | F:μσmM 356.8 22.3 202.0 360.0 | H 1.102 | V -8.412 | pL 36.362 | vL 1494.074 | ∇ 43.898\n",
      "U 35 | F 586880 | FPS 2059 | D 38 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 1.163 | V -8.956 | pL 36.030 | vL 1475.127 | ∇ 36.344\n",
      "U 36 | F 603648 | FPS 1956 | D 47 | rR:μσmM 0.03 0.10 0.00 0.51 | F:μσmM 351.9 31.7 194.0 360.0 | H 1.200 | V -9.504 | pL 35.719 | vL 1448.845 | ∇ 33.442\n",
      "U 37 | F 620416 | FPS 2095 | D 55 | rR:μσmM 0.03 0.11 0.00 0.51 | F:μσmM 351.3 33.1 195.0 360.0 | H 1.273 | V -9.879 | pL 35.482 | vL 1437.831 | ∇ 31.426\n",
      "U 38 | F 637184 | FPS 2091 | D 63 | rR:μσmM 0.02 0.11 0.00 0.71 | F:μσmM 353.3 35.3 116.0 360.0 | H 1.290 | V -10.402 | pL 35.233 | vL 1420.419 | ∇ 27.364\n",
      "U 39 | F 653952 | FPS 2080 | D 71 | rR:μσmM 0.05 0.16 0.00 0.73 | F:μσmM 343.8 50.8 110.0 360.0 | H 1.305 | V -10.861 | pL 34.936 | vL 1407.475 | ∇ 24.593\n",
      "U 40 | F 670720 | FPS 1920 | D 80 | rR:μσmM 0.01 0.03 0.00 0.20 | F:μσmM 359.0 5.7 321.0 360.0 | H 1.308 | V -11.383 | pL 35.171 | vL 1414.894 | ∇ 25.137\n",
      "Status saved\n",
      "U 41 | F 687488 | FPS 1708 | D 90 | rR:μσmM 0.03 0.11 0.00 0.65 | F:μσmM 351.6 36.2 140.0 360.0 | H 1.349 | V -11.849 | pL 34.864 | vL 1399.121 | ∇ 28.967\n",
      "U 42 | F 704256 | FPS 2049 | D 98 | rR:μσmM 0.06 0.14 0.00 0.59 | F:μσmM 343.6 45.1 165.0 360.0 | H 1.370 | V -12.299 | pL 34.771 | vL 1382.460 | ∇ 22.929\n",
      "U 43 | F 721024 | FPS 2000 | D 106 | rR:μσmM 0.04 0.13 0.00 0.70 | F:μσmM 348.6 40.2 120.0 360.0 | H 1.336 | V -12.790 | pL 34.238 | vL 1357.547 | ∇ 24.196\n",
      "U 44 | F 737792 | FPS 2056 | D 114 | rR:μσmM 0.02 0.11 0.00 0.71 | F:μσmM 353.6 35.7 115.0 360.0 | H 1.370 | V -13.124 | pL 34.144 | vL 1348.409 | ∇ 21.009\n",
      "U 45 | F 754560 | FPS 2068 | D 123 | rR:μσmM 0.10 0.22 0.00 0.75 | F:μσmM 327.6 71.8 101.0 360.0 | H 1.408 | V -13.514 | pL 33.397 | vL 1303.215 | ∇ 26.005\n",
      "U 46 | F 771328 | FPS 2073 | D 131 | rR:μσmM 0.12 0.22 0.00 0.88 | F:μσmM 324.0 70.9 47.0 360.0 | H 1.433 | V -13.932 | pL 32.774 | vL 1266.846 | ∇ 23.927\n",
      "U 47 | F 788096 | FPS 2086 | D 139 | rR:μσmM 0.21 0.27 0.00 0.87 | F:μσmM 295.7 93.9 51.0 360.0 | H 1.480 | V -14.141 | pL 31.993 | vL 1221.879 | ∇ 21.171\n",
      "U 48 | F 804864 | FPS 2089 | D 147 | rR:μσmM 0.24 0.32 0.00 0.92 | F:μσmM 282.5 112.1 34.0 360.0 | H 1.491 | V -14.355 | pL 31.684 | vL 1210.499 | ∇ 21.385\n",
      "U 49 | F 821632 | FPS 2083 | D 155 | rR:μσmM 0.31 0.30 0.00 0.90 | F:μσmM 261.6 103.7 38.0 360.0 | H 1.551 | V -14.871 | pL 30.704 | vL 1154.521 | ∇ 20.483\n",
      "U 50 | F 838400 | FPS 2075 | D 163 | rR:μσmM 0.43 0.31 0.00 0.94 | F:μσmM 218.3 109.0 24.0 360.0 | H 1.558 | V -15.189 | pL 28.991 | vL 1060.223 | ∇ 19.481\n",
      "Status saved\n",
      "U 51 | F 855168 | FPS 1956 | D 171 | rR:μσmM 0.42 0.33 0.00 0.91 | F:μσmM 218.9 116.2 37.0 360.0 | H 1.578 | V -15.691 | pL 29.349 | vL 1086.898 | ∇ 20.177\n",
      "U 52 | F 871936 | FPS 2077 | D 180 | rR:μσmM 0.48 0.31 0.00 0.97 | F:μσmM 201.3 116.3 13.0 360.0 | H 1.603 | V -15.795 | pL 27.792 | vL 1011.752 | ∇ 21.655\n",
      "U 53 | F 888704 | FPS 2032 | D 188 | rR:μσmM 0.59 0.29 0.00 0.96 | F:μσmM 160.6 107.7 16.0 360.0 | H 1.543 | V -16.036 | pL 24.997 | vL 882.416 | ∇ 23.432\n",
      "U 54 | F 905472 | FPS 2055 | D 196 | rR:μσmM 0.71 0.21 0.00 0.97 | F:μσmM 113.2 79.2 12.0 360.0 | H 1.526 | V -16.371 | pL 21.664 | vL 726.390 | ∇ 21.490\n",
      "U 55 | F 922240 | FPS 1769 | D 205 | rR:μσmM 0.77 0.19 0.00 0.98 | F:μσmM 90.5 74.1 9.0 360.0 | H 1.485 | V -16.281 | pL 17.242 | vL 558.045 | ∇ 24.157\n",
      "U 56 | F 939008 | FPS 1890 | D 214 | rR:μσmM 0.84 0.12 0.00 0.98 | F:μσmM 62.7 45.6 10.0 360.0 | H 1.419 | V -16.114 | pL 11.622 | vL 345.938 | ∇ 23.040\n",
      "U 57 | F 955776 | FPS 2071 | D 222 | rR:μσmM 0.87 0.10 0.32 0.98 | F:μσmM 50.3 39.0 9.0 270.0 | H 1.338 | V -16.009 | pL 8.237 | vL 251.689 | ∇ 26.280\n",
      "U 58 | F 972544 | FPS 1909 | D 231 | rR:μσmM 0.91 0.06 0.60 0.98 | F:μσmM 36.4 25.4 8.0 159.0 | H 1.180 | V -15.469 | pL 3.838 | vL 153.072 | ∇ 18.882\n",
      "U 59 | F 989312 | FPS 2041 | D 239 | rR:μσmM 0.93 0.05 0.66 0.98 | F:μσmM 30.0 19.6 8.0 135.0 | H 1.024 | V -14.839 | pL 1.049 | vL 101.170 | ∇ 18.828\n",
      "U 60 | F 1006080 | FPS 2028 | D 248 | rR:μσmM 0.94 0.04 0.74 0.98 | F:μσmM 24.0 14.0 8.0 103.0 | H 0.898 | V -13.839 | pL -1.228 | vL 61.289 | ∇ 17.880\n",
      "Status saved\n",
      "Number of frames:  1006080\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 61 | F 1022848 | FPS 2038 | D 8 | rR:μσmM 0.46 0.39 0.00 0.98 | F:μσmM 147.1 165.4 2.0 720.0 | H 1.290 | V -17.753 | pL 28.903 | vL 1139.073 | ∇ 43.784\n",
      "U 62 | F 1039616 | FPS 2216 | D 15 | rR:μσmM 0.45 0.42 0.00 0.97 | F:μσmM 92.9 119.3 1.0 720.0 | H 1.288 | V -18.469 | pL 19.245 | vL 720.365 | ∇ 44.963\n",
      "U 63 | F 1056384 | FPS 2203 | D 23 | rR:μσmM 0.46 0.43 0.00 0.98 | F:μσmM 75.6 88.1 1.0 681.0 | H 1.345 | V -19.059 | pL 16.514 | vL 625.581 | ∇ 40.988\n",
      "U 64 | F 1073152 | FPS 2084 | D 31 | rR:μσmM 0.48 0.44 0.00 0.98 | F:μσmM 61.5 64.9 1.0 472.0 | H 1.354 | V -19.369 | pL 12.887 | vL 504.027 | ∇ 38.477\n",
      "U 65 | F 1089920 | FPS 1929 | D 40 | rR:μσmM 0.36 0.45 0.00 0.99 | F:μσmM 39.4 45.6 1.0 401.0 | H 1.345 | V -19.467 | pL 6.781 | vL 358.039 | ∇ 40.757\n",
      "U 66 | F 1106688 | FPS 2067 | D 48 | rR:μσmM 0.28 0.43 0.00 0.99 | F:μσmM 29.8 33.2 1.0 224.0 | H 1.258 | V -19.476 | pL 2.153 | vL 266.405 | ∇ 40.819\n",
      "U 67 | F 1123456 | FPS 2043 | D 56 | rR:μσmM 0.21 0.39 0.00 0.99 | F:μσmM 20.4 22.2 1.0 215.0 | H 1.167 | V -18.947 | pL -3.519 | vL 190.461 | ∇ 38.867\n",
      "U 68 | F 1140224 | FPS 2028 | D 64 | rR:μσmM 0.16 0.36 0.00 0.99 | F:μσmM 14.7 12.5 1.0 106.0 | H 0.996 | V -18.611 | pL -8.386 | vL 151.465 | ∇ 28.073\n",
      "U 69 | F 1156992 | FPS 1996 | D 73 | rR:μσmM 0.12 0.31 0.00 0.99 | F:μσmM 11.8 9.3 1.0 97.0 | H 0.851 | V -18.051 | pL -10.456 | vL 156.959 | ∇ 22.959\n",
      "U 70 | F 1173760 | FPS 1963 | D 81 | rR:μσmM 0.10 0.29 0.00 0.99 | F:μσmM 10.3 7.5 1.0 119.0 | H 0.697 | V -17.433 | pL -11.758 | vL 165.166 | ∇ 16.073\n",
      "Status saved\n",
      "U 71 | F 1190528 | FPS 2001 | D 90 | rR:μσmM 0.09 0.28 0.00 0.99 | F:μσmM 9.4 6.4 1.0 83.0 | H 0.622 | V -16.415 | pL -11.458 | vL 151.307 | ∇ 18.896\n",
      "U 72 | F 1207296 | FPS 1891 | D 98 | rR:μσmM 0.07 0.26 0.00 0.99 | F:μσmM 9.0 5.7 1.0 46.0 | H 0.541 | V -15.520 | pL -11.139 | vL 137.510 | ∇ 20.301\n",
      "U 73 | F 1224064 | FPS 1985 | D 107 | rR:μσmM 0.07 0.25 0.00 0.99 | F:μσmM 8.5 5.4 1.0 47.0 | H 0.459 | V -14.346 | pL -10.433 | vL 120.517 | ∇ 16.625\n",
      "U 74 | F 1240832 | FPS 1998 | D 115 | rR:μσmM 0.06 0.23 0.00 0.99 | F:μσmM 7.9 4.6 1.0 54.0 | H 0.408 | V -13.357 | pL -10.163 | vL 112.798 | ∇ 18.894\n",
      "U 75 | F 1257600 | FPS 1987 | D 124 | rR:μσmM 0.06 0.23 0.00 0.99 | F:μσmM 7.7 4.0 1.0 52.0 | H 0.317 | V -12.190 | pL -9.643 | vL 99.546 | ∇ 12.259\n",
      "U 76 | F 1274368 | FPS 1971 | D 132 | rR:μσmM 0.05 0.22 0.00 0.99 | F:μσmM 7.3 3.7 1.0 33.0 | H 0.270 | V -10.848 | pL -8.571 | vL 80.895 | ∇ 10.941\n",
      "U 77 | F 1291136 | FPS 1977 | D 141 | rR:μσmM 0.05 0.21 0.00 0.99 | F:μσmM 7.2 3.4 1.0 41.0 | H 0.229 | V -9.581 | pL -7.493 | vL 64.690 | ∇ 9.671\n",
      "U 78 | F 1307904 | FPS 1976 | D 149 | rR:μσmM 0.05 0.21 0.00 0.99 | F:μσmM 7.2 3.6 1.0 36.0 | H 0.207 | V -8.858 | pL -6.663 | vL 52.950 | ∇ 9.908\n",
      "U 79 | F 1324672 | FPS 1886 | D 158 | rR:μσmM 0.05 0.21 0.00 0.99 | F:μσmM 7.3 3.7 1.0 48.0 | H 0.206 | V -8.080 | pL -5.842 | vL 43.580 | ∇ 9.767\n",
      "U 80 | F 1341440 | FPS 1967 | D 167 | rR:μσmM 0.05 0.21 0.00 0.99 | F:μσmM 7.1 3.5 1.0 39.0 | H 0.179 | V -7.072 | pL -4.955 | vL 34.187 | ∇ 10.340\n",
      "Status saved\n",
      "U 81 | F 1358208 | FPS 1998 | D 175 | rR:μσmM 0.04 0.21 0.00 0.99 | F:μσmM 7.0 3.3 1.0 26.0 | H 0.152 | V -6.365 | pL -4.254 | vL 27.810 | ∇ 8.821\n",
      "U 82 | F 1374976 | FPS 1980 | D 184 | rR:μσmM 0.04 0.19 0.00 0.99 | F:μσmM 6.9 3.3 1.0 35.0 | H 0.137 | V -5.723 | pL -3.611 | vL 22.585 | ∇ 8.854\n",
      "U 83 | F 1391744 | FPS 1959 | D 192 | rR:μσmM 0.04 0.18 0.00 0.99 | F:μσmM 6.8 3.0 1.0 46.0 | H 0.110 | V -4.819 | pL -2.708 | vL 16.428 | ∇ 6.060\n",
      "U 84 | F 1408512 | FPS 1823 | D 201 | rR:μσmM 0.03 0.18 0.00 0.99 | F:μσmM 6.6 3.3 1.0 51.0 | H 0.091 | V -4.285 | pL -2.301 | vL 12.982 | ∇ 5.046\n",
      "U 85 | F 1425280 | FPS 1897 | D 210 | rR:μσmM 0.03 0.17 0.00 0.99 | F:μσmM 6.6 2.8 1.0 19.0 | H 0.074 | V -3.675 | pL -1.588 | vL 7.173 | ∇ 4.399\n",
      "U 86 | F 1442048 | FPS 1887 | D 219 | rR:μσmM 0.02 0.15 0.00 0.99 | F:μσmM 6.5 2.8 1.0 24.0 | H 0.065 | V -3.272 | pL -1.162 | vL 4.847 | ∇ 3.841\n",
      "U 87 | F 1458816 | FPS 1975 | D 228 | rR:μσmM 0.03 0.17 0.00 0.99 | F:μσmM 6.4 2.8 1.0 28.0 | H 0.047 | V -3.039 | pL -1.036 | vL 3.676 | ∇ 2.958\n",
      "U 88 | F 1475584 | FPS 1963 | D 236 | rR:μσmM 0.03 0.17 0.00 0.99 | F:μσmM 6.3 2.7 1.0 15.0 | H 0.035 | V -2.691 | pL -0.617 | vL 2.319 | ∇ 2.848\n",
      "U 89 | F 1492352 | FPS 1956 | D 245 | rR:μσmM 0.03 0.17 0.00 0.99 | F:μσmM 6.4 2.6 1.0 15.0 | H 0.021 | V -2.553 | pL -0.409 | vL 1.565 | ∇ 2.526\n",
      "U 90 | F 1509120 | FPS 1974 | D 253 | rR:μσmM 0.03 0.17 0.00 0.99 | F:μσmM 6.4 2.6 1.0 15.0 | H 0.017 | V -2.462 | pL -0.276 | vL 1.049 | ∇ 2.303\n",
      "Status saved\n",
      "Number of frames:  1509120\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 91 | F 1525888 | FPS 2157 | D 7 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 324.0 0.0 324.0 324.0 | H 0.829 | V -7.493 | pL 36.304 | vL 1563.134 | ∇ 178.354\n",
      "U 92 | F 1542656 | FPS 2321 | D 15 | rR:μσmM 0.06 0.19 0.00 0.90 | F:μσmM 306.1 59.3 35.0 324.0 | H 0.834 | V -8.032 | pL 36.140 | vL 1478.443 | ∇ 79.268\n",
      "U 93 | F 1559424 | FPS 2249 | D 22 | rR:μσmM 0.09 0.22 0.00 0.89 | F:μσmM 298.6 66.4 38.0 324.0 | H 0.927 | V -8.465 | pL 35.158 | vL 1437.968 | ∇ 63.018\n",
      "U 94 | F 1576192 | FPS 1914 | D 31 | rR:μσmM 0.17 0.30 0.00 0.91 | F:μσmM 273.8 92.6 33.0 324.0 | H 0.832 | V -8.774 | pL 35.059 | vL 1421.532 | ∇ 51.882\n",
      "U 95 | F 1592960 | FPS 2015 | D 39 | rR:μσmM 0.26 0.34 0.00 0.91 | F:μσmM 245.4 107.1 31.0 324.0 | H 0.943 | V -9.179 | pL 33.333 | vL 1330.344 | ∇ 48.127\n",
      "U 96 | F 1609728 | FPS 2038 | D 47 | rR:μσmM 0.43 0.37 0.00 0.96 | F:μσmM 192.3 120.3 15.0 324.0 | H 1.018 | V -9.466 | pL 31.290 | vL 1244.020 | ∇ 67.532\n",
      "U 97 | F 1626496 | FPS 2045 | D 56 | rR:μσmM 0.44 0.38 0.00 0.95 | F:μσmM 189.7 121.6 17.0 324.0 | H 1.048 | V -10.032 | pL 31.110 | vL 1211.016 | ∇ 41.621\n",
      "U 98 | F 1643264 | FPS 1773 | D 65 | rR:μσmM 0.42 0.37 0.00 0.95 | F:μσmM 195.2 117.4 18.0 324.0 | H 1.133 | V -10.564 | pL 30.970 | vL 1203.998 | ∇ 58.410\n",
      "U 99 | F 1660032 | FPS 1869 | D 74 | rR:μσmM 0.52 0.37 0.00 0.95 | F:μσmM 161.7 118.3 17.0 324.0 | H 1.135 | V -10.960 | pL 28.934 | vL 1091.715 | ∇ 34.606\n",
      "U 100 | F 1676800 | FPS 2052 | D 82 | rR:μσmM 0.62 0.33 0.00 0.94 | F:μσmM 128.8 106.4 20.0 324.0 | H 1.223 | V -11.436 | pL 25.601 | vL 934.970 | ∇ 33.784\n",
      "Status saved\n",
      "U 101 | F 1693568 | FPS 1954 | D 91 | rR:μσmM 0.62 0.31 0.00 0.95 | F:μσmM 132.4 102.5 19.0 324.0 | H 1.369 | V -12.093 | pL 26.334 | vL 972.221 | ∇ 33.862\n",
      "U 102 | F 1710336 | FPS 2060 | D 99 | rR:μσmM 0.61 0.32 0.00 0.95 | F:μσmM 134.2 104.9 19.0 324.0 | H 1.400 | V -12.627 | pL 25.664 | vL 927.926 | ∇ 27.735\n",
      "U 103 | F 1727104 | FPS 2055 | D 107 | rR:μσmM 0.65 0.30 0.00 0.95 | F:μσmM 122.4 98.1 17.0 324.0 | H 1.411 | V -12.949 | pL 25.076 | vL 898.390 | ∇ 31.501\n",
      "U 104 | F 1743872 | FPS 2052 | D 115 | rR:μσmM 0.66 0.31 0.00 0.94 | F:μσmM 118.2 99.9 20.0 324.0 | H 1.417 | V -13.321 | pL 23.293 | vL 823.636 | ∇ 27.358\n",
      "U 105 | F 1760640 | FPS 2026 | D 123 | rR:μσmM 0.68 0.29 0.00 0.95 | F:μσmM 109.9 93.8 18.0 324.0 | H 1.448 | V -13.660 | pL 23.185 | vL 817.750 | ∇ 26.125\n",
      "U 106 | F 1777408 | FPS 2031 | D 132 | rR:μσmM 0.72 0.28 0.00 0.96 | F:μσmM 97.4 91.8 15.0 324.0 | H 1.389 | V -13.762 | pL 20.438 | vL 702.882 | ∇ 26.771\n",
      "U 107 | F 1794176 | FPS 2037 | D 140 | rR:μσmM 0.79 0.18 0.00 0.96 | F:μσmM 74.4 60.3 16.0 324.0 | H 1.348 | V -14.065 | pL 16.388 | vL 523.279 | ∇ 24.226\n",
      "U 108 | F 1810944 | FPS 1937 | D 149 | rR:μσmM 0.80 0.20 0.00 0.96 | F:μσmM 72.1 67.8 15.0 324.0 | H 1.372 | V -14.420 | pL 16.743 | vL 549.916 | ∇ 25.667\n",
      "U 109 | F 1827712 | FPS 2041 | D 157 | rR:μσmM 0.83 0.20 0.00 0.96 | F:μσmM 61.0 65.2 14.0 324.0 | H 1.307 | V -14.487 | pL 14.900 | vL 507.867 | ∇ 23.063\n",
      "U 110 | F 1844480 | FPS 2074 | D 165 | rR:μσmM 0.84 0.18 0.00 0.96 | F:μσmM 56.9 60.0 15.0 324.0 | H 1.296 | V -14.538 | pL 12.543 | vL 411.537 | ∇ 24.870\n",
      "Status saved\n",
      "U 111 | F 1861248 | FPS 2056 | D 173 | rR:μσmM 0.85 0.17 0.00 0.96 | F:μσmM 53.7 56.5 14.0 324.0 | H 1.264 | V -14.567 | pL 12.188 | vL 407.685 | ∇ 24.411\n",
      "U 112 | F 1878016 | FPS 2022 | D 181 | rR:μσmM 0.88 0.13 0.00 0.96 | F:μσmM 41.1 42.9 14.0 324.0 | H 1.111 | V -14.197 | pL 6.847 | vL 233.317 | ∇ 20.618\n",
      "U 113 | F 1894784 | FPS 1688 | D 191 | rR:μσmM 0.90 0.07 0.38 0.96 | F:μσmM 34.4 23.7 14.0 225.0 | H 1.014 | V -13.808 | pL 3.878 | vL 138.714 | ∇ 21.297\n",
      "U 114 | F 1911552 | FPS 2052 | D 200 | rR:μσmM 0.91 0.06 0.35 0.96 | F:μσmM 31.4 21.8 13.0 235.0 | H 0.938 | V -13.487 | pL 2.985 | vL 122.484 | ∇ 21.315\n",
      "U 115 | F 1928320 | FPS 1947 | D 208 | rR:μσmM 0.92 0.05 0.56 0.96 | F:μσmM 27.6 16.4 13.0 160.0 | H 0.859 | V -13.188 | pL 1.248 | vL 82.780 | ∇ 16.894\n",
      "U 116 | F 1945088 | FPS 2023 | D 216 | rR:μσmM 0.93 0.04 0.61 0.96 | F:μσmM 25.0 13.3 13.0 142.0 | H 0.715 | V -12.556 | pL -0.009 | vL 57.206 | ∇ 16.087\n",
      "U 117 | F 1961856 | FPS 2045 | D 225 | rR:μσmM 0.94 0.03 0.70 0.96 | F:μσmM 22.1 10.6 13.0 108.0 | H 0.573 | V -11.813 | pL -1.391 | vL 38.120 | ∇ 13.252\n",
      "U 118 | F 1978624 | FPS 2049 | D 233 | rR:μσmM 0.94 0.02 0.74 0.96 | F:μσmM 20.1 7.4 13.0 92.0 | H 0.471 | V -11.248 | pL -2.224 | vL 29.364 | ∇ 10.696\n",
      "U 119 | F 1995392 | FPS 2045 | D 241 | rR:μσmM 0.95 0.02 0.80 0.96 | F:μσmM 18.5 5.8 13.0 72.0 | H 0.349 | V -10.608 | pL -2.697 | vL 25.477 | ∇ 8.883\n",
      "U 120 | F 2012160 | FPS 2015 | D 249 | rR:μσmM 0.95 0.01 0.87 0.96 | F:μσmM 17.3 3.8 13.0 46.0 | H 0.267 | V -9.882 | pL -2.921 | vL 20.526 | ∇ 6.029\n",
      "Status saved\n",
      "Number of frames:  2012160\n",
      "{'algo': 'ppopc', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'wallgap-doorkey-redblue-crossing', 'early_stop': False, 'seed': 345678, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 500000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 1048, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'cascade_depth': 4, 'flow_factor': 1.0, 'mesh_factor': 4.0, 'lr_decay': True, 'imp_sampling': 'clipped', 'imp_clips': [-5, 5], 'dynamic_neglogpacs': False, 'optimizer_type': 'rmsprop', 'scheduler_flag': False, 'var_init': 'equal', 'reshape_reward': True, 'date': datetime.date(2023, 11, 11), 'mem': False, 'lrs': [0.0007, 0.000175, 4.375e-05, 1.09375e-05], 'lrs_fn': <function decayfn_arr_2.<locals>.f at 0x7f7c2ffb8e60>, 'clipranges': [0.2, 0.05, 0.0125, 0.003125]}\n",
      "\n",
      "Device: cpu\n",
      "\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden models loaded\n",
      "\n",
      "U 1 | F 016768 | FPS 2097 | D 7 | rR:μσmM 0.07 0.18 0.00 0.87 | F:μσmM 135.5 24.3 21.0 144.0 | H 1.928 | V -0.132 | pL 32.130 | vL 1220.593 | ∇ 6.469\n",
      "U 2 | F 033536 | FPS 2209 | D 15 | rR:μσmM 0.11 0.24 0.00 0.89 | F:μσmM 130.1 32.0 17.0 144.0 | H 1.923 | V -0.490 | pL 31.252 | vL 1165.202 | ∇ 7.278\n",
      "U 3 | F 050304 | FPS 2222 | D 23 | rR:μσmM 0.15 0.28 0.00 0.89 | F:μσmM 124.3 37.9 17.0 144.0 | H 1.906 | V -0.840 | pL 30.812 | vL 1145.705 | ∇ 7.553\n",
      "U 4 | F 067072 | FPS 2055 | D 31 | rR:μσmM 0.21 0.31 0.00 0.98 | F:μσmM 116.0 42.8 4.0 144.0 | H 1.885 | V -1.210 | pL 29.904 | vL 1088.155 | ∇ 8.212\n",
      "U 5 | F 083840 | FPS 2054 | D 39 | rR:μσmM 0.23 0.30 0.00 0.99 | F:μσmM 114.1 41.8 2.0 144.0 | H 1.856 | V -1.624 | pL 29.073 | vL 1051.747 | ∇ 10.007\n",
      "U 6 | F 100608 | FPS 2064 | D 47 | rR:μσmM 0.22 0.30 0.00 0.94 | F:μσmM 115.4 41.8 9.0 144.0 | H 1.866 | V -2.085 | pL 29.182 | vL 1050.801 | ∇ 10.172\n",
      "U 7 | F 117376 | FPS 2027 | D 55 | rR:μσmM 0.36 0.37 0.00 0.99 | F:μσmM 95.1 52.8 2.0 144.0 | H 1.849 | V -2.495 | pL 27.592 | vL 978.796 | ∇ 10.346\n",
      "U 8 | F 134144 | FPS 1990 | D 64 | rR:μσmM 0.41 0.35 0.00 0.96 | F:μσmM 88.1 50.2 6.0 144.0 | H 1.817 | V -2.965 | pL 26.185 | vL 898.006 | ∇ 11.569\n",
      "U 9 | F 150912 | FPS 2045 | D 72 | rR:μσmM 0.45 0.33 0.00 0.98 | F:μσmM 84.4 47.7 3.0 144.0 | H 1.794 | V -3.462 | pL 25.165 | vL 846.423 | ∇ 11.006\n",
      "U 10 | F 167680 | FPS 1935 | D 81 | rR:μσmM 0.51 0.34 0.00 0.98 | F:μσmM 75.5 49.9 4.0 144.0 | H 1.753 | V -3.838 | pL 24.360 | vL 812.255 | ∇ 13.577\n",
      "Status saved\n",
      "U 11 | F 184448 | FPS 2033 | D 89 | rR:μσmM 0.58 0.32 0.00 0.98 | F:μσmM 64.6 46.4 3.0 144.0 | H 1.720 | V -4.252 | pL 22.008 | vL 701.095 | ∇ 13.908\n",
      "U 12 | F 201216 | FPS 2081 | D 97 | rR:μσmM 0.68 0.24 0.00 0.99 | F:μσmM 49.9 36.3 2.0 144.0 | H 1.702 | V -4.598 | pL 18.075 | vL 521.351 | ∇ 12.259\n",
      "U 13 | F 217984 | FPS 2077 | D 105 | rR:μσmM 0.72 0.23 0.00 0.98 | F:μσmM 45.0 34.7 3.0 144.0 | H 1.624 | V -4.924 | pL 16.512 | vL 458.480 | ∇ 11.861\n",
      "U 14 | F 234752 | FPS 2055 | D 113 | rR:μσmM 0.81 0.14 0.10 0.99 | F:μσmM 30.7 22.2 2.0 144.0 | H 1.479 | V -5.271 | pL 10.638 | vL 237.215 | ∇ 11.766\n",
      "U 15 | F 251520 | FPS 2059 | D 121 | rR:μσmM 0.86 0.11 0.18 0.99 | F:μσmM 22.4 17.0 2.0 131.0 | H 1.297 | V -5.254 | pL 7.020 | vL 140.560 | ∇ 10.662\n",
      "U 16 | F 268288 | FPS 2030 | D 130 | rR:μσmM 0.90 0.06 0.51 0.99 | F:μσmM 16.6 10.3 2.0 79.0 | H 1.087 | V -5.343 | pL 3.243 | vL 54.106 | ∇ 9.333\n",
      "U 17 | F 285056 | FPS 1924 | D 138 | rR:μσmM 0.91 0.05 0.61 0.99 | F:μσmM 13.7 7.5 2.0 62.0 | H 0.903 | V -5.065 | pL 1.623 | vL 25.813 | ∇ 8.152\n",
      "U 18 | F 301824 | FPS 2030 | D 147 | rR:μσmM 0.92 0.04 0.58 0.99 | F:μσmM 12.1 6.0 2.0 67.0 | H 0.724 | V -4.864 | pL 0.643 | vL 14.544 | ∇ 6.908\n",
      "U 19 | F 318592 | FPS 2012 | D 155 | rR:μσmM 0.94 0.03 0.74 0.99 | F:μσmM 10.4 4.6 2.0 41.0 | H 0.509 | V -4.331 | pL -0.003 | vL 6.268 | ∇ 5.103\n",
      "U 20 | F 335360 | FPS 2030 | D 163 | rR:μσmM 0.94 0.02 0.82 0.99 | F:μσmM 9.3 3.4 2.0 28.0 | H 0.349 | V -4.022 | pL -0.585 | vL 2.591 | ∇ 3.942\n",
      "Status saved\n",
      "U 21 | F 352128 | FPS 2007 | D 172 | rR:μσmM 0.94 0.02 0.82 0.99 | F:μσmM 8.9 3.2 2.0 29.0 | H 0.249 | V -3.882 | pL -0.812 | vL 2.362 | ∇ 3.005\n",
      "U 22 | F 368896 | FPS 1643 | D 182 | rR:μσmM 0.95 0.02 0.84 0.99 | F:μσmM 8.6 2.8 2.0 25.0 | H 0.179 | V -3.519 | pL -0.647 | vL 1.452 | ∇ 2.514\n",
      "U 23 | F 385664 | FPS 1989 | D 190 | rR:μσmM 0.95 0.02 0.88 0.99 | F:μσmM 8.5 2.6 2.0 19.0 | H 0.137 | V -3.178 | pL -0.201 | vL 0.665 | ∇ 2.167\n",
      "U 24 | F 402432 | FPS 1901 | D 199 | rR:μσmM 0.95 0.02 0.83 0.99 | F:μσmM 8.3 2.6 2.0 27.0 | H 0.111 | V -3.017 | pL -0.165 | vL 0.602 | ∇ 1.900\n",
      "U 25 | F 419200 | FPS 1988 | D 208 | rR:μσmM 0.95 0.01 0.88 0.99 | F:μσmM 8.2 2.4 2.0 19.0 | H 0.080 | V -2.936 | pL -0.177 | vL 0.419 | ∇ 1.598\n",
      "U 26 | F 435968 | FPS 2004 | D 216 | rR:μσmM 0.95 0.01 0.89 0.99 | F:μσmM 8.3 2.3 2.0 17.0 | H 0.064 | V -2.900 | pL 0.006 | vL 0.312 | ∇ 1.433\n",
      "U 27 | F 452736 | FPS 2017 | D 224 | rR:μσmM 0.95 0.01 0.88 0.99 | F:μσmM 8.2 2.2 2.0 19.0 | H 0.048 | V -2.833 | pL 0.095 | vL 0.271 | ∇ 1.295\n",
      "U 28 | F 469504 | FPS 2006 | D 233 | rR:μσmM 0.95 0.01 0.86 0.99 | F:μσmM 8.2 2.2 2.0 23.0 | H 0.040 | V -2.825 | pL 0.131 | vL 0.240 | ∇ 1.171\n",
      "U 29 | F 486272 | FPS 2014 | D 241 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.2 2.1 2.0 14.0 | H 0.030 | V -2.822 | pL -0.110 | vL 0.206 | ∇ 0.975\n",
      "U 30 | F 503040 | FPS 1980 | D 249 | rR:μσmM 0.95 0.01 0.91 0.99 | F:μσmM 8.2 2.1 2.0 14.0 | H 0.021 | V -2.804 | pL 0.017 | vL 0.192 | ∇ 0.925\n",
      "Status saved\n",
      "Number of frames:  503040\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 31 | F 519808 | FPS 1974 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.790 | V -6.107 | pL 40.073 | vL 1782.385 | ∇ 151.048\n",
      "U 32 | F 536576 | FPS 2344 | D 15 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.890 | V -6.621 | pL 38.333 | vL 1647.842 | ∇ 57.373\n",
      "U 33 | F 553344 | FPS 2224 | D 23 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.941 | V -7.071 | pL 37.615 | vL 1580.654 | ∇ 43.406\n",
      "U 34 | F 570112 | FPS 2063 | D 31 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 0.987 | V -7.558 | pL 36.957 | vL 1531.693 | ∇ 40.848\n",
      "U 35 | F 586880 | FPS 2064 | D 39 | rR:μσmM 0.00 0.02 0.00 0.13 | F:μσmM 359.8 1.6 349.0 360.0 | H 1.039 | V -8.035 | pL 36.446 | vL 1501.977 | ∇ 34.317\n",
      "U 36 | F 603648 | FPS 2011 | D 47 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 360.0 0.0 360.0 360.0 | H 1.113 | V -8.471 | pL 36.155 | vL 1478.409 | ∇ 31.965\n",
      "U 37 | F 620416 | FPS 2026 | D 56 | rR:μσmM 0.01 0.06 0.00 0.42 | F:μσmM 357.3 18.3 232.0 360.0 | H 1.129 | V -8.878 | pL 35.826 | vL 1462.485 | ∇ 28.438\n",
      "U 38 | F 637184 | FPS 1959 | D 64 | rR:μσmM 0.01 0.08 0.00 0.55 | F:μσmM 356.3 25.6 181.0 360.0 | H 1.139 | V -9.246 | pL 35.905 | vL 1462.575 | ∇ 27.792\n",
      "U 39 | F 653952 | FPS 2022 | D 72 | rR:μσmM 0.00 0.02 0.00 0.17 | F:μσmM 359.5 3.7 334.0 360.0 | H 1.240 | V -9.903 | pL 35.549 | vL 1448.528 | ∇ 25.190\n",
      "U 40 | F 670720 | FPS 2037 | D 81 | rR:μσmM 0.02 0.08 0.00 0.38 | F:μσmM 354.9 21.0 247.0 360.0 | H 1.299 | V -10.132 | pL 35.686 | vL 1457.531 | ∇ 25.020\n",
      "Status saved\n",
      "U 41 | F 687488 | FPS 2048 | D 89 | rR:μσmM 0.07 0.19 0.00 0.74 | F:μσmM 338.0 62.3 104.0 360.0 | H 1.399 | V -10.643 | pL 35.238 | vL 1441.285 | ∇ 26.410\n",
      "U 42 | F 704256 | FPS 2067 | D 97 | rR:μσmM 0.11 0.23 0.00 0.86 | F:μσmM 326.1 79.3 55.0 360.0 | H 1.498 | V -11.103 | pL 35.107 | vL 1421.879 | ∇ 23.197\n",
      "U 43 | F 721024 | FPS 2071 | D 105 | rR:μσmM 0.09 0.21 0.00 0.84 | F:μσmM 332.0 72.3 63.0 360.0 | H 1.521 | V -11.603 | pL 34.588 | vL 1383.188 | ∇ 21.895\n",
      "U 44 | F 737792 | FPS 2071 | D 113 | rR:μσmM 0.05 0.15 0.00 0.73 | F:μσmM 344.8 48.5 107.0 360.0 | H 1.558 | V -11.971 | pL 34.425 | vL 1369.723 | ∇ 22.846\n",
      "U 45 | F 754560 | FPS 2034 | D 121 | rR:μσmM 0.07 0.16 0.00 0.75 | F:μσmM 340.4 51.2 100.0 360.0 | H 1.539 | V -12.302 | pL 34.071 | vL 1344.582 | ∇ 23.483\n",
      "U 46 | F 771328 | FPS 1951 | D 130 | rR:μσmM 0.09 0.20 0.00 0.75 | F:μσmM 332.1 68.1 98.0 360.0 | H 1.555 | V -12.779 | pL 33.727 | vL 1326.991 | ∇ 22.019\n",
      "U 47 | F 788096 | FPS 2056 | D 138 | rR:μσmM 0.11 0.22 0.00 0.94 | F:μσmM 326.7 74.2 22.0 360.0 | H 1.539 | V -13.143 | pL 33.398 | vL 1311.050 | ∇ 23.655\n",
      "U 48 | F 804864 | FPS 2057 | D 146 | rR:μσmM 0.09 0.20 0.00 0.73 | F:μσmM 332.7 66.4 107.0 360.0 | H 1.537 | V -13.659 | pL 33.555 | vL 1309.851 | ∇ 18.940\n",
      "U 49 | F 821632 | FPS 2078 | D 154 | rR:μσmM 0.14 0.28 0.00 0.88 | F:μσmM 313.6 96.2 46.0 360.0 | H 1.557 | V -14.047 | pL 32.454 | vL 1254.041 | ∇ 20.575\n",
      "U 50 | F 838400 | FPS 2051 | D 163 | rR:μσmM 0.10 0.20 0.00 0.70 | F:μσmM 329.4 64.3 120.0 360.0 | H 1.535 | V -14.403 | pL 32.735 | vL 1264.683 | ∇ 20.246\n",
      "Status saved\n",
      "U 51 | F 855168 | FPS 1990 | D 171 | rR:μσmM 0.07 0.17 0.00 0.71 | F:μσmM 339.0 52.6 115.0 360.0 | H 1.561 | V -14.713 | pL 32.870 | vL 1271.967 | ∇ 21.457\n",
      "U 52 | F 871936 | FPS 1933 | D 180 | rR:μσmM 0.10 0.23 0.00 0.87 | F:μσmM 328.4 78.7 54.0 360.0 | H 1.586 | V -15.174 | pL 32.373 | vL 1238.933 | ∇ 25.247\n",
      "U 53 | F 888704 | FPS 1966 | D 188 | rR:μσmM 0.20 0.28 0.00 0.81 | F:μσmM 296.3 94.9 75.0 360.0 | H 1.552 | V -15.373 | pL 31.300 | vL 1190.481 | ∇ 20.221\n",
      "U 54 | F 905472 | FPS 2057 | D 196 | rR:μσmM 0.22 0.30 0.00 0.88 | F:μσmM 289.6 102.5 46.0 360.0 | H 1.599 | V -15.770 | pL 31.108 | vL 1173.340 | ∇ 20.803\n",
      "U 55 | F 922240 | FPS 2078 | D 204 | rR:μσmM 0.29 0.34 0.00 0.94 | F:μσmM 265.0 118.4 26.0 360.0 | H 1.596 | V -16.090 | pL 29.990 | vL 1117.638 | ∇ 23.495\n",
      "U 56 | F 939008 | FPS 2043 | D 213 | rR:μσmM 0.33 0.33 0.00 0.96 | F:μσmM 249.5 117.4 15.0 360.0 | H 1.649 | V -16.417 | pL 29.504 | vL 1090.098 | ∇ 22.685\n",
      "U 57 | F 955776 | FPS 2042 | D 221 | rR:μσmM 0.45 0.35 0.00 0.95 | F:μσmM 206.9 123.7 19.0 360.0 | H 1.656 | V -16.459 | pL 27.651 | vL 1013.258 | ∇ 25.016\n",
      "U 58 | F 972544 | FPS 2069 | D 229 | rR:μσmM 0.50 0.32 0.00 0.96 | F:μσmM 191.2 115.3 15.0 360.0 | H 1.666 | V -16.794 | pL 26.963 | vL 977.192 | ∇ 20.256\n",
      "U 59 | F 989312 | FPS 2056 | D 237 | rR:μσmM 0.62 0.29 0.00 0.97 | F:μσmM 149.0 110.9 13.0 360.0 | H 1.604 | V -16.927 | pL 23.759 | vL 830.146 | ∇ 21.645\n",
      "U 60 | F 1006080 | FPS 1975 | D 246 | rR:μσmM 0.70 0.25 0.00 0.96 | F:μσmM 117.7 94.9 14.0 360.0 | H 1.575 | V -16.829 | pL 21.813 | vL 761.623 | ∇ 21.911\n",
      "Status saved\n",
      "Number of frames:  1006080\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 61 | F 1022848 | FPS 2110 | D 7 | rR:μσmM 0.33 0.38 0.00 0.96 | F:μσmM 143.6 158.0 4.0 720.0 | H 1.624 | V -17.659 | pL 28.056 | vL 1091.824 | ∇ 25.328\n",
      "U 62 | F 1039616 | FPS 2319 | D 15 | rR:μσmM 0.37 0.39 0.00 0.96 | F:μσmM 156.4 156.8 4.0 720.0 | H 1.619 | V -18.116 | pL 23.950 | vL 886.791 | ∇ 24.580\n",
      "U 63 | F 1056384 | FPS 2052 | D 23 | rR:μσmM 0.34 0.39 0.00 0.97 | F:μσmM 110.5 115.5 1.0 609.0 | H 1.637 | V -18.425 | pL 22.588 | vL 840.643 | ∇ 25.711\n",
      "U 64 | F 1073152 | FPS 2037 | D 31 | rR:μσmM 0.36 0.41 0.00 0.98 | F:μσmM 96.7 122.7 1.0 720.0 | H 1.618 | V -18.619 | pL 19.962 | vL 746.878 | ∇ 30.567\n",
      "U 65 | F 1089920 | FPS 2012 | D 39 | rR:μσmM 0.35 0.43 0.00 0.99 | F:μσmM 57.5 70.2 2.0 600.0 | H 1.569 | V -18.716 | pL 11.590 | vL 452.286 | ∇ 29.388\n",
      "U 66 | F 1106688 | FPS 1937 | D 48 | rR:μσmM 0.28 0.42 0.00 0.99 | F:μσmM 43.6 48.5 1.0 346.0 | H 1.539 | V -18.753 | pL 7.868 | vL 367.881 | ∇ 27.932\n",
      "U 67 | F 1123456 | FPS 2051 | D 56 | rR:μσmM 0.24 0.41 0.00 0.99 | F:μσmM 33.9 36.9 1.0 246.0 | H 1.465 | V -18.954 | pL 4.636 | vL 312.079 | ∇ 29.479\n",
      "U 68 | F 1140224 | FPS 1924 | D 65 | rR:μσmM 0.19 0.38 0.00 0.99 | F:μσmM 25.2 31.4 1.0 441.0 | H 1.362 | V -18.898 | pL -0.512 | vL 219.508 | ∇ 28.931\n",
      "U 69 | F 1156992 | FPS 2022 | D 73 | rR:μσmM 0.16 0.36 0.00 0.99 | F:μσmM 17.8 15.0 1.0 137.0 | H 1.207 | V -18.449 | pL -6.231 | vL 145.330 | ∇ 23.732\n",
      "U 70 | F 1173760 | FPS 2026 | D 82 | rR:μσmM 0.14 0.34 0.00 0.99 | F:μσmM 13.9 10.7 1.0 110.0 | H 0.996 | V -17.991 | pL -9.224 | vL 139.749 | ∇ 19.115\n",
      "Status saved\n",
      "U 71 | F 1190528 | FPS 2014 | D 90 | rR:μσmM 0.10 0.29 0.00 0.99 | F:μσmM 11.4 7.7 1.0 62.0 | H 0.770 | V -17.310 | pL -10.982 | vL 146.795 | ∇ 15.696\n",
      "U 72 | F 1207296 | FPS 1998 | D 98 | rR:μσmM 0.09 0.29 0.00 0.99 | F:μσmM 10.0 7.1 1.0 141.0 | H 0.634 | V -16.365 | pL -11.111 | vL 149.660 | ∇ 13.865\n",
      "U 73 | F 1224064 | FPS 1980 | D 107 | rR:μσmM 0.10 0.29 0.00 0.99 | F:μσmM 9.1 5.4 1.0 68.0 | H 0.463 | V -15.193 | pL -11.234 | vL 136.075 | ∇ 11.576\n",
      "U 74 | F 1240832 | FPS 1984 | D 115 | rR:μσmM 0.08 0.27 0.00 0.99 | F:μσmM 8.3 4.9 1.0 53.0 | H 0.352 | V -14.027 | pL -10.783 | vL 123.002 | ∇ 11.462\n",
      "U 75 | F 1257600 | FPS 1848 | D 124 | rR:μσmM 0.11 0.30 0.00 0.99 | F:μσmM 8.3 4.8 1.0 63.0 | H 0.259 | V -12.824 | pL -9.528 | vL 100.486 | ∇ 11.055\n",
      "U 76 | F 1274368 | FPS 1985 | D 133 | rR:μσmM 0.11 0.31 0.00 0.99 | F:μσmM 8.0 4.8 1.0 73.0 | H 0.198 | V -11.252 | pL -8.226 | vL 79.976 | ∇ 9.922\n",
      "U 77 | F 1291136 | FPS 1976 | D 141 | rR:μσmM 0.11 0.31 0.00 0.99 | F:μσmM 8.0 4.7 1.0 78.0 | H 0.140 | V -9.695 | pL -6.891 | vL 60.482 | ∇ 8.273\n",
      "U 78 | F 1307904 | FPS 1976 | D 150 | rR:μσmM 0.09 0.28 0.00 0.99 | F:μσmM 7.7 4.2 1.0 48.0 | H 0.117 | V -8.617 | pL -6.163 | vL 50.238 | ∇ 7.522\n",
      "U 79 | F 1324672 | FPS 1974 | D 158 | rR:μσmM 0.09 0.28 0.00 0.99 | F:μσmM 7.4 3.8 1.0 34.0 | H 0.086 | V -7.182 | pL -4.733 | vL 35.005 | ∇ 5.800\n",
      "U 80 | F 1341440 | FPS 1968 | D 167 | rR:μσmM 0.08 0.26 0.00 0.99 | F:μσmM 7.3 3.7 1.0 31.0 | H 0.057 | V -6.210 | pL -3.833 | vL 26.354 | ∇ 5.266\n",
      "Status saved\n",
      "U 81 | F 1358208 | FPS 1989 | D 175 | rR:μσmM 0.08 0.26 0.00 0.99 | F:μσmM 7.4 4.3 1.0 85.0 | H 0.056 | V -5.580 | pL -2.726 | vL 20.818 | ∇ 5.984\n",
      "U 82 | F 1374976 | FPS 1852 | D 184 | rR:μσmM 0.09 0.28 0.00 0.99 | F:μσmM 7.4 4.2 1.0 60.0 | H 0.050 | V -5.060 | pL -2.202 | vL 15.450 | ∇ 6.311\n",
      "U 83 | F 1391744 | FPS 1947 | D 193 | rR:μσmM 0.08 0.26 0.00 0.99 | F:μσmM 7.2 3.5 1.0 35.0 | H 0.032 | V -4.474 | pL -2.170 | vL 11.139 | ∇ 3.700\n",
      "U 84 | F 1408512 | FPS 1970 | D 201 | rR:μσmM 0.07 0.25 0.00 0.99 | F:μσmM 7.1 3.7 1.0 37.0 | H 0.031 | V -4.095 | pL -1.396 | vL 8.127 | ∇ 4.478\n",
      "U 85 | F 1425280 | FPS 1981 | D 210 | rR:μσmM 0.07 0.26 0.00 0.99 | F:μσmM 7.2 3.8 1.0 47.0 | H 0.025 | V -4.045 | pL -1.467 | vL 6.996 | ∇ 4.195\n",
      "U 86 | F 1442048 | FPS 1963 | D 218 | rR:μσmM 0.08 0.26 0.00 0.99 | F:μσmM 7.1 3.5 1.0 28.0 | H 0.020 | V -3.730 | pL -1.123 | vL 5.477 | ∇ 3.621\n",
      "U 87 | F 1458816 | FPS 1970 | D 227 | rR:μσmM 0.07 0.25 0.00 0.99 | F:μσmM 7.1 3.7 1.0 48.0 | H 0.021 | V -3.529 | pL -0.759 | vL 5.251 | ∇ 4.152\n",
      "U 88 | F 1475584 | FPS 1950 | D 236 | rR:μσmM 0.07 0.26 0.00 0.99 | F:μσmM 6.9 3.5 1.0 38.0 | H 0.018 | V -3.317 | pL -0.761 | vL 3.812 | ∇ 3.237\n",
      "U 89 | F 1492352 | FPS 1858 | D 245 | rR:μσmM 0.08 0.26 0.00 0.99 | F:μσmM 7.0 3.8 1.0 92.0 | H 0.019 | V -3.244 | pL -0.488 | vL 6.104 | ∇ 3.795\n",
      "U 90 | F 1509120 | FPS 1972 | D 253 | rR:μσmM 0.08 0.27 0.00 0.99 | F:μσmM 7.1 3.4 1.0 21.0 | H 0.014 | V -3.193 | pL -0.549 | vL 2.484 | ∇ 2.898\n",
      "Status saved\n",
      "Number of frames:  1509120\n",
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden policies initialized as visible policy\n",
      "Hidden models loaded\n",
      "\n",
      "U 91 | F 1525888 | FPS 2076 | D 8 | rR:μσmM 0.13 0.31 0.00 0.96 | F:μσmM 283.6 97.6 15.0 324.0 | H 0.696 | V -9.468 | pL 35.240 | vL 1488.879 | ∇ 239.820\n",
      "U 92 | F 1542656 | FPS 2328 | D 15 | rR:μσmM 0.29 0.40 0.00 0.96 | F:μσmM 231.9 127.2 15.0 324.0 | H 0.841 | V -9.499 | pL 33.766 | vL 1361.706 | ∇ 80.425\n",
      "U 93 | F 1559424 | FPS 2150 | D 23 | rR:μσmM 0.20 0.35 0.00 0.92 | F:μσmM 261.6 111.9 29.0 324.0 | H 0.989 | V -9.884 | pL 34.318 | vL 1379.449 | ∇ 89.660\n",
      "U 94 | F 1576192 | FPS 1751 | D 32 | rR:μσmM 0.19 0.35 0.00 0.95 | F:μσmM 264.1 110.7 17.0 324.0 | H 1.009 | V -10.272 | pL 34.471 | vL 1375.325 | ∇ 67.645\n",
      "U 95 | F 1592960 | FPS 1893 | D 41 | rR:μσmM 0.29 0.40 0.00 0.95 | F:μσmM 235.1 127.0 17.0 324.0 | H 0.980 | V -10.616 | pL 32.758 | vL 1326.911 | ∇ 56.751\n",
      "U 96 | F 1609728 | FPS 1940 | D 50 | rR:μσmM 0.31 0.36 0.00 0.93 | F:μσmM 228.4 114.5 25.0 324.0 | H 1.024 | V -11.413 | pL 31.978 | vL 1252.707 | ∇ 47.700\n",
      "U 97 | F 1626496 | FPS 2033 | D 58 | rR:μσmM 0.40 0.42 0.00 0.95 | F:μσmM 197.9 132.5 18.0 324.0 | H 1.022 | V -11.729 | pL 31.729 | vL 1243.652 | ∇ 44.905\n",
      "U 98 | F 1643264 | FPS 2013 | D 66 | rR:μσmM 0.43 0.41 0.00 0.96 | F:μσmM 188.1 130.3 16.0 324.0 | H 1.159 | V -12.336 | pL 29.737 | vL 1154.712 | ∇ 40.378\n",
      "U 99 | F 1660032 | FPS 2024 | D 75 | rR:μσmM 0.49 0.41 0.00 0.96 | F:μσmM 168.7 130.5 14.0 324.0 | H 1.238 | V -12.448 | pL 29.840 | vL 1150.321 | ∇ 38.426\n",
      "U 100 | F 1676800 | FPS 2024 | D 83 | rR:μσmM 0.49 0.39 0.00 0.95 | F:μσmM 171.7 124.8 18.0 324.0 | H 1.283 | V -13.001 | pL 29.171 | vL 1108.504 | ∇ 36.115\n",
      "Status saved\n",
      "U 101 | F 1693568 | FPS 2076 | D 91 | rR:μσmM 0.54 0.40 0.00 0.96 | F:μσmM 153.3 129.8 16.0 324.0 | H 1.354 | V -13.337 | pL 28.141 | vL 1072.425 | ∇ 34.286\n",
      "U 102 | F 1710336 | FPS 2048 | D 99 | rR:μσmM 0.49 0.40 0.00 0.96 | F:μσmM 169.4 130.0 15.0 324.0 | H 1.422 | V -13.818 | pL 28.203 | vL 1067.868 | ∇ 31.692\n",
      "U 103 | F 1727104 | FPS 1923 | D 108 | rR:μσmM 0.49 0.39 0.00 0.95 | F:μσmM 170.6 124.6 18.0 324.0 | H 1.435 | V -14.341 | pL 27.968 | vL 1052.595 | ∇ 28.986\n",
      "U 104 | F 1743872 | FPS 2050 | D 116 | rR:μσmM 0.51 0.37 0.00 0.95 | F:μσmM 165.0 117.6 19.0 324.0 | H 1.469 | V -14.590 | pL 28.026 | vL 1037.066 | ∇ 28.883\n",
      "U 105 | F 1760640 | FPS 2051 | D 124 | rR:μσmM 0.47 0.38 0.00 0.95 | F:μσmM 178.5 122.9 17.0 324.0 | H 1.475 | V -15.010 | pL 27.911 | vL 1032.236 | ∇ 30.356\n",
      "U 106 | F 1777408 | FPS 2037 | D 132 | rR:μσmM 0.42 0.37 0.00 0.95 | F:μσmM 195.5 119.7 19.0 324.0 | H 1.501 | V -15.414 | pL 27.463 | vL 1016.618 | ∇ 29.503\n",
      "U 107 | F 1794176 | FPS 2060 | D 141 | rR:μσmM 0.50 0.36 0.00 0.94 | F:μσmM 170.6 114.5 20.0 324.0 | H 1.501 | V -15.668 | pL 27.213 | vL 990.089 | ∇ 27.238\n",
      "U 108 | F 1810944 | FPS 1781 | D 150 | rR:μσmM 0.53 0.37 0.00 0.95 | F:μσmM 158.8 119.4 17.0 324.0 | H 1.520 | V -15.943 | pL 25.426 | vL 917.573 | ∇ 26.710\n",
      "U 109 | F 1827712 | FPS 1748 | D 160 | rR:μσmM 0.51 0.36 0.00 0.95 | F:μσmM 166.3 113.9 19.0 324.0 | H 1.513 | V -16.277 | pL 25.857 | vL 931.723 | ∇ 25.931\n",
      "U 110 | F 1844480 | FPS 1945 | D 168 | rR:μσmM 0.57 0.31 0.00 0.94 | F:μσmM 150.2 100.9 22.0 324.0 | H 1.512 | V -16.422 | pL 24.493 | vL 857.975 | ∇ 23.690\n",
      "Status saved\n",
      "U 111 | F 1861248 | FPS 2036 | D 176 | rR:μσmM 0.66 0.30 0.00 0.95 | F:μσmM 116.4 97.4 18.0 324.0 | H 1.495 | V -16.617 | pL 21.612 | vL 735.011 | ∇ 22.874\n",
      "U 112 | F 1878016 | FPS 2049 | D 185 | rR:μσmM 0.69 0.29 0.00 0.96 | F:μσmM 108.8 94.4 15.0 324.0 | H 1.459 | V -16.709 | pL 20.638 | vL 703.913 | ∇ 24.194\n",
      "U 113 | F 1894784 | FPS 2052 | D 193 | rR:μσmM 0.75 0.25 0.00 0.96 | F:μσmM 88.9 81.7 14.0 324.0 | H 1.415 | V -16.792 | pL 18.051 | vL 611.051 | ∇ 24.641\n",
      "U 114 | F 1911552 | FPS 2032 | D 201 | rR:μσmM 0.77 0.21 0.00 0.96 | F:μσmM 83.0 71.6 14.0 324.0 | H 1.400 | V -16.919 | pL 16.088 | vL 528.463 | ∇ 25.461\n",
      "U 115 | F 1928320 | FPS 2062 | D 209 | rR:μσmM 0.79 0.19 0.00 0.96 | F:μσmM 73.7 63.0 15.0 324.0 | H 1.394 | V -16.975 | pL 13.948 | vL 444.825 | ∇ 25.725\n",
      "U 116 | F 1945088 | FPS 2019 | D 218 | rR:μσmM 0.83 0.16 0.00 0.96 | F:μσmM 59.1 54.1 14.0 324.0 | H 1.314 | V -16.867 | pL 11.773 | vL 391.442 | ∇ 25.284\n",
      "U 117 | F 1961856 | FPS 1957 | D 226 | rR:μσmM 0.86 0.12 0.00 0.96 | F:μσmM 51.3 42.9 14.0 324.0 | H 1.249 | V -16.716 | pL 8.428 | vL 279.436 | ∇ 22.431\n",
      "U 118 | F 1978624 | FPS 2044 | D 234 | rR:μσmM 0.87 0.10 0.26 0.96 | F:μσmM 47.9 36.9 14.0 268.0 | H 1.224 | V -16.697 | pL 6.557 | vL 225.613 | ∇ 22.367\n",
      "U 119 | F 1995392 | FPS 2045 | D 243 | rR:μσmM 0.89 0.08 0.27 0.96 | F:μσmM 40.2 30.0 14.0 262.0 | H 1.127 | V -16.314 | pL 4.920 | vL 188.096 | ∇ 23.006\n",
      "U 120 | F 2012160 | FPS 2054 | D 251 | rR:μσmM 0.90 0.06 0.39 0.96 | F:μσmM 35.8 22.2 13.0 221.0 | H 1.046 | V -15.956 | pL 2.342 | vL 119.483 | ∇ 17.365\n",
      "Status saved\n",
      "Number of frames:  2012160\n"
     ]
    }
   ],
   "source": [
    "# JUPYTER SETTINGS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# IMPORT LIBRARIES\n",
    "\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "\n",
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env\n",
    "\n",
    "# functions to calculate decays\n",
    "def constfn(val):\n",
    "    def f(_):\n",
    "        return val\n",
    "    return f\n",
    "\n",
    "def constfn_arr(val,length):\n",
    "    return [val for i in range(length)]\n",
    "\n",
    "def constfn_arr2(val,length):\n",
    "    def f(_):\n",
    "        return [val for i in range(length)]\n",
    "    return f\n",
    "\n",
    "def decayfn_arr_2(start, decay, length):\n",
    "    def f(start):\n",
    "        return [start*decay**i for i in range(length)]\n",
    "    return f\n",
    "\n",
    "def decayfn_arr(start, decay, length):\n",
    "    return [start*decay**i for i in range(length)]\n",
    "\n",
    "# List of tasks\n",
    "\n",
    "sequence = 2\n",
    "\n",
    "if sequence == 0:\n",
    "    ## Experiment 0\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-RedBlueDoors-6x6-v0'), \n",
    "        (1, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (2, 'MiniGrid-WallGapS6-v0'),\n",
    "        (3, 'MiniGrid-LavaGapS6-v0')      \n",
    "        ]\n",
    "elif sequence == 1:\n",
    "    ## Experiment 1\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (1, 'MiniGrid-RedBlueDoors-6x6-v0'), \n",
    "        (2, 'MiniGrid-WallGapS6-v0'),\n",
    "        (3, 'MiniGrid-LavaGapS6-v0')\n",
    "        ]\n",
    "elif sequence == 2:\n",
    "    ## Experiment 3\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-WallGapS6-v0'),\n",
    "        (1, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (2, 'MiniGrid-RedBlueDoors-6x6-v0'), \n",
    "        (3, 'MiniGrid-SimpleCrossingS9N1-v0')   \n",
    "        ]\n",
    "elif sequence == 3:\n",
    "    ## Experiment 4\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-WallGapS6-v0'),\n",
    "        (1, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (2, 'MiniGrid-SimpleCrossingS9N1-v0'),\n",
    "        (3, 'MiniGrid-UnlockPickup-v0'), \n",
    "        ]\n",
    "elif sequence == 4:\n",
    "    ## Experiment 4\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-UnlockPickup-v0'),\n",
    "        (1, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (2, 'MiniGrid-WallGapS6-v0'),\n",
    "        (3, 'MiniGrid-SimpleCrossingS9N1-v0'), \n",
    "        ]\n",
    "elif sequence == 5:\n",
    "    ## Experiment 3\n",
    "    taskcla = [(0,7), (1,7), (2,7), (3,7)]\n",
    "    tasks_sequence = [\n",
    "        (0, 'MiniGrid-LavaGapS5-v0'),\n",
    "        (1, 'MiniGrid-DoorKey-6x6-v0'),\n",
    "        (2, 'MiniGrid-RedBlueDoors-6x6-v0'), \n",
    "        (3, 'MiniGrid-WallGapS6-v0')   \n",
    "        ]\n",
    "\n",
    "seed_list = [123456, 789012, 345678]\n",
    "\n",
    "model = \"wallgap-doorkey-redblue-crossing\"\n",
    "frames_per_proc = 128\n",
    "processes = 16\n",
    "\n",
    "for seed in seed_list:\n",
    "    \n",
    "    # START TRAINING 1st ENVIRONMENT ----------------------\n",
    "\n",
    "    # LOAD PARAMETERS\n",
    "    index = 0\n",
    "    env_id = tasks_sequence[index][1]\n",
    "\n",
    "    frames = 5e5\n",
    "    add_frames = 5e5\n",
    "\n",
    "    ## Hyper-parameters\n",
    "    args = {\n",
    "    # General parameters\n",
    "    'algo':\"ppo\",\n",
    "    'env':env_id,\n",
    "    'model':model,\n",
    "    'early_stop':False,\n",
    "    'seed':seed,\n",
    "    'log_interval':1,\n",
    "    'save_interval':10,\n",
    "    'procs':processes,\n",
    "    'frames':int(frames), # default 1e7\n",
    "    # Parameters for main algorithm\n",
    "    'epochs':4,\n",
    "    'batch_size':256,\n",
    "    'frames_per_proc':frames_per_proc, # 128 for PPO and 5 per A2C\n",
    "    'discount':0.99,\n",
    "    #'lr':2.5e-4,#0.0001, # for Adam\n",
    "    'lr':0.0007, # for RMSProp\n",
    "    #'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "    'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "    'entropy_coef': 0.01,\n",
    "    'value_loss_coef':0.5,\n",
    "    'max_grad_norm':0.5,\n",
    "    'optim_eps':1e-8,\n",
    "    'optim_alpha':0.99,\n",
    "    'clip_eps':0.2,\n",
    "    'recurrence':1, # if > 1, a LSTM is added\n",
    "    'text':False, # add a GRU for text input\n",
    "    # Model Parameters\n",
    "    'optimizer_type':'rmsprop',\n",
    "    #'optimizer_type':'adam',\n",
    "    #'scheduler_flag':False,\n",
    "    #'var_init':'equal',\n",
    "    'reshape_reward':True,\n",
    "    'date':datetime.date.today()\n",
    "    }\n",
    "\n",
    "    #args = utils.dotdict(args)\n",
    "    args = DictList(args)\n",
    "\n",
    "    args.mem = args.recurrence > 1\n",
    "\n",
    "    # INITIAL SETTINGS\n",
    "\n",
    "    # Set run dir\n",
    "\n",
    "    date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "    default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "    #model_name = args.model or default_model_name\n",
    "    model_name = '{}_{}_{}_{}_{}_frames_{}_reshape_{}'.format(args.date, args.model, args.algo, args.seed, args.frames, args.frames_per_proc, args.reshape_reward) or default_model_name\n",
    "    model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "    # Load loggers and Tensorboard writer\n",
    "\n",
    "    txt_logger = utils.get_txt_logger(model_dir)\n",
    "    csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "    tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "    # Log command and all script arguments\n",
    "\n",
    "    #txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "    txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "    # Set seed for all randomness sources\n",
    "\n",
    "    utils.seed(args.seed)\n",
    "\n",
    "    # Set device\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    txt_logger.info(f\"Device: {device}\\n\")\n",
    "\n",
    "\n",
    "    # LOAD ENVIRONMENTS AND INITIALIZE MODELS\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "    txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "    # Load training status\n",
    "\n",
    "    try:\n",
    "        status = utils.get_status(model_dir)\n",
    "    except OSError:\n",
    "        status = {\"num_frames\": 0, \"update\": 0}\n",
    "    txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "    # Load observations preprocessor\n",
    "\n",
    "    obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "    if \"vocab\" in status:\n",
    "        preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "    txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "    # Reshape reward function\n",
    "    if args.reshape_reward:\n",
    "        def reshape_reward(obs, action, reward, done):\n",
    "            if not done:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = 1\n",
    "            return reward\n",
    "    else:\n",
    "        reshape_reward = None\n",
    "\n",
    "    # Load model\n",
    "\n",
    "    acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "    if \"model_state\" in status:\n",
    "        acmodel.load_state_dict(status[\"model_state\"])\n",
    "    acmodel.to(device)\n",
    "    txt_logger.info(\"Model loaded\\n\")\n",
    "    txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "    # Create hidden policies\n",
    "\n",
    "    acmodels = [acmodel]\n",
    "\n",
    "    # Load algo\n",
    "\n",
    "    if args.algo == \"a2c\":\n",
    "        algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "    elif args.algo == \"ppo\":\n",
    "        algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "                            \n",
    "    else:\n",
    "        raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "    # change to RMSProp optimizer\n",
    "    if args.optimizer == 'rmsprop':\n",
    "        algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "    if \"optimizer_state\" in status:\n",
    "        algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "    txt_logger.info(\"Optimizer loaded\\n\")\n",
    "\n",
    "    # TRAINING LOOP\n",
    "\n",
    "    # Train model\n",
    "\n",
    "    num_frames = status[\"num_frames\"]\n",
    "    update = status[\"update\"]\n",
    "    start_time = time.time()\n",
    "    #nupdates = args.frames // (args.procs * args.frames_per_proc)\n",
    "\n",
    "    # Moving average parameters\n",
    "    threshold = 0.90\n",
    "    window = 10\n",
    "    rreturn_total = 0\n",
    "    i = 0\n",
    "\n",
    "    while num_frames < args.frames:\n",
    "\n",
    "        update_start_time = time.time()\n",
    "\n",
    "        # Evaluate decay lr and cliprange    \n",
    "        # frac = 1.0 - (update - 1.0) / nupdates\n",
    "        # algo.lrs = lrs(frac)\n",
    "        # algo.clipranges = clip_epss(frac)\n",
    "        # algo.kl_betas = None # Clipped-PPO, not full KL\n",
    "\n",
    "        # Collect experiences for cascade policies\n",
    "        exps, logs1 = algo.collect_experiences_cascade()\n",
    "\n",
    "        # Update model parameters\n",
    "        logs2 = algo.update_parameters_cascade(exps)\n",
    "        logs = {**logs1, **logs2}\n",
    "        update_end_time = time.time()\n",
    "\n",
    "        num_frames += logs[\"num_frames\"]\n",
    "        update += 1\n",
    "\n",
    "        # Print logs\n",
    "\n",
    "        if update % args.log_interval == 0:\n",
    "            fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "            duration = int(time.time() - start_time)\n",
    "            return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "            rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "            num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "            # Moving average to break loop if mean reward threshold reached\n",
    "            #rreturn_total +=rreturn_per_episode['mean']\n",
    "            if args.early_stop:\n",
    "                rreturn_total +=return_per_episode['mean']\n",
    "                i+=1\n",
    "                if i >= window:\n",
    "                    rreturn_mavg = rreturn_total / i\n",
    "                    if rreturn_mavg >= threshold:\n",
    "                        break_flag = True \n",
    "                        break\n",
    "                    else:\n",
    "                        i = 0\n",
    "                        rreturn_total = 0\n",
    "\n",
    "            header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "            data = [update, num_frames, fps, duration]\n",
    "            # header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "            # data += rreturn_per_episode.values()\n",
    "            header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()        \n",
    "            header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "            data += num_frames_per_episode.values()\n",
    "            header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "            data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "            txt_logger.info(\n",
    "                \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "                .format(*data))\n",
    "\n",
    "            header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "\n",
    "            if status[\"num_frames\"] == 0:\n",
    "                csv_logger.writerow(header)\n",
    "            csv_logger.writerow(data)\n",
    "            csv_file.flush()\n",
    "\n",
    "            for field, value in zip(header, data):\n",
    "                tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "        # Save status\n",
    "\n",
    "        if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "            status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                      \"model_state\": acmodels[0].state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "            if hasattr(preprocess_obss, \"vocab\"):\n",
    "                status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "            if args.cascade_depth > 1:\n",
    "                status[\"hidden_model_states\"] = [acmodels[k].state_dict() for k in range(1, args.cascade_depth)]\n",
    "            utils.save_status(status, model_dir)\n",
    "            txt_logger.info(\"Status saved\")\n",
    "\n",
    "    print(\"Number of frames: \", num_frames)\n",
    "\n",
    "\n",
    "\n",
    "    # CONTINUE TRAINING 2nd ENVIRONMENT ----------------------\n",
    "\n",
    "    index = 1\n",
    "    env_id = tasks_sequence[index][1]\n",
    "    frames = args.frames + add_frames\n",
    "\n",
    "    ## Hyper-parameters\n",
    "    args.env = env_id\n",
    "    args.frames = int(frames)\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "    txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "    # Load training status\n",
    "\n",
    "    try:\n",
    "        status = utils.get_status(model_dir)\n",
    "    except OSError:\n",
    "        status = {\"num_frames\": 0, \"update\": 0}\n",
    "    txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "    # Load observations preprocessor\n",
    "\n",
    "    obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "    if \"vocab\" in status:\n",
    "        preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "    txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "    # Load model\n",
    "\n",
    "    acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "    if \"model_state\" in status:\n",
    "        acmodel.load_state_dict(status[\"model_state\"])\n",
    "    acmodel.to(device)\n",
    "    txt_logger.info(\"Model loaded\\n\")\n",
    "    txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "\n",
    "    # Load algo\n",
    "\n",
    "    if args.algo == \"a2c\":\n",
    "        algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "    elif args.algo == \"ppo\":\n",
    "        algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)                             \n",
    "    else:\n",
    "        raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "    # change to RMSProp optimizer\n",
    "    if args.optimizer == 'RMSProp':\n",
    "        algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "        \n",
    "    if \"optimizer_state\" in status:\n",
    "        algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "    txt_logger.info(\"Optimizer loaded\\n\")\n",
    "\n",
    "    # Train model\n",
    "\n",
    "    num_frames = status[\"num_frames\"]\n",
    "    update = status[\"update\"]\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    # Moving average parameters\n",
    "    threshold = 0.90\n",
    "    window = 10\n",
    "    rreturn_total = 0\n",
    "    i = 0\n",
    "\n",
    "    while num_frames < args.frames:\n",
    "\n",
    "        update_start_time = time.time()\n",
    "\n",
    "        # Collect experiences for cascade policies\n",
    "        exps, logs1 = algo.collect_experiences_cascade()\n",
    "\n",
    "        # Update model parameters\n",
    "        logs2 = algo.update_parameters_cascade(exps)\n",
    "        logs = {**logs1, **logs2}\n",
    "        update_end_time = time.time()\n",
    "\n",
    "        num_frames += logs[\"num_frames\"]\n",
    "        update += 1\n",
    "\n",
    "        # Print logs\n",
    "\n",
    "        if update % args.log_interval == 0:\n",
    "            fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "            duration = int(time.time() - start_time)\n",
    "            return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "            rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "            num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "            if args.early_stop:\n",
    "                rreturn_total +=return_per_episode['mean']\n",
    "                i+=1\n",
    "                if i >= window:\n",
    "                    rreturn_mavg = rreturn_total / i\n",
    "                    if rreturn_mavg >= threshold:\n",
    "                        break_flag = True \n",
    "                        break\n",
    "                    else:\n",
    "                        i = 0\n",
    "                        rreturn_total = 0\n",
    "\n",
    "            header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "            data = [update, num_frames, fps, duration]\n",
    "            header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "            header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "            data += num_frames_per_episode.values()\n",
    "            header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "            data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "            txt_logger.info(\n",
    "                \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "                .format(*data))\n",
    "\n",
    "            header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "\n",
    "            if status[\"num_frames\"] == 0:\n",
    "                csv_logger.writerow(header)\n",
    "            csv_logger.writerow(data)\n",
    "            csv_file.flush()\n",
    "\n",
    "            for field, value in zip(header, data):\n",
    "                tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "        # Save status\n",
    "\n",
    "        if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "            status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                      \"model_state\": acmodels[0].state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "            if hasattr(preprocess_obss, \"vocab\"):\n",
    "                status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "            if args.cascade_depth > 1:\n",
    "                status[\"hidden_model_states\"] = [acmodels[k].state_dict() for k in range(1, args.cascade_depth)]\n",
    "            utils.save_status(status, model_dir)\n",
    "            txt_logger.info(\"Status saved\")\n",
    "\n",
    "    print(\"Number of frames: \", num_frames)\n",
    "\n",
    "\n",
    "    # CONTINUE TRAINING 3rd ENVIRONMENT ----------------------\n",
    "\n",
    "    index = 2\n",
    "    env_id = tasks_sequence[index][1]\n",
    "    frames = args.frames + add_frames\n",
    "\n",
    "    ## Hyper-parameters\n",
    "    args.env = env_id\n",
    "    args.frames = int(frames)\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "    txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "    # Load training status\n",
    "\n",
    "    try:\n",
    "        status = utils.get_status(model_dir)\n",
    "    except OSError:\n",
    "        status = {\"num_frames\": 0, \"update\": 0}\n",
    "    txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "    # Load observations preprocessor\n",
    "\n",
    "    obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "    if \"vocab\" in status:\n",
    "        preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "    txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "    # Load model\n",
    "\n",
    "    acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "    if \"model_state\" in status:\n",
    "        acmodel.load_state_dict(status[\"model_state\"])\n",
    "    acmodel.to(device)\n",
    "    txt_logger.info(\"Model loaded\\n\")\n",
    "    txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "\n",
    "    # Load algo\n",
    "\n",
    "    if args.algo == \"a2c\":\n",
    "        algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "    elif args.algo == \"ppo\":\n",
    "        algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)                             \n",
    "    else:\n",
    "        raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "    # change to RMSProp optimizer\n",
    "    if args.optimizer == 'RMSProp':\n",
    "        algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "        \n",
    "    if \"optimizer_state\" in status:\n",
    "        algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "    txt_logger.info(\"Optimizer loaded\\n\")\n",
    "\n",
    "    # Train model\n",
    "\n",
    "    num_frames = status[\"num_frames\"]\n",
    "    update = status[\"update\"]\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    # Moving average parameters\n",
    "    threshold = 0.90\n",
    "    window = 10\n",
    "    rreturn_total = 0\n",
    "    i = 0\n",
    "\n",
    "    while num_frames < args.frames:\n",
    "\n",
    "        update_start_time = time.time()\n",
    "\n",
    "        # Collect experiences for cascade policies\n",
    "        exps, logs1 = algo.collect_experiences_cascade()\n",
    "\n",
    "        # Update model parameters\n",
    "        logs2 = algo.update_parameters_cascade(exps)\n",
    "        logs = {**logs1, **logs2}\n",
    "        update_end_time = time.time()\n",
    "\n",
    "        num_frames += logs[\"num_frames\"]\n",
    "        update += 1\n",
    "\n",
    "        # Print logs\n",
    "\n",
    "        if update % args.log_interval == 0:\n",
    "            fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "            duration = int(time.time() - start_time)\n",
    "            return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "            rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "            num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "            if args.early_stop:\n",
    "                rreturn_total +=return_per_episode['mean']\n",
    "                i+=1\n",
    "                if i >= window:\n",
    "                    rreturn_mavg = rreturn_total / i\n",
    "                    if rreturn_mavg >= threshold:\n",
    "                        break_flag = True \n",
    "                        break\n",
    "                    else:\n",
    "                        i = 0\n",
    "                        rreturn_total = 0\n",
    "\n",
    "            header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "            data = [update, num_frames, fps, duration]\n",
    "            header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "            header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "            data += num_frames_per_episode.values()\n",
    "            header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "            data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "            txt_logger.info(\n",
    "                \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "                .format(*data))\n",
    "\n",
    "            header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "\n",
    "            if status[\"num_frames\"] == 0:\n",
    "                csv_logger.writerow(header)\n",
    "            csv_logger.writerow(data)\n",
    "            csv_file.flush()\n",
    "\n",
    "            for field, value in zip(header, data):\n",
    "                tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "        # Save status\n",
    "\n",
    "        if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "            status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                      \"model_state\": acmodels[0].state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "            if hasattr(preprocess_obss, \"vocab\"):\n",
    "                status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "            if args.cascade_depth > 1:\n",
    "                status[\"hidden_model_states\"] = [acmodels[k].state_dict() for k in range(1, args.cascade_depth)]\n",
    "            utils.save_status(status, model_dir)\n",
    "            txt_logger.info(\"Status saved\")\n",
    "\n",
    "    print(\"Number of frames: \", num_frames)\n",
    "\n",
    "    # CONTINUE TRAINING 4th ENVIRONMENT ----------------------\n",
    "\n",
    "    index = 3\n",
    "    env_id = tasks_sequence[index][1]\n",
    "    frames = args.frames + add_frames\n",
    "\n",
    "    ## Hyper-parameters\n",
    "    args.env = env_id\n",
    "    args.frames = int(frames)\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "    txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "    # Load training status\n",
    "\n",
    "    try:\n",
    "        status = utils.get_status(model_dir)\n",
    "    except OSError:\n",
    "        status = {\"num_frames\": 0, \"update\": 0}\n",
    "    txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "    # Load observations preprocessor\n",
    "\n",
    "    obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "    if \"vocab\" in status:\n",
    "        preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "    txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "    # Load model\n",
    "\n",
    "    acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "    if \"model_state\" in status:\n",
    "        acmodel.load_state_dict(status[\"model_state\"])\n",
    "    acmodel.to(device)\n",
    "    txt_logger.info(\"Model loaded\\n\")\n",
    "    txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "\n",
    "    # Load algo\n",
    "\n",
    "    if args.algo == \"a2c\":\n",
    "        algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "    elif args.algo == \"ppo\":\n",
    "        algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)                             \n",
    "    else:\n",
    "        raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "    # change to RMSProp optimizer\n",
    "    if args.optimizer == 'RMSProp':\n",
    "        algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "        \n",
    "    if \"optimizer_state\" in status:\n",
    "        algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "    txt_logger.info(\"Optimizer loaded\\n\")\n",
    "\n",
    "    # Train model\n",
    "\n",
    "    num_frames = status[\"num_frames\"]\n",
    "    update = status[\"update\"]\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    # Moving average parameters\n",
    "    threshold = 0.90\n",
    "    window = 10\n",
    "    rreturn_total = 0\n",
    "    i = 0\n",
    "\n",
    "    while num_frames < args.frames:\n",
    "\n",
    "        update_start_time = time.time()\n",
    "\n",
    "        # Collect experiences for cascade policies\n",
    "        exps, logs1 = algo.collect_experiences_cascade()\n",
    "\n",
    "        # Update model parameters\n",
    "        logs2 = algo.update_parameters_cascade(exps)\n",
    "        logs = {**logs1, **logs2}\n",
    "        update_end_time = time.time()\n",
    "\n",
    "        num_frames += logs[\"num_frames\"]\n",
    "        update += 1\n",
    "\n",
    "        # Print logs\n",
    "\n",
    "        if update % args.log_interval == 0:\n",
    "            fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "            duration = int(time.time() - start_time)\n",
    "            return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "            rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "            num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "            if args.early_stop:\n",
    "                rreturn_total +=return_per_episode['mean']\n",
    "                i+=1\n",
    "                if i >= window:\n",
    "                    rreturn_mavg = rreturn_total / i\n",
    "                    if rreturn_mavg >= threshold:\n",
    "                        break_flag = True \n",
    "                        break\n",
    "                    else:\n",
    "                        i = 0\n",
    "                        rreturn_total = 0\n",
    "\n",
    "            header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "            data = [update, num_frames, fps, duration]\n",
    "            header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "            header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "            data += num_frames_per_episode.values()\n",
    "            header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "            data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "            txt_logger.info(\n",
    "                \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "                .format(*data))\n",
    "\n",
    "            header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "            data += return_per_episode.values()\n",
    "\n",
    "            if status[\"num_frames\"] == 0:\n",
    "                csv_logger.writerow(header)\n",
    "            csv_logger.writerow(data)\n",
    "            csv_file.flush()\n",
    "\n",
    "            for field, value in zip(header, data):\n",
    "                tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "        # Save status\n",
    "\n",
    "        if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "            status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                      \"model_state\": acmodels[0].state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "            if hasattr(preprocess_obss, \"vocab\"):\n",
    "                status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "            if args.cascade_depth > 1:\n",
    "                status[\"hidden_model_states\"] = [acmodels[k].state_dict() for k in range(1, args.cascade_depth)]\n",
    "            utils.save_status(status, model_dir)\n",
    "            txt_logger.info(\"Status saved\")\n",
    "\n",
    "    print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PARAMETERS\n",
    "\n",
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 1\n",
    "# Deterministic actions for evaluation, no exploit, no need of randomness for exploration\n",
    "args.argmax = True \n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "\n",
    "# SET ENVIROMENTS, AGENT AND LOGS. RUN EVALUATION\n",
    "\n",
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [1]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    #model_dir = utils.get_model_dir(args.model)\n",
    "    model_dir = utils.get_model_dir(model_name)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "#print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "#      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.mean(num_frames_tot, axis=0)[0], np.mean(fps_tot, axis=0)[0], np.mean(duration_tot, axis=0)[0], *np.mean(return_per_episode_tot, axis=0), *np.mean(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':True,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "#args.model = 'test_cascade_8_frames_2048_doorkey_wallgap_crossing_clip_impsampling_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 123456\n",
    "args.argmax = True # Deterministic for evaluation\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [123456]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate  2nd environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "\n",
    "#args.model = 'test_cascade_8_frames_2048_doorkey_wallgap_crossing_clip_impsampling_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 123456\n",
    "args.argmax = True # Deterministic for evaluation\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [123456]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate  3rd environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "\n",
    "#args.model = 'test_cascade_8_frames_2048_doorkey_wallgap_crossing_clip_impsampling_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 123456\n",
    "args.argmax = True # Deterministic for evaluation\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [123456]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate  4th environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "\n",
    "#args.model = 'test_cascade_8_frames_2048_doorkey_wallgap_crossing_clip_impsampling_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 123456\n",
    "args.argmax = True # Deterministic for evaluation\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [123456]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "5d2efec84aee61a766032e9dfbe418d90107ced57033c9077d1ba6267f248fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
