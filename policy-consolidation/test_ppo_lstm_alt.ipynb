{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# PPO+LSTM learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "\n",
    "seed = 1\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id_2 = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id_1 = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "model = 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_mid'\n",
    "model = 'test_lstm'\n",
    "processes = 16\n",
    "frames = 1e6\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env1':env_id_1,\n",
    "'env2':env_id_2,\n",
    "'model':model,\n",
    "'interlaced': True,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':False # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 6\n",
    "    args.k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env1': 'MiniGrid-WallGapS6-v0', 'env2': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_lstm', 'interlaced': True, 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 1000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env1}_{args.env2}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (memory_rnn): LSTMCell(64, 64)\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env1, args.seed + 10000 * i))\n",
    "\n",
    "if args.interlaced:\n",
    "    # Create the parallel envs for later episodic alternation\n",
    "    envs1 = make_envs(args.env1, args.procs, args.seed)\n",
    "    envs2 = make_envs(args.env2, args.procs, args.seed)\n",
    "\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (alternate episodes with different environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.85\n",
    "window = 20\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "env_flag = False\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    \n",
    "    # Update model parameters\n",
    "    \n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        \n",
    "        #print environment name under train\n",
    "        print(algo.env.envs[0].spec.id)\n",
    "\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=rreturn_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "        \n",
    "        algo.env = envs1 if env_flag else envs2\n",
    "        env_flag = not(env_flag)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env1': 'MiniGrid-WallGapS6-v0', 'env2': 'MiniGrid-DoorKey-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_mid', 'interlaced': True, 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 1000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True, 'env': 'MiniGrid-DoorKey-6x6-v0', 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id_2 = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id_1 = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = args.env2\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, Run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 7278.0 | FPS 3904 | D 1.0 | R:μσmM 0.81 0.17 0.00 0.96 | F:μσmM 74.8 64.3 16.0 360.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "# print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "#       .format(num_frames, fps, duration,\n",
    "#               *return_per_episode.values(),\n",
    "#               *num_frames_per_episode.values()))\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "# n = args.worst_episodes_to_show\n",
    "# if n > 0:\n",
    "#     print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "#     indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "#     for i in indexes[:n]:\n",
    "#         print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id_2 = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id_1 = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "model = 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end'\n",
    "\n",
    "add_frames = 1e6\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'interlaced': False,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':32, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "# Model Parameters\n",
    "'use_rim':False # action = 'store_true'\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1\n",
    "\n",
    "# RIM specific hyperparameters\n",
    "if args.use_rim:\n",
    "    args.num_units = 6\n",
    "    args.k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-RedBlueDoors-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end', 'interlaced': False, 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 2000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (memory_rnn): LSTMCell(64, 64)\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 471 | F 964608 | FPS 0682 | D 3 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 8.6 22.8 0.0 92.0 | H 1.590 | V 0.462 | pL 0.232 | vL 0.015 | ∇ 0.218\n",
      "U 472 | F 966656 | FPS 0678 | D 6 | rR:μσmM 0.05 0.18 0.00 0.73 | F:μσmM 31.4 62.5 0.0 215.0 | H 1.635 | V 0.285 | pL 0.146 | vL 0.005 | ∇ 0.119\n",
      "U 473 | F 968704 | FPS 0711 | D 8 | rR:μσmM 0.33 0.34 0.00 0.83 | F:μσmM 158.0 124.2 0.0 347.0 | H 1.684 | V 0.243 | pL 0.058 | vL 0.013 | ∇ 0.082\n",
      "U 474 | F 970752 | FPS 0688 | D 11 | rR:μσmM 0.45 0.32 0.00 0.83 | F:μσmM 202.2 140.5 9.0 456.0 | H 1.704 | V 0.166 | pL 0.035 | vL 0.013 | ∇ 0.082\n",
      "U 475 | F 972800 | FPS 0706 | D 14 | rR:μσmM 0.35 0.35 0.00 0.89 | F:μσmM 225.2 238.8 3.0 635.0 | H 1.708 | V 0.156 | pL 0.047 | vL 0.006 | ∇ 0.048\n",
      "U 476 | F 974848 | FPS 0609 | D 18 | rR:μσmM 0.31 0.34 0.00 0.89 | F:μσmM 292.8 276.9 3.0 720.0 | H 1.698 | V 0.135 | pL 0.020 | vL 0.014 | ∇ 0.101\n",
      "U 477 | F 976896 | FPS 0687 | D 21 | rR:μσmM 0.38 0.32 0.00 0.88 | F:μσmM 291.0 230.9 9.0 720.0 | H 1.727 | V 0.147 | pL -0.037 | vL 0.023 | ∇ 0.101\n",
      "U 478 | F 978944 | FPS 0705 | D 24 | rR:μσmM 0.32 0.36 0.00 0.88 | F:μσmM 109.0 109.8 5.0 327.0 | H 1.718 | V 0.173 | pL -0.024 | vL 0.026 | ∇ 0.096\n",
      "U 479 | F 980992 | FPS 0745 | D 26 | rR:μσmM 0.52 0.36 0.00 0.94 | F:μσmM 209.3 189.0 5.0 691.0 | H 1.694 | V 0.195 | pL -0.041 | vL 0.028 | ∇ 0.108\n",
      "U 480 | F 983040 | FPS 0664 | D 29 | rR:μσmM 0.58 0.38 0.00 0.92 | F:μσmM 146.1 151.8 3.0 655.0 | H 1.686 | V 0.256 | pL -0.058 | vL 0.037 | ∇ 0.139\n",
      "Status saved\n",
      "U 481 | F 985088 | FPS 0683 | D 32 | rR:μσmM 0.61 0.38 0.00 0.95 | F:μσmM 109.4 115.0 5.0 499.0 | H 1.649 | V 0.305 | pL -0.048 | vL 0.036 | ∇ 0.138\n",
      "U 482 | F 987136 | FPS 0664 | D 36 | rR:μσmM 0.46 0.41 0.00 0.96 | F:μσmM 127.2 171.4 4.0 653.0 | H 1.682 | V 0.331 | pL -0.003 | vL 0.041 | ∇ 0.142\n",
      "U 483 | F 989184 | FPS 0683 | D 39 | rR:μσmM 0.55 0.42 0.00 0.94 | F:μσmM 77.8 49.1 3.0 151.0 | H 1.655 | V 0.333 | pL -0.034 | vL 0.039 | ∇ 0.148\n",
      "U 484 | F 991232 | FPS 0732 | D 41 | rR:μσmM 0.47 0.44 0.00 0.93 | F:μσmM 62.4 38.2 6.0 142.0 | H 1.636 | V 0.328 | pL 0.047 | vL 0.039 | ∇ 0.164\n",
      "U 485 | F 993280 | FPS 0724 | D 44 | rR:μσmM 0.42 0.41 0.00 0.94 | F:μσmM 96.4 114.6 4.0 408.0 | H 1.630 | V 0.295 | pL -0.002 | vL 0.036 | ∇ 0.137\n",
      "U 486 | F 995328 | FPS 0720 | D 47 | rR:μσmM 0.30 0.39 0.00 0.96 | F:μσmM 101.5 153.4 5.0 587.0 | H 1.615 | V 0.264 | pL 0.037 | vL 0.042 | ∇ 0.143\n",
      "U 487 | F 997376 | FPS 0738 | D 50 | rR:μσmM 0.38 0.44 0.00 0.96 | F:μσmM 63.2 87.6 2.0 378.0 | H 1.617 | V 0.212 | pL 0.024 | vL 0.040 | ∇ 0.123\n",
      "U 488 | F 999424 | FPS 0727 | D 53 | rR:μσmM 0.60 0.40 0.00 0.95 | F:μσmM 85.5 75.2 4.0 280.0 | H 1.600 | V 0.330 | pL -0.095 | vL 0.046 | ∇ 0.160\n",
      "U 489 | F 1001472 | FPS 0736 | D 55 | rR:μσmM 0.35 0.43 0.00 0.96 | F:μσmM 67.9 114.2 1.0 500.0 | H 1.584 | V 0.292 | pL 0.032 | vL 0.048 | ∇ 0.170\n",
      "U 490 | F 1003520 | FPS 0703 | D 58 | rR:μσmM 0.43 0.45 0.00 0.96 | F:μσmM 72.2 126.8 1.0 720.0 | H 1.578 | V 0.325 | pL -0.017 | vL 0.052 | ∇ 0.196\n",
      "Status saved\n",
      "U 491 | F 1005568 | FPS 0766 | D 61 | rR:μσmM 0.51 0.43 0.00 0.98 | F:μσmM 79.0 103.0 5.0 528.0 | H 1.561 | V 0.381 | pL -0.056 | vL 0.063 | ∇ 0.197\n",
      "U 492 | F 1007616 | FPS 0737 | D 64 | rR:μσmM 0.50 0.44 0.00 0.97 | F:μσmM 58.0 59.3 3.0 307.0 | H 1.574 | V 0.433 | pL -0.085 | vL 0.049 | ∇ 0.208\n",
      "U 493 | F 1009664 | FPS 0752 | D 67 | rR:μσmM 0.57 0.44 0.00 0.97 | F:μσmM 55.5 52.5 3.0 241.0 | H 1.545 | V 0.489 | pL -0.037 | vL 0.042 | ∇ 0.189\n",
      "U 494 | F 1011712 | FPS 0739 | D 69 | rR:μσmM 0.62 0.42 0.00 0.97 | F:μσmM 61.4 47.3 4.0 185.0 | H 1.560 | V 0.534 | pL 0.005 | vL 0.039 | ∇ 0.155\n",
      "U 495 | F 1013760 | FPS 0752 | D 72 | rR:μσmM 0.63 0.42 0.00 0.96 | F:μσmM 55.9 42.4 4.0 197.0 | H 1.555 | V 0.514 | pL 0.031 | vL 0.042 | ∇ 0.185\n",
      "U 496 | F 1015808 | FPS 0758 | D 75 | rR:μσmM 0.60 0.43 0.00 0.96 | F:μσmM 62.2 52.8 2.0 244.0 | H 1.538 | V 0.434 | pL -0.014 | vL 0.043 | ∇ 0.171\n",
      "U 497 | F 1017856 | FPS 0739 | D 78 | rR:μσmM 0.58 0.44 0.00 0.98 | F:μσmM 58.1 85.2 4.0 549.0 | H 1.526 | V 0.466 | pL -0.003 | vL 0.045 | ∇ 0.183\n",
      "U 498 | F 1019904 | FPS 0760 | D 80 | rR:μσmM 0.65 0.41 0.00 0.97 | F:μσmM 65.1 67.5 11.0 349.0 | H 1.536 | V 0.485 | pL -0.018 | vL 0.037 | ∇ 0.144\n",
      "U 499 | F 1021952 | FPS 0740 | D 83 | rR:μσmM 0.53 0.44 0.00 0.98 | F:μσmM 59.9 50.2 9.0 246.0 | H 1.519 | V 0.451 | pL -0.013 | vL 0.048 | ∇ 0.217\n",
      "U 500 | F 1024000 | FPS 0743 | D 86 | rR:μσmM 0.55 0.45 0.00 0.97 | F:μσmM 47.4 40.0 5.0 165.0 | H 1.539 | V 0.489 | pL -0.063 | vL 0.038 | ∇ 0.202\n",
      "Status saved\n",
      "U 501 | F 1026048 | FPS 0717 | D 89 | rR:μσmM 0.65 0.41 0.00 0.96 | F:μσmM 67.2 48.4 2.0 201.0 | H 1.545 | V 0.490 | pL 0.038 | vL 0.022 | ∇ 0.125\n",
      "U 502 | F 1028096 | FPS 0746 | D 91 | rR:μσmM 0.46 0.43 0.00 0.97 | F:μσmM 78.5 77.9 3.0 282.0 | H 1.564 | V 0.419 | pL 0.050 | vL 0.046 | ∇ 0.210\n",
      "U 503 | F 1030144 | FPS 0750 | D 94 | rR:μσmM 0.46 0.45 0.00 0.98 | F:μσmM 49.9 48.0 2.0 233.0 | H 1.596 | V 0.450 | pL -0.063 | vL 0.033 | ∇ 0.207\n",
      "U 504 | F 1032192 | FPS 0730 | D 97 | rR:μσmM 0.67 0.41 0.00 0.98 | F:μσmM 49.5 40.0 3.0 206.0 | H 1.545 | V 0.519 | pL -0.077 | vL 0.034 | ∇ 0.163\n",
      "U 505 | F 1034240 | FPS 0758 | D 100 | rR:μσmM 0.62 0.42 0.00 0.96 | F:μσmM 60.0 38.2 9.0 188.0 | H 1.548 | V 0.462 | pL -0.007 | vL 0.031 | ∇ 0.206\n",
      "U 506 | F 1036288 | FPS 0734 | D 102 | rR:μσmM 0.73 0.37 0.00 0.98 | F:μσmM 53.1 37.7 3.0 155.0 | H 1.494 | V 0.603 | pL -0.019 | vL 0.037 | ∇ 0.215\n",
      "U 507 | F 1038336 | FPS 0769 | D 105 | rR:μσmM 0.68 0.41 0.00 0.98 | F:μσmM 47.7 30.5 4.0 122.0 | H 1.470 | V 0.617 | pL -0.002 | vL 0.035 | ∇ 0.170\n",
      "U 508 | F 1040384 | FPS 0750 | D 108 | rR:μσmM 0.54 0.47 0.00 0.98 | F:μσmM 32.8 23.2 2.0 145.0 | H 1.447 | V 0.580 | pL 0.093 | vL 0.063 | ∇ 0.221\n",
      "U 509 | F 1042432 | FPS 0739 | D 111 | rR:μσmM 0.63 0.44 0.00 0.98 | F:μσmM 40.3 31.1 3.0 171.0 | H 1.413 | V 0.578 | pL 0.042 | vL 0.035 | ∇ 0.161\n",
      "U 510 | F 1044480 | FPS 0744 | D 113 | rR:μσmM 0.65 0.43 0.00 0.97 | F:μσmM 44.9 37.8 4.0 215.0 | H 1.440 | V 0.616 | pL 0.020 | vL 0.038 | ∇ 0.186\n",
      "Status saved\n",
      "U 511 | F 1046528 | FPS 0729 | D 116 | rR:μσmM 0.66 0.43 0.00 0.98 | F:μσmM 43.4 35.1 1.0 174.0 | H 1.431 | V 0.583 | pL -0.041 | vL 0.031 | ∇ 0.157\n",
      "U 512 | F 1048576 | FPS 0666 | D 119 | rR:μσmM 0.72 0.39 0.00 0.98 | F:μσmM 45.7 36.0 3.0 176.0 | H 1.423 | V 0.560 | pL 0.027 | vL 0.030 | ∇ 0.177\n",
      "U 513 | F 1050624 | FPS 0691 | D 122 | rR:μσmM 0.61 0.45 0.00 0.98 | F:μσmM 38.8 34.2 1.0 176.0 | H 1.363 | V 0.614 | pL -0.086 | vL 0.035 | ∇ 0.204\n",
      "U 514 | F 1052672 | FPS 0705 | D 125 | rR:μσmM 0.66 0.43 0.00 0.98 | F:μσmM 37.7 18.9 2.0 97.0 | H 1.391 | V 0.645 | pL 0.005 | vL 0.024 | ∇ 0.179\n",
      "U 515 | F 1054720 | FPS 0713 | D 128 | rR:μσmM 0.76 0.37 0.00 0.98 | F:μσmM 44.4 29.5 2.0 141.0 | H 1.390 | V 0.642 | pL 0.009 | vL 0.024 | ∇ 0.139\n",
      "U 516 | F 1056768 | FPS 0750 | D 131 | rR:μσmM 0.72 0.38 0.00 0.98 | F:μσmM 54.6 42.4 1.0 169.0 | H 1.473 | V 0.606 | pL 0.011 | vL 0.027 | ∇ 0.148\n",
      "U 517 | F 1058816 | FPS 0753 | D 134 | rR:μσmM 0.78 0.34 0.00 0.98 | F:μσmM 56.6 37.2 3.0 194.0 | H 1.448 | V 0.593 | pL 0.025 | vL 0.028 | ∇ 0.173\n",
      "U 518 | F 1060864 | FPS 0757 | D 136 | rR:μσmM 0.62 0.44 0.00 0.98 | F:μσmM 42.3 37.0 3.0 216.0 | H 1.436 | V 0.595 | pL 0.041 | vL 0.032 | ∇ 0.146\n",
      "U 519 | F 1062912 | FPS 0737 | D 139 | rR:μσmM 0.78 0.35 0.00 0.99 | F:μσmM 44.5 29.1 6.0 119.0 | H 1.443 | V 0.594 | pL -0.002 | vL 0.033 | ∇ 0.169\n",
      "U 520 | F 1064960 | FPS 0762 | D 142 | rR:μσmM 0.72 0.38 0.00 0.98 | F:μσmM 55.9 44.2 1.0 230.0 | H 1.425 | V 0.547 | pL 0.003 | vL 0.033 | ∇ 0.184\n",
      "Status saved\n",
      "U 521 | F 1067008 | FPS 0740 | D 145 | rR:μσmM 0.70 0.39 0.00 0.98 | F:μσmM 54.0 49.5 3.0 232.0 | H 1.381 | V 0.611 | pL -0.022 | vL 0.032 | ∇ 0.179\n",
      "U 522 | F 1069056 | FPS 0746 | D 147 | rR:μσmM 0.80 0.33 0.00 0.98 | F:μσmM 46.8 27.9 2.0 133.0 | H 1.378 | V 0.656 | pL -0.026 | vL 0.020 | ∇ 0.135\n",
      "U 523 | F 1071104 | FPS 0677 | D 150 | rR:μσmM 0.71 0.40 0.00 0.97 | F:μσmM 42.7 26.7 2.0 116.0 | H 1.409 | V 0.652 | pL 0.005 | vL 0.024 | ∇ 0.128\n",
      "U 524 | F 1073152 | FPS 0714 | D 153 | rR:μσmM 0.81 0.33 0.00 0.98 | F:μσmM 47.0 25.7 7.0 153.0 | H 1.392 | V 0.653 | pL 0.005 | vL 0.023 | ∇ 0.150\n",
      "U 525 | F 1075200 | FPS 0737 | D 156 | rR:μσmM 0.84 0.29 0.00 0.97 | F:μσmM 46.2 27.9 3.0 143.0 | H 1.411 | V 0.668 | pL 0.038 | vL 0.023 | ∇ 0.127\n",
      "U 526 | F 1077248 | FPS 0751 | D 159 | rR:μσmM 0.87 0.21 0.00 0.97 | F:μσmM 63.1 45.1 12.0 192.0 | H 1.396 | V 0.656 | pL 0.031 | vL 0.021 | ∇ 0.127\n",
      "U 527 | F 1079296 | FPS 0759 | D 161 | rR:μσmM 0.83 0.30 0.00 0.98 | F:μσmM 45.5 27.8 11.0 135.0 | H 1.443 | V 0.618 | pL 0.003 | vL 0.026 | ∇ 0.172\n",
      "U 528 | F 1081344 | FPS 0753 | D 164 | rR:μσmM 0.82 0.31 0.00 0.98 | F:μσmM 46.5 33.1 4.0 212.0 | H 1.448 | V 0.621 | pL -0.053 | vL 0.020 | ∇ 0.130\n",
      "U 529 | F 1083392 | FPS 0758 | D 167 | rR:μσmM 0.92 0.14 0.00 0.98 | F:μσmM 46.8 22.0 4.0 112.0 | H 1.409 | V 0.710 | pL -0.012 | vL 0.012 | ∇ 0.105\n",
      "U 530 | F 1085440 | FPS 0722 | D 170 | rR:μσmM 0.91 0.16 0.00 0.98 | F:μσmM 48.9 57.4 3.0 387.0 | H 1.389 | V 0.696 | pL 0.022 | vL 0.018 | ∇ 0.149\n",
      "Status saved\n",
      "U 531 | F 1087488 | FPS 0734 | D 173 | rR:μσmM 0.94 0.04 0.73 0.98 | F:μσmM 52.0 35.0 17.0 213.0 | H 1.414 | V 0.636 | pL 0.029 | vL 0.018 | ∇ 0.133\n",
      "U 532 | F 1089536 | FPS 0717 | D 175 | rR:μσmM 0.88 0.19 0.00 0.97 | F:μσmM 65.7 67.9 14.0 368.0 | H 1.443 | V 0.546 | pL 0.042 | vL 0.023 | ∇ 0.155\n",
      "U 533 | F 1091584 | FPS 0645 | D 179 | rR:μσmM 0.85 0.23 0.00 0.97 | F:μσmM 73.6 61.5 11.0 263.0 | H 1.390 | V 0.629 | pL -0.023 | vL 0.020 | ∇ 0.116\n",
      "U 534 | F 1093632 | FPS 0675 | D 182 | rR:μσmM 0.85 0.27 0.00 0.97 | F:μσmM 50.9 25.9 9.0 115.0 | H 1.430 | V 0.647 | pL -0.035 | vL 0.021 | ∇ 0.134\n",
      "U 535 | F 1095680 | FPS 0682 | D 185 | rR:μσmM 0.91 0.15 0.00 0.98 | F:μσmM 52.3 27.3 2.0 145.0 | H 1.365 | V 0.706 | pL -0.012 | vL 0.011 | ∇ 0.093\n",
      "U 536 | F 1097728 | FPS 0719 | D 188 | rR:μσmM 0.88 0.26 0.00 0.98 | F:μσmM 37.2 17.4 5.0 104.0 | H 1.358 | V 0.708 | pL -0.008 | vL 0.017 | ∇ 0.125\n",
      "U 537 | F 1099776 | FPS 0682 | D 191 | rR:μσmM 0.89 0.20 0.00 0.97 | F:μσmM 52.0 26.7 9.0 126.0 | H 1.366 | V 0.677 | pL 0.012 | vL 0.017 | ∇ 0.107\n",
      "U 538 | F 1101824 | FPS 0673 | D 194 | rR:μσmM 0.78 0.36 0.00 0.98 | F:μσmM 36.3 18.6 2.0 99.0 | H 1.359 | V 0.686 | pL 0.008 | vL 0.046 | ∇ 0.226\n",
      "U 539 | F 1103872 | FPS 0661 | D 197 | rR:μσmM 0.95 0.03 0.86 0.98 | F:μσmM 43.4 22.9 19.0 109.0 | H 1.382 | V 0.661 | pL 0.025 | vL 0.022 | ∇ 0.152\n",
      "Number of frames:  1105920\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.85\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=rreturn_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "                print(\"Number of frames: \", num_frames)\n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        data += rreturn_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-RedBlueDoors-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end', 'interlaced': False, 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 2000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id_2 = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id_1 = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "args.env = env_id\n",
    "#args.model = 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, Run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-RedBlueDoors-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 5006.0 | FPS 4192 | D 1.0 | R:μσmM 0.91 0.17 0.00 0.98 | F:μσmM 55.7 34.5 1.0 241.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "# print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "#       .format(num_frames, fps, duration,\n",
    "#               *return_per_episode.values(),\n",
    "#               *num_frames_per_episode.values()))\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "# n = args.worst_episodes_to_show\n",
    "# if n > 0:\n",
    "#     print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "#     indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "#     for i in indexes[:n]:\n",
    "#         print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate previous environments and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end', 'interlaced': False, 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 2000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = 10\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, Run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 2579.0 | FPS 2374 | D 1.0 | R:μσmM 0.84 0.10 0.37 0.98 | F:μσmM 26.4 15.3 4.0 101.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "# print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "#       .format(num_frames, fps, duration,\n",
    "#               *return_per_episode.values(),\n",
    "#               *num_frames_per_episode.values()))\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "# n = args.worst_episodes_to_show\n",
    "# if n > 0:\n",
    "#     print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "#     indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "#     for i in indexes[:n]:\n",
    "#         print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters env 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'MiniGrid-WallGapS6-v0_alt_MiniGrid-DoorKey-6x6-v0_PPO_lstm_proc_16_RMSProp_lr_7e4_gae_099_nxt_MiniGrid-RedBlueDoors-6x6-v0_end', 'interlaced': False, 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 2000000.0, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 32, 'text': False, 'use_rim': False, 'mem': True, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': 10}\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, Run agent and print results for env 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 24117.0 | FPS 3312 | D 7.0 | R:μσmM 0.39 0.32 0.00 0.91 | F:μσmM 228.9 116.0 35.0 360.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax, num_envs=args.procs, use_memory=args.mem, use_rim=args.use_rim)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "# print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "#       .format(num_frames, fps, duration,\n",
    "#               *return_per_episode.values(),\n",
    "#               *num_frames_per_episode.values()))\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "\n",
    "# n = args.worst_episodes_to_show\n",
    "# if n > 0:\n",
    "#     print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "#     indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "#     for i in indexes[:n]:\n",
    "#         print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-rims",
   "language": "python",
   "name": "tfm-rims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
