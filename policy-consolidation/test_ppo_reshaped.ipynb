{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNF5-qJ7B0Q3"
   },
   "source": [
    "# MiniGrid settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdM2FnEJB0Q8"
   },
   "source": [
    "## Basic Jupyter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1647123362972,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "aycUmr6OB0Q8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef0DdE0b4pLd"
   },
   "source": [
    "## Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLM4YYcL5rBt"
   },
   "source": [
    "Import libraries and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YgenDMtf4pLe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inigo/.local/share/virtualenvs/tfm-experiments-K5nk3NK1/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import base64\n",
    "# import stable_baselines3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint \n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28U_WEp25rBu"
   },
   "source": [
    "Define the video function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d7eCH8Kf4pLf"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from IPython import display \n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "        \n",
    "def show_animation(experiment):\n",
    "    giflist = glob.glob('animation/*.gif')\n",
    "    if len(giflist) > 0:\n",
    "        matching = [s for s in giflist if experiment in s]\n",
    "        gif_path = matching[0]\n",
    "        b64 = base64.b64encode(open(gif_path,'rb').read()).decode('ascii')\n",
    "        display.display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" height=\"400\" />'))\n",
    "    else:\n",
    "        print(\"Could not find animation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KchGuXpd5rBv"
   },
   "source": [
    "Define the rendering wrappers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gdhk3Oep4pLf"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "\n",
    "# Define wrapper for CNN Policy\n",
    "def ImgRGBImgPartialObsWrapper(env):\n",
    "    return ImgObsWrapper(RGBImgPartialObsWrapper(env))\n",
    "\n",
    "# Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, './video', force=True)\n",
    "    return env\n",
    "\n",
    "def gen_wrapped_env(env_name):\n",
    "    return wrap_env(FlatObsWrapper(gym.make(env_name)))\n",
    "\n",
    "def gen_wrapped_env_cnn(env_name):\n",
    "    return wrap_env(ImgObsWrapper(RGBImgPartialObsWrapper(gym.make(env_name))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render an environment image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1647083269049,
     "user": {
      "displayName": "Iñigo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14378798962183195551"
     },
     "user_tz": -60
    },
    "id": "B21JwGYn5rBv",
    "outputId": "54dfa526-2621-4f91-df2b-e4ff7a447aad"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-Empty-16x16-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'BreakoutNoFrameskip-v4'\n",
    "#env_id = 'MiniGrid-DistShift1-v0'\n",
    "#env_id ='MiniGrid-UnlockPickup-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "eval_env = gym.make(env_id)\n",
    "eval_env.seed(10000+randint(0, 10))\n",
    "eval_env.reset()\n",
    "#random_action = eval_env.action_space.sample()\n",
    "#new_obs, reward, done, info = eval_env.step(random_action)\n",
    "\n",
    "before_img = eval_env.render('rgb_array')\n",
    "\n",
    "plt.figure(figsize = (4.,4.))\n",
    "plt.imshow(before_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umY09KJP5rCI"
   },
   "source": [
    "# Standard PPO learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPq1XkeL5rCI"
   },
   "source": [
    "## Define the environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "import datetime\n",
    "import torch\n",
    "import torch_ac\n",
    "import tensorboardX\n",
    "import sys\n",
    "import utils\n",
    "from model import ACModel\n",
    "from torch_ac.utils import DictList, ParallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.wrappers import Monitor\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import FlatObsWrapper, ImgObsWrapper, RGBImgPartialObsWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_envs(env_id, procs, seed=None):\n",
    "    envs = []\n",
    "    for i in range(procs):\n",
    "        if seed:\n",
    "            e = utils.make_env(env_id, seed + 10000 * i)\n",
    "        else:\n",
    "            e = utils.make_env(env_id)\n",
    "        envs.append(e)\n",
    "    env = ParallelEnv(envs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Parallel environment snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "procs = 16\n",
    "max_tasks = 20\n",
    "seed_list = range(procs * max_tasks, (procs + 1) * max_tasks)\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N1-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS9N3-v0'\n",
    "#env_id = 'MiniGrid-SimpleCrossingS11N5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-LavaCrossingS9N2-v0'\n",
    "\n",
    "seed = 1\n",
    "env = make_envs(env_id, procs, seed)\n",
    "obs = env.reset()\n",
    "\n",
    "im_list = []\n",
    "for e in env.envs:\n",
    "    #print(type(e.render('rgb_array')))\n",
    "    #e.reset()\n",
    "    im_list.append(e.render('rgb_array'))\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, im_list):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "#model = 'MiniGrid-WallGapS6-v0_PPO_frames_600k_proc_16_RMSProp_lr_7e4_gae_099_test_MiniGrid-DoorKey-6x6-v0'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "processes = 16\n",
    "frames = 300000\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set run dir\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environments, model, algo and prepare training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space=obs_space, action_space=envs[0].action_space, use_memory=args.mem, use_text=args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1 | F 002048 | FPS 2774 | D 0 | rR:μσmM 0.11 0.23 0.00 0.75 | F:μσmM 13.2 29.1 0.0 94.0 | H 1.912 | V -0.071 | pL -0.089 | vL 0.016 | ∇ 0.056\n",
      "U 2 | F 004096 | FPS 2965 | D 1 | rR:μσmM 0.01 0.03 0.00 0.14 | F:μσmM 143.6 1.7 137.0 144.0 | H 1.925 | V -0.026 | pL -0.024 | vL 0.000 | ∇ 0.008\n",
      "U 3 | F 006144 | FPS 2745 | D 2 | rR:μσmM 0.07 0.19 0.00 0.61 | F:μσmM 135.2 25.0 62.0 144.0 | H 1.915 | V 0.008 | pL -0.035 | vL 0.008 | ∇ 0.026\n",
      "U 4 | F 008192 | FPS 2979 | D 2 | rR:μσmM 0.07 0.19 0.00 0.71 | F:μσmM 135.0 25.5 46.0 144.0 | H 1.927 | V 0.022 | pL -0.011 | vL 0.006 | ∇ 0.049\n",
      "U 5 | F 010240 | FPS 2492 | D 3 | rR:μσmM 0.09 0.23 0.00 0.77 | F:μσmM 131.9 31.8 37.0 144.0 | H 1.927 | V 0.031 | pL -0.016 | vL 0.008 | ∇ 0.040\n",
      "U 6 | F 012288 | FPS 2590 | D 4 | rR:μσmM 0.16 0.26 0.00 0.72 | F:μσmM 122.8 34.4 45.0 144.0 | H 1.918 | V 0.039 | pL -0.035 | vL 0.012 | ∇ 0.094\n",
      "U 7 | F 014336 | FPS 2757 | D 5 | rR:μσmM 0.21 0.32 0.00 0.84 | F:μσmM 115.8 44.6 26.0 144.0 | H 1.902 | V 0.072 | pL -0.022 | vL 0.019 | ∇ 0.089\n",
      "U 8 | F 016384 | FPS 3037 | D 5 | rR:μσmM 0.28 0.30 0.00 0.95 | F:μσmM 107.3 41.1 8.0 144.0 | H 1.899 | V 0.099 | pL -0.023 | vL 0.012 | ∇ 0.060\n",
      "U 9 | F 018432 | FPS 2997 | D 6 | rR:μσmM 0.14 0.24 0.00 0.84 | F:μσmM 126.9 32.4 26.0 144.0 | H 1.893 | V 0.083 | pL 0.022 | vL 0.009 | ∇ 0.080\n",
      "U 10 | F 020480 | FPS 3119 | D 7 | rR:μσmM 0.26 0.34 0.00 0.84 | F:μσmM 108.6 47.5 26.0 144.0 | H 1.883 | V 0.075 | pL -0.008 | vL 0.012 | ∇ 0.070\n",
      "Status saved\n",
      "U 11 | F 022528 | FPS 3097 | D 7 | rR:μσmM 0.45 0.36 0.00 0.94 | F:μσmM 83.8 52.7 10.0 144.0 | H 1.872 | V 0.165 | pL -0.074 | vL 0.024 | ∇ 0.093\n",
      "U 12 | F 024576 | FPS 2961 | D 8 | rR:μσmM 0.48 0.35 0.00 0.94 | F:μσmM 78.2 50.2 10.0 144.0 | H 1.845 | V 0.187 | pL -0.040 | vL 0.021 | ∇ 0.074\n",
      "U 13 | F 026624 | FPS 3048 | D 9 | rR:μσmM 0.39 0.34 0.00 0.99 | F:μσmM 92.6 48.3 2.0 144.0 | H 1.799 | V 0.205 | pL 0.022 | vL 0.021 | ∇ 0.101\n",
      "U 14 | F 028672 | FPS 2829 | D 10 | rR:μσmM 0.37 0.36 0.00 0.98 | F:μσmM 94.6 50.1 4.0 144.0 | H 1.861 | V 0.164 | pL 0.018 | vL 0.018 | ∇ 0.082\n",
      "U 15 | F 030720 | FPS 3022 | D 10 | rR:μσmM 0.46 0.34 0.00 0.94 | F:μσmM 83.2 48.9 10.0 144.0 | H 1.821 | V 0.221 | pL -0.022 | vL 0.025 | ∇ 0.118\n",
      "U 16 | F 032768 | FPS 3057 | D 11 | rR:μσmM 0.40 0.34 0.00 0.91 | F:μσmM 90.1 47.5 14.0 144.0 | H 1.831 | V 0.230 | pL 0.017 | vL 0.018 | ∇ 0.099\n",
      "U 17 | F 034816 | FPS 3035 | D 12 | rR:μσmM 0.57 0.29 0.00 0.93 | F:μσmM 66.5 42.1 12.0 144.0 | H 1.800 | V 0.296 | pL -0.073 | vL 0.032 | ∇ 0.129\n",
      "U 18 | F 036864 | FPS 3104 | D 12 | rR:μσmM 0.51 0.30 0.00 0.84 | F:μσmM 75.8 42.5 26.0 144.0 | H 1.790 | V 0.304 | pL -0.009 | vL 0.030 | ∇ 0.100\n",
      "U 19 | F 038912 | FPS 3149 | D 13 | rR:μσmM 0.59 0.26 0.00 0.95 | F:μσmM 64.5 39.6 8.0 144.0 | H 1.771 | V 0.320 | pL -0.032 | vL 0.027 | ∇ 0.166\n",
      "U 20 | F 040960 | FPS 3102 | D 14 | rR:μσmM 0.59 0.31 0.00 0.96 | F:μσmM 62.8 45.5 7.0 144.0 | H 1.769 | V 0.350 | pL 0.009 | vL 0.027 | ∇ 0.126\n",
      "Status saved\n",
      "U 21 | F 043008 | FPS 3083 | D 14 | rR:μσmM 0.68 0.28 0.00 0.98 | F:μσmM 48.9 41.1 4.0 144.0 | H 1.727 | V 0.369 | pL -0.032 | vL 0.033 | ∇ 0.168\n",
      "U 22 | F 045056 | FPS 3046 | D 15 | rR:μσmM 0.63 0.32 0.00 0.97 | F:μσmM 56.5 46.9 5.0 144.0 | H 1.731 | V 0.378 | pL -0.015 | vL 0.036 | ∇ 0.192\n",
      "U 23 | F 047104 | FPS 2990 | D 16 | rR:μσmM 0.70 0.23 0.00 0.96 | F:μσmM 47.7 35.0 6.0 144.0 | H 1.709 | V 0.452 | pL -0.044 | vL 0.028 | ∇ 0.113\n",
      "U 24 | F 049152 | FPS 2953 | D 16 | rR:μσmM 0.72 0.23 0.00 0.99 | F:μσmM 44.7 35.2 2.0 144.0 | H 1.659 | V 0.491 | pL 0.018 | vL 0.026 | ∇ 0.131\n",
      "U 25 | F 051200 | FPS 3035 | D 17 | rR:μσmM 0.74 0.22 0.00 0.96 | F:μσmM 40.2 32.7 6.0 144.0 | H 1.689 | V 0.495 | pL 0.013 | vL 0.026 | ∇ 0.156\n",
      "U 26 | F 053248 | FPS 2750 | D 18 | rR:μσmM 0.75 0.21 0.00 0.98 | F:μσmM 40.4 33.1 3.0 144.0 | H 1.657 | V 0.515 | pL -0.005 | vL 0.026 | ∇ 0.161\n",
      "U 27 | F 055296 | FPS 2997 | D 18 | rR:μσmM 0.76 0.19 0.29 0.98 | F:μσmM 38.3 30.5 4.0 114.0 | H 1.624 | V 0.532 | pL -0.011 | vL 0.025 | ∇ 0.172\n",
      "U 28 | F 057344 | FPS 3039 | D 19 | rR:μσmM 0.82 0.14 0.35 0.97 | F:μσmM 28.8 21.7 5.0 104.0 | H 1.555 | V 0.618 | pL -0.109 | vL 0.018 | ∇ 0.167\n",
      "U 29 | F 059392 | FPS 3058 | D 20 | rR:μσmM 0.83 0.11 0.54 0.97 | F:μσmM 26.8 18.2 5.0 74.0 | H 1.492 | V 0.620 | pL -0.064 | vL 0.017 | ∇ 0.135\n",
      "U 30 | F 061440 | FPS 3033 | D 20 | rR:μσmM 0.84 0.11 0.42 0.98 | F:μσmM 25.4 18.4 4.0 93.0 | H 1.498 | V 0.664 | pL -0.021 | vL 0.015 | ∇ 0.142\n",
      "Status saved\n",
      "U 31 | F 063488 | FPS 2974 | D 21 | rR:μσmM 0.83 0.13 0.37 0.98 | F:μσmM 27.8 20.0 4.0 101.0 | H 1.504 | V 0.657 | pL 0.020 | vL 0.014 | ∇ 0.136\n",
      "U 32 | F 065536 | FPS 2958 | D 22 | rR:μσmM 0.84 0.10 0.51 0.98 | F:μσmM 25.2 16.8 3.0 78.0 | H 1.479 | V 0.671 | pL -0.056 | vL 0.014 | ∇ 0.199\n",
      "U 33 | F 067584 | FPS 2988 | D 23 | rR:μσmM 0.87 0.08 0.68 0.98 | F:μσmM 21.4 12.5 4.0 52.0 | H 1.405 | V 0.731 | pL -0.001 | vL 0.009 | ∇ 0.139\n",
      "U 34 | F 069632 | FPS 2969 | D 23 | rR:μσmM 0.87 0.08 0.56 0.98 | F:μσmM 21.2 12.8 3.0 70.0 | H 1.409 | V 0.729 | pL -0.029 | vL 0.009 | ∇ 0.112\n",
      "U 35 | F 071680 | FPS 2971 | D 24 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.6 3.0 75.0 | H 1.366 | V 0.750 | pL -0.015 | vL 0.011 | ∇ 0.174\n",
      "U 36 | F 073728 | FPS 2963 | D 25 | rR:μσmM 0.88 0.07 0.49 0.98 | F:μσmM 19.0 12.0 3.0 81.0 | H 1.339 | V 0.765 | pL -0.004 | vL 0.008 | ∇ 0.096\n",
      "U 37 | F 075776 | FPS 2974 | D 25 | rR:μσmM 0.89 0.07 0.53 0.98 | F:μσmM 17.9 11.7 3.0 75.0 | H 1.334 | V 0.760 | pL 0.018 | vL 0.010 | ∇ 0.161\n",
      "U 38 | F 077824 | FPS 2950 | D 26 | rR:μσmM 0.88 0.06 0.66 0.98 | F:μσmM 19.1 10.2 3.0 55.0 | H 1.411 | V 0.771 | pL 0.031 | vL 0.005 | ∇ 0.100\n",
      "U 39 | F 079872 | FPS 2946 | D 27 | rR:μσmM 0.89 0.06 0.68 0.98 | F:μσmM 16.9 9.6 3.0 51.0 | H 1.323 | V 0.783 | pL -0.025 | vL 0.011 | ∇ 0.202\n",
      "U 40 | F 081920 | FPS 2951 | D 27 | rR:μσmM 0.89 0.05 0.68 0.98 | F:μσmM 17.8 8.6 3.0 51.0 | H 1.339 | V 0.780 | pL -0.009 | vL 0.006 | ∇ 0.118\n",
      "Status saved\n",
      "U 41 | F 083968 | FPS 2919 | D 28 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.5 4.0 45.0 | H 1.274 | V 0.792 | pL -0.047 | vL 0.005 | ∇ 0.114\n",
      "U 42 | F 086016 | FPS 2822 | D 29 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.1 5.8 3.0 34.0 | H 1.206 | V 0.823 | pL -0.061 | vL 0.003 | ∇ 0.098\n",
      "U 43 | F 088064 | FPS 2860 | D 30 | rR:μσmM 0.91 0.04 0.73 0.98 | F:μσmM 13.8 6.5 3.0 43.0 | H 1.260 | V 0.837 | pL 0.021 | vL 0.003 | ∇ 0.097\n",
      "U 44 | F 090112 | FPS 2891 | D 30 | rR:μσmM 0.89 0.06 0.74 0.98 | F:μσmM 17.4 9.3 3.0 42.0 | H 1.367 | V 0.781 | pL 0.048 | vL 0.004 | ∇ 0.094\n",
      "U 45 | F 092160 | FPS 2870 | D 31 | rR:μσmM 0.89 0.05 0.72 0.98 | F:μσmM 16.9 8.0 3.0 45.0 | H 1.378 | V 0.805 | pL 0.018 | vL 0.003 | ∇ 0.062\n",
      "U 46 | F 094208 | FPS 2800 | D 32 | rR:μσmM 0.89 0.06 0.66 0.98 | F:μσmM 16.9 9.2 3.0 55.0 | H 1.358 | V 0.787 | pL 0.014 | vL 0.009 | ∇ 0.182\n",
      "U 47 | F 096256 | FPS 2859 | D 32 | rR:μσmM 0.90 0.06 0.41 0.98 | F:μσmM 16.5 10.0 4.0 95.0 | H 1.372 | V 0.805 | pL 0.038 | vL 0.006 | ∇ 0.084\n",
      "U 48 | F 098304 | FPS 2851 | D 33 | rR:μσmM 0.88 0.07 0.68 0.98 | F:μσmM 19.8 10.9 4.0 52.0 | H 1.365 | V 0.752 | pL 0.019 | vL 0.006 | ∇ 0.097\n",
      "U 49 | F 100352 | FPS 2763 | D 34 | rR:μσmM 0.89 0.06 0.68 0.96 | F:μσmM 17.6 9.5 6.0 52.0 | H 1.262 | V 0.775 | pL -0.033 | vL 0.005 | ∇ 0.077\n",
      "U 50 | F 102400 | FPS 2160 | D 35 | rR:μσmM 0.89 0.06 0.68 0.99 | F:μσmM 17.3 9.3 2.0 51.0 | H 1.256 | V 0.784 | pL -0.025 | vL 0.005 | ∇ 0.094\n",
      "Status saved\n",
      "U 51 | F 104448 | FPS 2859 | D 36 | rR:μσmM 0.90 0.05 0.75 0.97 | F:μσmM 16.1 7.5 5.0 40.0 | H 1.230 | V 0.798 | pL -0.059 | vL 0.004 | ∇ 0.092\n",
      "U 52 | F 106496 | FPS 2374 | D 36 | rR:μσmM 0.90 0.04 0.77 0.98 | F:μσmM 15.3 6.2 4.0 37.0 | H 1.217 | V 0.823 | pL -0.027 | vL 0.003 | ∇ 0.072\n",
      "U 53 | F 108544 | FPS 2459 | D 37 | rR:μσmM 0.91 0.04 0.71 0.98 | F:μσmM 14.0 6.7 3.0 46.0 | H 1.177 | V 0.821 | pL -0.046 | vL 0.004 | ∇ 0.099\n",
      "U 54 | F 110592 | FPS 2523 | D 38 | rR:μσmM 0.92 0.03 0.78 0.98 | F:μσmM 12.2 5.4 3.0 35.0 | H 1.055 | V 0.846 | pL -0.067 | vL 0.002 | ∇ 0.097\n",
      "U 55 | F 112640 | FPS 2833 | D 39 | rR:μσmM 0.92 0.03 0.79 0.99 | F:μσmM 13.0 5.5 2.0 33.0 | H 1.118 | V 0.840 | pL -0.019 | vL 0.002 | ∇ 0.066\n",
      "U 56 | F 114688 | FPS 2722 | D 40 | rR:μσmM 0.92 0.03 0.79 0.98 | F:μσmM 13.0 5.1 3.0 34.0 | H 1.238 | V 0.853 | pL 0.035 | vL 0.002 | ∇ 0.055\n",
      "U 57 | F 116736 | FPS 2881 | D 40 | rR:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 13.9 6.2 3.0 35.0 | H 1.268 | V 0.831 | pL -0.000 | vL 0.004 | ∇ 0.115\n",
      "U 58 | F 118784 | FPS 2865 | D 41 | rR:μσmM 0.91 0.04 0.79 0.98 | F:μσmM 14.9 6.7 3.0 34.0 | H 1.333 | V 0.822 | pL 0.045 | vL 0.003 | ∇ 0.066\n",
      "U 59 | F 120832 | FPS 2896 | D 42 | rR:μσmM 0.90 0.05 0.68 0.98 | F:μσmM 16.5 8.6 3.0 51.0 | H 1.295 | V 0.802 | pL 0.011 | vL 0.005 | ∇ 0.106\n",
      "Number of frames:  122880\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 300000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_ac.utils.penv import ParallelEnv\n",
    "\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 1439.0 | FPS 3977 | D 0.0 | R:μσmM 0.91 0.04 0.78 0.98 | F:μσmM 14.4 6.3 3.0 35.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array2gif\n",
    "from pathlib import Path\n",
    "import numpy\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'env':args.env,\n",
    "'model':args.model,\n",
    "'seed':15,\n",
    "'shift':0,\n",
    "'argmax':False,\n",
    "'pause':0.1,\n",
    "'gif':args.model,\n",
    "'episodes':5,\n",
    "# Model Parameters\n",
    "'use_rim':args.use_rim,\n",
    "'num_units':args.num_units,\n",
    "'k':args.k\n",
    "}\n",
    "\n",
    "args = DictList(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment, agent and logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "# Load environment\n",
    "\n",
    "env = utils.make_env(args.env, args.seed)\n",
    "for _ in range(args.shift):\n",
    "    env.reset()\n",
    "print(\"Environment loaded\\n\")\n",
    "\n",
    "# Load agent\n",
    "\n",
    "model_dir = utils.get_model_dir(args.model)\n",
    "agent = utils.Agent(env.observation_space, env.action_space, model_dir, device, args.argmax, use_rim = args.use_rim, num_units = args.num_units, k = args.k)\n",
    "\n",
    "print(\"Agent loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the agent\n",
    "\n",
    "if args.gif:\n",
    "   from array2gif import write_gif\n",
    "   frames = []\n",
    "\n",
    "# Create a window to view the environment\n",
    "env.render('human')\n",
    "\n",
    "for episode in range(args.episodes):\n",
    "    obs = env.reset()\n",
    "    done2 = False\n",
    "    while True:\n",
    "        env.render('human')\n",
    "        if args.gif:\n",
    "            frames.append(numpy.moveaxis(env.render(\"rgb_array\"), 2, 0))\n",
    "            \n",
    "\n",
    "        action = agent.get_action(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        agent.analyze_feedback(reward, done)\n",
    "        \n",
    "        if done or env.window.closed:\n",
    "            if episode == 4:\n",
    "                done2 = True\n",
    "            break\n",
    "    if done2 == True:\n",
    "        env.close()\n",
    "        break\n",
    "    #if env.window.closed:\n",
    "    #    break\n",
    "print('doneeee')\n",
    "if args.gif:\n",
    "    print(\"Saving gif... \", end=\"\")\n",
    "    utils.create_folders_if_necessary(\"./animation\")\n",
    "    #Path(\"./animation\").mkdir(parents=True, exist_ok=True)\n",
    "    write_gif(numpy.array(frames), \"./animation/\"+args.gif+\".gif\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_animation(args.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = wrap_env(env)\n",
    "observation = test_env.reset()\n",
    "\n",
    "done = False\n",
    "episode_reward = 0\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = agent.get_action(observation)\n",
    "    observation, reward, done, info = test_env.step(action)\n",
    "    episode_reward += reward\n",
    "    episode_length += 1\n",
    "\n",
    "print('Total reward:', episode_reward)\n",
    "print('Total length:', episode_length)\n",
    "\n",
    "test_env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set general parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':False\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous loggers and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 600000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status (TEST for CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "envs = make_envs(args.env, args.procs, args.seed)\n",
    "\n",
    "algo.env = envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing environments, model and training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 51 | F 104448 | FPS 2588 | D 0 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.509 | V 0.490 | pL 0.217 | vL 0.010 | ∇ 0.239\n",
      "U 52 | F 106496 | FPS 3027 | D 1 | rR:μσmM 0.03 0.10 0.00 0.43 | F:μσmM 14.4 55.7 0.0 230.0 | H 1.523 | V 0.365 | pL 0.173 | vL 0.005 | ∇ 0.132\n",
      "U 53 | F 108544 | FPS 2680 | D 2 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 345.4 38.8 230.0 360.0 | H 1.705 | V 0.162 | pL 0.196 | vL 0.009 | ∇ 0.151\n",
      "U 54 | F 110592 | FPS 2925 | D 2 | rR:μσmM 0.07 0.18 0.00 0.70 | F:μσmM 338.6 61.5 121.0 360.0 | H 1.784 | V 0.130 | pL 0.047 | vL 0.003 | ∇ 0.050\n",
      "U 55 | F 112640 | FPS 2558 | D 3 | rR:μσmM 0.07 0.19 0.00 0.70 | F:μσmM 336.8 64.2 121.0 360.0 | H 1.839 | V 0.089 | pL 0.040 | vL 0.001 | ∇ 0.029\n",
      "U 56 | F 114688 | FPS 3023 | D 4 | rR:μσmM 0.05 0.13 0.00 0.43 | F:μσmM 346.1 37.5 228.0 360.0 | H 1.870 | V 0.054 | pL 0.037 | vL 0.001 | ∇ 0.024\n",
      "U 57 | F 116736 | FPS 2580 | D 5 | rR:μσmM 0.09 0.20 0.00 0.71 | F:μσmM 330.8 67.2 114.0 360.0 | H 1.873 | V 0.066 | pL -0.006 | vL 0.004 | ∇ 0.043\n",
      "U 58 | F 118784 | FPS 2783 | D 5 | rR:μσmM 0.21 0.24 0.00 0.71 | F:μσmM 294.8 76.4 114.0 360.0 | H 1.893 | V 0.063 | pL 0.003 | vL 0.003 | ∇ 0.042\n",
      "U 59 | F 120832 | FPS 3068 | D 6 | rR:μσmM 0.23 0.29 0.00 0.94 | F:μσmM 286.1 100.3 26.0 360.0 | H 1.885 | V 0.043 | pL 0.018 | vL 0.005 | ∇ 0.059\n",
      "U 60 | F 122880 | FPS 3192 | D 7 | rR:μσmM 0.20 0.28 0.00 0.94 | F:μσmM 300.9 97.1 26.0 360.0 | H 1.903 | V 0.053 | pL -0.011 | vL 0.005 | ∇ 0.044\n",
      "Status saved\n",
      "U 61 | F 124928 | FPS 3163 | D 7 | rR:μσmM 0.20 0.29 0.00 0.94 | F:μσmM 299.1 101.2 26.0 360.0 | H 1.918 | V 0.043 | pL 0.002 | vL 0.002 | ∇ 0.039\n",
      "U 62 | F 126976 | FPS 3109 | D 8 | rR:μσmM 0.27 0.30 0.00 0.75 | F:μσmM 273.9 101.1 98.0 360.0 | H 1.909 | V 0.100 | pL -0.047 | vL 0.011 | ∇ 0.077\n",
      "U 63 | F 129024 | FPS 3308 | D 9 | rR:μσmM 0.35 0.31 0.00 0.76 | F:μσmM 244.1 106.7 94.0 360.0 | H 1.895 | V 0.108 | pL 0.001 | vL 0.008 | ∇ 0.065\n",
      "U 64 | F 131072 | FPS 3268 | D 9 | rR:μσmM 0.54 0.31 0.00 0.88 | F:μσmM 180.8 114.8 46.0 360.0 | H 1.859 | V 0.161 | pL -0.054 | vL 0.022 | ∇ 0.097\n",
      "U 65 | F 133120 | FPS 3290 | D 10 | rR:μσmM 0.47 0.35 0.00 0.88 | F:μσmM 205.5 129.0 46.0 360.0 | H 1.886 | V 0.147 | pL 0.005 | vL 0.011 | ∇ 0.072\n",
      "U 66 | F 135168 | FPS 2980 | D 11 | rR:μσmM 0.44 0.33 0.00 0.93 | F:μσmM 218.2 121.7 30.0 360.0 | H 1.868 | V 0.140 | pL 0.007 | vL 0.012 | ∇ 0.078\n",
      "U 67 | F 137216 | FPS 3352 | D 11 | rR:μσmM 0.34 0.33 0.00 0.93 | F:μσmM 250.4 115.3 30.0 360.0 | H 1.860 | V 0.141 | pL 0.033 | vL 0.009 | ∇ 0.078\n",
      "U 68 | F 139264 | FPS 3286 | D 12 | rR:μσmM 0.50 0.35 0.00 0.93 | F:μσmM 191.2 125.2 28.0 360.0 | H 1.849 | V 0.166 | pL -0.010 | vL 0.013 | ∇ 0.110\n",
      "U 69 | F 141312 | FPS 3231 | D 13 | rR:μσmM 0.54 0.31 0.00 0.93 | F:μσmM 176.3 110.3 29.0 360.0 | H 1.801 | V 0.204 | pL -0.032 | vL 0.016 | ∇ 0.115\n",
      "U 70 | F 143360 | FPS 3211 | D 13 | rR:μσmM 0.60 0.28 0.00 0.89 | F:μσmM 153.9 102.6 45.0 360.0 | H 1.815 | V 0.210 | pL -0.039 | vL 0.018 | ∇ 0.149\n",
      "Status saved\n",
      "U 71 | F 145408 | FPS 3197 | D 14 | rR:μσmM 0.60 0.30 0.00 0.93 | F:μσmM 155.9 108.5 27.0 360.0 | H 1.806 | V 0.262 | pL -0.014 | vL 0.015 | ∇ 0.130\n",
      "U 72 | F 147456 | FPS 3215 | D 15 | rR:μσmM 0.55 0.29 0.00 0.94 | F:μσmM 173.8 108.1 23.0 360.0 | H 1.801 | V 0.248 | pL 0.022 | vL 0.014 | ∇ 0.119\n",
      "U 73 | F 149504 | FPS 3235 | D 15 | rR:μσmM 0.55 0.34 0.00 0.89 | F:μσmM 170.3 121.2 42.0 360.0 | H 1.771 | V 0.314 | pL 0.021 | vL 0.020 | ∇ 0.142\n",
      "U 74 | F 151552 | FPS 3259 | D 16 | rR:μσmM 0.66 0.27 0.00 0.94 | F:μσmM 131.6 102.5 22.0 360.0 | H 1.742 | V 0.306 | pL -0.008 | vL 0.016 | ∇ 0.099\n",
      "U 75 | F 153600 | FPS 3020 | D 16 | rR:μσmM 0.74 0.21 0.00 0.93 | F:μσmM 101.8 78.1 30.0 360.0 | H 1.739 | V 0.378 | pL -0.074 | vL 0.022 | ∇ 0.186\n",
      "U 76 | F 155648 | FPS 3174 | D 17 | rR:μσmM 0.74 0.21 0.00 0.97 | F:μσmM 101.7 79.4 13.0 360.0 | H 1.713 | V 0.408 | pL -0.011 | vL 0.024 | ∇ 0.137\n",
      "U 77 | F 157696 | FPS 3180 | D 18 | rR:μσmM 0.83 0.12 0.49 0.95 | F:μσmM 69.0 48.5 19.0 206.0 | H 1.693 | V 0.443 | pL -0.036 | vL 0.018 | ∇ 0.151\n",
      "U 78 | F 159744 | FPS 2693 | D 19 | rR:μσmM 0.75 0.24 0.00 0.95 | F:μσmM 97.1 89.7 18.0 360.0 | H 1.681 | V 0.461 | pL 0.010 | vL 0.023 | ∇ 0.154\n",
      "U 79 | F 161792 | FPS 2871 | D 19 | rR:μσmM 0.79 0.13 0.36 0.94 | F:μσmM 83.7 53.7 25.0 255.0 | H 1.648 | V 0.483 | pL -0.026 | vL 0.013 | ∇ 0.104\n",
      "U 80 | F 163840 | FPS 2931 | D 20 | rR:μσmM 0.83 0.13 0.29 0.96 | F:μσmM 69.1 52.1 14.0 285.0 | H 1.590 | V 0.509 | pL -0.035 | vL 0.016 | ∇ 0.151\n",
      "Status saved\n",
      "U 81 | F 165888 | FPS 3028 | D 21 | rR:μσmM 0.84 0.08 0.66 0.96 | F:μσmM 64.1 30.0 17.0 137.0 | H 1.620 | V 0.519 | pL -0.026 | vL 0.016 | ∇ 0.158\n",
      "U 82 | F 167936 | FPS 2507 | D 21 | rR:μσmM 0.83 0.10 0.58 0.96 | F:μσmM 69.0 41.8 16.0 166.0 | H 1.650 | V 0.537 | pL -0.033 | vL 0.012 | ∇ 0.174\n",
      "U 83 | F 169984 | FPS 2630 | D 22 | rR:μσmM 0.83 0.10 0.56 0.94 | F:μσmM 66.2 38.5 22.0 178.0 | H 1.594 | V 0.569 | pL -0.005 | vL 0.014 | ∇ 0.126\n",
      "U 84 | F 172032 | FPS 2977 | D 23 | rR:μσmM 0.88 0.07 0.57 0.97 | F:μσmM 49.6 29.8 12.0 171.0 | H 1.642 | V 0.617 | pL -0.018 | vL 0.012 | ∇ 0.173\n",
      "U 85 | F 174080 | FPS 2920 | D 24 | rR:μσmM 0.86 0.10 0.48 0.97 | F:μσmM 55.2 41.6 12.0 208.0 | H 1.568 | V 0.599 | pL -0.004 | vL 0.016 | ∇ 0.154\n",
      "U 86 | F 176128 | FPS 3135 | D 24 | rR:μσmM 0.86 0.08 0.57 0.97 | F:μσmM 55.0 32.1 12.0 173.0 | H 1.584 | V 0.618 | pL -0.073 | vL 0.011 | ∇ 0.151\n",
      "U 87 | F 178176 | FPS 3100 | D 25 | rR:μσmM 0.89 0.05 0.76 0.96 | F:μσmM 45.6 19.4 17.0 95.0 | H 1.481 | V 0.680 | pL -0.009 | vL 0.008 | ∇ 0.134\n",
      "U 88 | F 180224 | FPS 3202 | D 26 | rR:μσmM 0.89 0.06 0.76 0.98 | F:μσmM 43.7 23.4 10.0 97.0 | H 1.531 | V 0.667 | pL 0.020 | vL 0.007 | ∇ 0.098\n",
      "U 89 | F 182272 | FPS 3248 | D 26 | rR:μσmM 0.89 0.06 0.69 0.95 | F:μσmM 45.1 25.9 18.0 122.0 | H 1.528 | V 0.673 | pL 0.001 | vL 0.009 | ∇ 0.134\n",
      "U 90 | F 184320 | FPS 3244 | D 27 | rR:μσmM 0.89 0.07 0.63 0.98 | F:μσmM 42.4 28.8 10.0 146.0 | H 1.550 | V 0.689 | pL 0.022 | vL 0.009 | ∇ 0.136\n",
      "Status saved\n",
      "U 91 | F 186368 | FPS 3229 | D 28 | rR:μσmM 0.89 0.05 0.74 0.96 | F:μσmM 43.3 19.6 14.0 104.0 | H 1.536 | V 0.731 | pL 0.019 | vL 0.004 | ∇ 0.074\n",
      "U 92 | F 188416 | FPS 2948 | D 28 | rR:μσmM 0.90 0.05 0.67 0.97 | F:μσmM 42.0 20.7 11.0 134.0 | H 1.544 | V 0.671 | pL 0.035 | vL 0.011 | ∇ 0.134\n",
      "U 93 | F 190464 | FPS 3098 | D 29 | rR:μσmM 0.90 0.05 0.72 0.98 | F:μσmM 38.2 20.2 10.0 112.0 | H 1.539 | V 0.644 | pL 0.002 | vL 0.010 | ∇ 0.115\n",
      "U 94 | F 192512 | FPS 3155 | D 30 | rR:μσmM 0.86 0.17 0.00 0.97 | F:μσmM 54.6 63.1 11.0 360.0 | H 1.535 | V 0.638 | pL 0.001 | vL 0.015 | ∇ 0.187\n",
      "U 95 | F 194560 | FPS 3110 | D 30 | rR:μσmM 0.90 0.06 0.56 0.96 | F:μσmM 39.6 25.7 17.0 178.0 | H 1.515 | V 0.676 | pL 0.009 | vL 0.009 | ∇ 0.120\n",
      "U 96 | F 196608 | FPS 3222 | D 31 | rR:μσmM 0.90 0.08 0.43 0.96 | F:μσmM 39.2 31.2 15.0 228.0 | H 1.502 | V 0.695 | pL -0.002 | vL 0.010 | ∇ 0.126\n",
      "U 97 | F 198656 | FPS 1984 | D 32 | rR:μσmM 0.91 0.05 0.69 0.98 | F:μσmM 35.6 21.4 10.0 126.0 | H 1.439 | V 0.704 | pL -0.023 | vL 0.008 | ∇ 0.101\n",
      "U 98 | F 200704 | FPS 2849 | D 33 | rR:μσmM 0.91 0.08 0.33 0.97 | F:μσmM 35.4 31.5 12.0 269.0 | H 1.382 | V 0.750 | pL -0.048 | vL 0.007 | ∇ 0.124\n",
      "U 99 | F 202752 | FPS 2904 | D 33 | rR:μσmM 0.93 0.04 0.78 0.97 | F:μσmM 29.8 14.4 12.0 87.0 | H 1.358 | V 0.752 | pL -0.043 | vL 0.006 | ∇ 0.104\n",
      "Number of frames:  204800\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 2nd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_redblue', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 1800000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "args.env = env_id\n",
    "\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 3633.0 | FPS 3963 | D 0.0 | R:μσmM 0.91 0.07 0.63 0.97 | F:μσmM 36.4 27.0 12.0 149.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_reshaped', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 1800000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': False, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_reshaped'\n",
    "#args.model = 'test_ppo_frames_128_wallgap_doorkey'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environments, agent and logs, run agent and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 4841.0 | FPS 4192 | D 1.0 | R:μσmM 0.69 0.35 0.00 0.99 | F:μσmM 46.6 50.9 2.0 144.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue learning on 3rd environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-5x5-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS6-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-5x5-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "#model = 'MiniGrid-DoorKey-6x6-v0_meta_RIM_5_3_frames_500k_tasks_2_recur_64_16_proc_16_RMSProp_lr_7e4_gae_099_newloop_changeseed'\n",
    "model = 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped'\n",
    "\n",
    "add_frames = 300000\n",
    "frames = frames + add_frames\n",
    "\n",
    "## Hyper-parameters\n",
    "args = {\n",
    "# General parameters\n",
    "'algo':'ppo',\n",
    "'env':env_id,\n",
    "'model':model,\n",
    "'seed':1,\n",
    "'log_interval':1,\n",
    "'save_interval':10,\n",
    "'procs':processes,\n",
    "'frames':frames, # default 1e7\n",
    "# Parameters for main algorithm\n",
    "'epochs':4,\n",
    "'batch_size':256,\n",
    "'frames_per_proc':128, # 128 for PPO and 5 per A2C\n",
    "'discount':0.99,\n",
    "#'lr':0.0001, # for Adam\n",
    "'lr':0.0007, # for RMSProp\n",
    "#'gae_lambda':0.95, # 1 means no gae, for Adam\n",
    "'gae_lambda':0.99, # 1 means no gae, for RMSProp\n",
    "'entropy_coef':0.01,\n",
    "'value_loss_coef':0.5,\n",
    "'max_grad_norm':0.5,\n",
    "'optim_eps':1e-8,\n",
    "'optim_alpha':0.99,\n",
    "'clip_eps':0.2,\n",
    "'recurrence':1, # if > 1, a LSTM is added\n",
    "'text':False, # add a GRU for text input\n",
    "'reshape_reward':True\n",
    "}\n",
    "\n",
    "#args = utils.dotdict(args)\n",
    "args = DictList(args)\n",
    "\n",
    "args.mem = args.recurrence > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped', 'seed': 1, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': True, 'mem': False}\n",
      "\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "default_model_name = f\"{args.env}_{args.algo}_seed{args.seed}_{date}\"\n",
    "\n",
    "model_name = args.model or default_model_name\n",
    "model_dir = utils.get_model_dir(model_name)\n",
    "\n",
    "# Load loggers and Tensorboard writer\n",
    "\n",
    "txt_logger = utils.get_txt_logger(model_dir)\n",
    "csv_file, csv_logger = utils.get_csv_logger(model_dir)\n",
    "tb_writer = tensorboardX.SummaryWriter(model_dir)\n",
    "\n",
    "# Log command and all script arguments\n",
    "\n",
    "#txt_logger.info(\"{}\\n\".format(\" \".join(sys.argv)))\n",
    "txt_logger.info(\"{}\\n\".format(args))\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "txt_logger.info(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments loaded\n",
      "\n",
      "Training status loaded\n",
      "\n",
      "Observations preprocessor loaded\n",
      "Model loaded\n",
      "\n",
      "ACModel(\n",
      "  (image_conv): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (actor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
      "  )\n",
      "  (critic): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Optimizer loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environments\n",
    "\n",
    "envs = []\n",
    "for i in range(args.procs):\n",
    "    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\n",
    "txt_logger.info(\"Environments loaded\\n\")\n",
    "\n",
    "# Load training status\n",
    "\n",
    "try:\n",
    "    status = utils.get_status(model_dir)\n",
    "except OSError:\n",
    "    status = {\"num_frames\": 0, \"update\": 0}\n",
    "txt_logger.info(\"Training status loaded\\n\")\n",
    "\n",
    "# Load observations preprocessor\n",
    "\n",
    "obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\n",
    "if \"vocab\" in status:\n",
    "    preprocess_obss.vocab.load_vocab(status[\"vocab\"])\n",
    "txt_logger.info(\"Observations preprocessor loaded\")\n",
    "\n",
    "# Reshape reward function\n",
    "if args.reshape_reward:\n",
    "    def reshape_reward(obs, action, reward, done):\n",
    "        if not done:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 1\n",
    "        return reward\n",
    "else:\n",
    "    reshape_reward = None\n",
    "\n",
    "# Load model\n",
    "\n",
    "acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\n",
    "if \"model_state\" in status:\n",
    "    acmodel.load_state_dict(status[\"model_state\"])\n",
    "acmodel.to(device)\n",
    "txt_logger.info(\"Model loaded\\n\")\n",
    "txt_logger.info(\"{}\\n\".format(acmodel))\n",
    "\n",
    "# Load algo\n",
    "\n",
    "if args.algo == \"a2c\":\n",
    "    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_alpha, args.optim_eps, preprocess_obss)\n",
    "elif args.algo == \"ppo\":\n",
    "    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n",
    "                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n",
    "                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, reshape_reward)\n",
    "else:\n",
    "    raise ValueError(\"Incorrect algorithm name: {}\".format(args.algo))\n",
    "\n",
    "# change to RMSProp optimizer\n",
    "algo.optimizer = torch.optim.RMSprop(algo.acmodel.parameters(), args.lr, eps=args.optim_eps)\n",
    "\n",
    "if \"optimizer_state\" in status:\n",
    "    algo.optimizer.load_state_dict(status[\"optimizer_state\"])\n",
    "txt_logger.info(\"Optimizer loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 171 | F 350208 | FPS 2302 | D 0 | rR:μσmM 0.50 0.44 0.00 0.96 | F:μσmM 23.2 28.8 0.0 108.0 | H 1.131 | V -26.965 | pL 19.323 | vL 612.108 | ∇ 123.642\n",
      "U 172 | F 352256 | FPS 2985 | D 1 | rR:μσmM 0.79 0.17 0.44 0.96 | F:μσmM 74.5 62.7 15.0 202.0 | H 1.024 | V -26.678 | pL 20.256 | vL 603.917 | ∇ 65.042\n",
      "U 173 | F 354304 | FPS 2677 | D 2 | rR:μσmM 0.33 0.37 0.00 0.96 | F:μσmM 226.2 118.9 15.0 324.0 | H 1.140 | V -28.477 | pL 12.468 | vL 391.448 | ∇ 138.877\n",
      "U 174 | F 356352 | FPS 2588 | D 3 | rR:μσmM 0.64 0.31 0.00 0.93 | F:μσmM 126.8 101.9 25.0 324.0 | H 1.212 | V -29.108 | pL 14.343 | vL 429.502 | ∇ 88.875\n",
      "U 175 | F 358400 | FPS 2456 | D 3 | rR:μσmM 0.55 0.36 0.00 0.96 | F:μσmM 154.4 116.5 16.0 324.0 | H 1.234 | V -29.634 | pL 14.687 | vL 456.685 | ∇ 165.080\n",
      "U 176 | F 360448 | FPS 2711 | D 4 | rR:μσmM 0.49 0.33 0.00 0.93 | F:μσmM 176.4 107.1 27.0 324.0 | H 1.251 | V -27.591 | pL 13.714 | vL 446.975 | ∇ 154.554\n",
      "U 177 | F 362496 | FPS 2969 | D 5 | rR:μσmM 0.51 0.39 0.00 0.94 | F:μσmM 165.9 124.8 22.0 324.0 | H 1.282 | V -29.552 | pL 16.527 | vL 474.597 | ∇ 157.011\n",
      "U 178 | F 364544 | FPS 3250 | D 6 | rR:μσmM 0.55 0.36 0.00 0.94 | F:μσmM 151.9 114.6 21.0 324.0 | H 1.301 | V -30.611 | pL 8.380 | vL 331.026 | ∇ 132.134\n",
      "U 179 | F 366592 | FPS 3343 | D 6 | rR:μσmM 0.62 0.28 0.00 0.93 | F:μσmM 132.6 90.9 27.0 324.0 | H 1.302 | V -31.358 | pL 12.830 | vL 404.324 | ∇ 97.509\n",
      "U 180 | F 368640 | FPS 3269 | D 7 | rR:μσmM 0.61 0.28 0.00 0.94 | F:μσmM 134.4 90.4 23.0 324.0 | H 1.419 | V -32.123 | pL 14.339 | vL 415.904 | ∇ 88.070\n",
      "Status saved\n",
      "U 181 | F 370688 | FPS 3316 | D 7 | rR:μσmM 0.59 0.37 0.00 0.92 | F:μσmM 139.9 119.7 28.0 324.0 | H 1.366 | V -30.537 | pL 12.711 | vL 412.396 | ∇ 88.756\n",
      "U 182 | F 372736 | FPS 3098 | D 8 | rR:μσmM 0.45 0.39 0.00 0.92 | F:μσmM 184.7 125.4 30.0 324.0 | H 1.425 | V -29.925 | pL 12.505 | vL 406.371 | ∇ 336.515\n",
      "U 183 | F 374784 | FPS 3070 | D 9 | rR:μσmM 0.49 0.33 0.00 0.88 | F:μσmM 175.0 105.8 44.0 324.0 | H 1.466 | V -32.747 | pL 15.412 | vL 435.394 | ∇ 87.697\n",
      "U 184 | F 376832 | FPS 3152 | D 9 | rR:μσmM 0.44 0.30 0.00 0.88 | F:μσmM 193.8 96.1 45.0 324.0 | H 1.437 | V -32.750 | pL 9.765 | vL 317.464 | ∇ 97.909\n",
      "U 185 | F 378880 | FPS 2867 | D 10 | rR:μσmM 0.45 0.28 0.00 0.88 | F:μσmM 190.8 89.8 45.0 324.0 | H 1.422 | V -33.067 | pL 15.479 | vL 431.163 | ∇ 98.826\n",
      "U 186 | F 380928 | FPS 3184 | D 11 | rR:μσmM 0.50 0.28 0.00 0.91 | F:μσmM 174.8 93.1 34.0 324.0 | H 1.369 | V -32.807 | pL 12.332 | vL 380.084 | ∇ 133.862\n",
      "U 187 | F 382976 | FPS 3222 | D 11 | rR:μσmM 0.39 0.35 0.00 0.93 | F:μσmM 206.9 114.4 26.0 324.0 | H 1.363 | V -33.962 | pL 14.146 | vL 437.398 | ∇ 146.645\n",
      "U 188 | F 385024 | FPS 3180 | D 12 | rR:μσmM 0.47 0.31 0.00 0.93 | F:μσmM 184.6 102.3 26.0 324.0 | H 1.388 | V -32.977 | pL 13.002 | vL 421.309 | ∇ 112.704\n",
      "U 189 | F 387072 | FPS 3173 | D 13 | rR:μσmM 0.62 0.36 0.00 0.95 | F:μσmM 129.1 115.8 17.0 324.0 | H 1.374 | V -33.621 | pL 12.326 | vL 436.495 | ∇ 139.453\n",
      "U 190 | F 389120 | FPS 3201 | D 13 | rR:μσmM 0.59 0.39 0.00 0.95 | F:μσmM 137.1 127.1 17.0 324.0 | H 1.422 | V -34.434 | pL 12.048 | vL 383.393 | ∇ 80.416\n",
      "Status saved\n",
      "U 191 | F 391168 | FPS 2817 | D 14 | rR:μσmM 0.55 0.36 0.00 0.92 | F:μσmM 152.5 115.2 30.0 324.0 | H 1.424 | V -33.159 | pL 7.517 | vL 321.552 | ∇ 120.423\n",
      "U 192 | F 393216 | FPS 2462 | D 15 | rR:μσmM 0.64 0.30 0.00 0.93 | F:μσmM 124.5 100.2 24.0 324.0 | H 1.461 | V -34.596 | pL 13.108 | vL 388.534 | ∇ 125.970\n",
      "U 193 | F 395264 | FPS 2724 | D 16 | rR:μσmM 0.50 0.34 0.00 0.93 | F:μσmM 171.5 108.3 24.0 324.0 | H 1.539 | V -35.318 | pL 15.219 | vL 421.842 | ∇ 65.116\n",
      "U 194 | F 397312 | FPS 2744 | D 16 | rR:μσmM 0.31 0.33 0.00 0.88 | F:μσmM 232.0 103.2 42.0 324.0 | H 1.538 | V -35.345 | pL 14.650 | vL 432.798 | ∇ 78.676\n",
      "U 195 | F 399360 | FPS 2244 | D 17 | rR:μσmM 0.27 0.36 0.00 0.84 | F:μσmM 238.9 113.6 57.0 324.0 | H 1.590 | V -35.515 | pL 10.640 | vL 392.353 | ∇ 105.429\n",
      "U 196 | F 401408 | FPS 2083 | D 18 | rR:μσmM 0.50 0.35 0.00 0.87 | F:μσmM 170.5 111.1 48.0 324.0 | H 1.590 | V -35.376 | pL 12.039 | vL 367.287 | ∇ 99.640\n",
      "U 197 | F 403456 | FPS 1933 | D 19 | rR:μσmM 0.44 0.32 0.00 0.86 | F:μσmM 191.9 102.0 52.0 324.0 | H 1.590 | V -36.165 | pL 13.989 | vL 393.487 | ∇ 106.545\n",
      "U 198 | F 405504 | FPS 2555 | D 20 | rR:μσmM 0.39 0.33 0.00 0.89 | F:μσmM 206.6 107.0 40.0 324.0 | H 1.564 | V -35.975 | pL 13.349 | vL 395.967 | ∇ 88.010\n",
      "U 199 | F 407552 | FPS 2809 | D 21 | rR:μσmM 0.38 0.36 0.00 0.88 | F:μσmM 209.1 111.9 42.0 324.0 | H 1.524 | V -35.764 | pL 12.978 | vL 384.651 | ∇ 90.501\n",
      "U 200 | F 409600 | FPS 2902 | D 22 | rR:μσmM 0.37 0.33 0.00 0.88 | F:μσmM 214.2 102.1 42.0 324.0 | H 1.537 | V -36.050 | pL 8.352 | vL 317.619 | ∇ 186.223\n",
      "Status saved\n",
      "U 201 | F 411648 | FPS 3201 | D 22 | rR:μσmM 0.54 0.32 0.00 0.93 | F:μσmM 158.4 105.8 26.0 324.0 | H 1.524 | V -36.105 | pL 11.313 | vL 361.260 | ∇ 128.266\n",
      "U 202 | F 413696 | FPS 3220 | D 23 | rR:μσmM 0.45 0.38 0.00 0.90 | F:μσmM 185.7 122.2 37.0 324.0 | H 1.543 | V -36.157 | pL 12.079 | vL 378.239 | ∇ 74.354\n",
      "U 203 | F 415744 | FPS 3251 | D 24 | rR:μσmM 0.35 0.35 0.00 0.90 | F:μσmM 218.9 112.1 37.0 324.0 | H 1.421 | V -33.976 | pL 12.074 | vL 425.483 | ∇ 205.275\n",
      "U 204 | F 417792 | FPS 3178 | D 24 | rR:μσmM 0.51 0.31 0.00 0.94 | F:μσmM 171.4 101.7 21.0 324.0 | H 1.539 | V -35.348 | pL 6.864 | vL 301.869 | ∇ 102.683\n",
      "U 205 | F 419840 | FPS 3190 | D 25 | rR:μσmM 0.61 0.30 0.00 0.91 | F:μσmM 135.1 98.5 33.0 324.0 | H 1.528 | V -36.026 | pL 11.882 | vL 359.765 | ∇ 98.723\n",
      "U 206 | F 421888 | FPS 3148 | D 26 | rR:μσmM 0.56 0.28 0.00 0.91 | F:μσmM 155.9 95.1 34.0 324.0 | H 1.515 | V -36.362 | pL 11.642 | vL 332.116 | ∇ 80.690\n",
      "U 207 | F 423936 | FPS 3144 | D 26 | rR:μσmM 0.40 0.33 0.00 0.91 | F:μσmM 203.9 106.6 34.0 324.0 | H 1.473 | V -36.499 | pL 8.485 | vL 309.341 | ∇ 152.162\n",
      "U 208 | F 425984 | FPS 2963 | D 27 | rR:μσmM 0.45 0.34 0.00 0.85 | F:μσmM 186.0 107.4 54.0 324.0 | H 1.449 | V -37.525 | pL 11.506 | vL 361.892 | ∇ 62.056\n",
      "U 209 | F 428032 | FPS 3119 | D 28 | rR:μσmM 0.47 0.36 0.00 0.93 | F:μσmM 180.8 116.6 26.0 324.0 | H 1.445 | V -38.334 | pL 10.513 | vL 356.596 | ∇ 66.651\n",
      "U 210 | F 430080 | FPS 3175 | D 28 | rR:μσmM 0.55 0.30 0.00 0.93 | F:μσmM 157.1 100.8 25.0 324.0 | H 1.411 | V -36.622 | pL 6.756 | vL 279.429 | ∇ 121.698\n",
      "Status saved\n",
      "U 211 | F 432128 | FPS 3132 | D 29 | rR:μσmM 0.56 0.30 0.00 0.94 | F:μσmM 155.4 104.9 22.0 324.0 | H 1.447 | V -38.010 | pL 13.129 | vL 345.037 | ∇ 58.839\n",
      "U 212 | F 434176 | FPS 3164 | D 30 | rR:μσmM 0.55 0.33 0.00 0.94 | F:μσmM 156.8 106.3 23.0 324.0 | H 1.397 | V -36.409 | pL 7.062 | vL 288.405 | ∇ 136.994\n",
      "U 213 | F 436224 | FPS 3163 | D 30 | rR:μσmM 0.55 0.33 0.00 0.94 | F:μσmM 152.7 104.6 23.0 324.0 | H 1.388 | V -37.585 | pL 8.943 | vL 321.711 | ∇ 113.290\n",
      "U 214 | F 438272 | FPS 3114 | D 31 | rR:μσmM 0.57 0.31 0.00 0.87 | F:μσmM 149.8 97.9 46.0 324.0 | H 1.419 | V -37.558 | pL 11.329 | vL 361.274 | ∇ 121.671\n",
      "U 215 | F 440320 | FPS 2899 | D 32 | rR:μσmM 0.51 0.34 0.00 0.94 | F:μσmM 168.4 109.9 22.0 324.0 | H 1.310 | V -35.302 | pL 6.343 | vL 354.926 | ∇ 138.877\n",
      "U 216 | F 442368 | FPS 3121 | D 32 | rR:μσmM 0.66 0.31 0.00 0.90 | F:μσmM 117.6 100.0 35.0 324.0 | H 1.366 | V -36.014 | pL 9.438 | vL 330.433 | ∇ 87.296\n",
      "U 217 | F 444416 | FPS 3096 | D 33 | rR:μσmM 0.62 0.28 0.00 0.90 | F:μσmM 130.9 89.6 37.0 324.0 | H 1.437 | V -37.997 | pL 12.377 | vL 374.935 | ∇ 56.064\n",
      "U 218 | F 446464 | FPS 3114 | D 34 | rR:μσmM 0.45 0.39 0.00 0.92 | F:μσmM 185.4 125.9 29.0 324.0 | H 1.415 | V -38.567 | pL 6.726 | vL 332.232 | ∇ 114.990\n",
      "U 219 | F 448512 | FPS 3095 | D 34 | rR:μσmM 0.56 0.32 0.00 0.92 | F:μσmM 151.3 104.0 29.0 324.0 | H 1.377 | V -37.466 | pL 11.721 | vL 347.223 | ∇ 98.280\n",
      "U 220 | F 450560 | FPS 2629 | D 35 | rR:μσmM 0.45 0.34 0.00 0.86 | F:μσmM 186.2 108.8 50.0 324.0 | H 1.384 | V -36.750 | pL 8.881 | vL 361.117 | ∇ 176.437\n",
      "Status saved\n",
      "U 221 | F 452608 | FPS 2890 | D 36 | rR:μσmM 0.48 0.32 0.00 0.86 | F:μσmM 177.4 100.9 51.0 324.0 | H 1.437 | V -38.319 | pL 6.814 | vL 293.397 | ∇ 99.273\n",
      "U 222 | F 454656 | FPS 2552 | D 37 | rR:μσmM 0.53 0.30 0.00 0.82 | F:μσmM 162.1 94.7 64.0 324.0 | H 1.445 | V -37.875 | pL 11.992 | vL 343.209 | ∇ 89.645\n",
      "U 223 | F 456704 | FPS 2585 | D 37 | rR:μσmM 0.46 0.32 0.00 0.91 | F:μσmM 183.8 103.1 31.0 324.0 | H 1.457 | V -38.514 | pL 8.151 | vL 332.156 | ∇ 114.824\n",
      "U 224 | F 458752 | FPS 2854 | D 38 | rR:μσmM 0.55 0.33 0.00 0.93 | F:μσmM 154.6 104.5 25.0 324.0 | H 1.423 | V -37.830 | pL 7.213 | vL 318.409 | ∇ 189.566\n",
      "U 225 | F 460800 | FPS 3110 | D 39 | rR:μσmM 0.56 0.32 0.00 0.93 | F:μσmM 150.2 103.1 25.0 324.0 | H 1.453 | V -39.356 | pL 8.868 | vL 340.337 | ∇ 94.550\n",
      "U 226 | F 462848 | FPS 3030 | D 39 | rR:μσmM 0.51 0.29 0.00 0.89 | F:μσmM 170.8 95.0 38.0 324.0 | H 1.422 | V -39.067 | pL 8.875 | vL 293.468 | ∇ 84.959\n",
      "U 227 | F 464896 | FPS 2952 | D 40 | rR:μσmM 0.61 0.30 0.00 0.88 | F:μσmM 137.3 104.3 43.0 324.0 | H 1.301 | V -36.823 | pL 9.755 | vL 371.246 | ∇ 115.442\n",
      "U 228 | F 466944 | FPS 2938 | D 41 | rR:μσmM 0.52 0.36 0.00 0.88 | F:μσmM 162.1 112.7 44.0 324.0 | H 1.354 | V -39.412 | pL 7.178 | vL 337.511 | ∇ 110.716\n",
      "U 229 | F 468992 | FPS 2616 | D 42 | rR:μσmM 0.54 0.34 0.00 0.88 | F:μσmM 156.1 108.5 44.0 324.0 | H 1.403 | V -40.174 | pL 12.683 | vL 401.047 | ∇ 106.962\n",
      "U 230 | F 471040 | FPS 2458 | D 42 | rR:μσmM 0.55 0.37 0.00 0.91 | F:μσmM 151.6 120.4 33.0 324.0 | H 1.347 | V -39.680 | pL 6.256 | vL 344.996 | ∇ 133.965\n",
      "Status saved\n",
      "U 231 | F 473088 | FPS 2698 | D 43 | rR:μσmM 0.45 0.40 0.00 0.90 | F:μσmM 182.8 127.1 37.0 324.0 | H 1.390 | V -37.882 | pL 6.952 | vL 331.825 | ∇ 134.359\n",
      "U 232 | F 475136 | FPS 3075 | D 44 | rR:μσmM 0.47 0.36 0.00 0.94 | F:μσmM 180.3 115.9 22.0 324.0 | H 1.359 | V -38.032 | pL 14.843 | vL 433.156 | ∇ 117.731\n",
      "U 233 | F 477184 | FPS 3121 | D 45 | rR:μσmM 0.54 0.33 0.00 0.91 | F:μσmM 158.9 110.8 33.0 324.0 | H 1.365 | V -38.486 | pL 5.164 | vL 331.181 | ∇ 153.732\n",
      "U 234 | F 479232 | FPS 3138 | D 45 | rR:μσmM 0.67 0.30 0.00 0.94 | F:μσmM 114.9 97.7 20.0 324.0 | H 1.318 | V -38.008 | pL 3.076 | vL 300.807 | ∇ 150.303\n",
      "U 235 | F 481280 | FPS 3030 | D 46 | rR:μσmM 0.72 0.23 0.00 0.94 | F:μσmM 100.8 76.3 21.0 324.0 | H 1.291 | V -38.086 | pL 4.237 | vL 285.049 | ∇ 138.824\n",
      "U 236 | F 483328 | FPS 3113 | D 47 | rR:μσmM 0.69 0.31 0.00 0.94 | F:μσmM 106.4 101.4 21.0 324.0 | H 1.302 | V -39.637 | pL 7.081 | vL 328.987 | ∇ 134.089\n",
      "U 237 | F 485376 | FPS 3128 | D 47 | rR:μσmM 0.56 0.30 0.00 0.89 | F:μσmM 152.2 97.5 41.0 324.0 | H 1.295 | V -38.367 | pL 11.840 | vL 369.988 | ∇ 104.890\n",
      "U 238 | F 487424 | FPS 3127 | D 48 | rR:μσmM 0.46 0.34 0.00 0.89 | F:μσmM 181.6 107.4 41.0 324.0 | H 1.362 | V -40.567 | pL 9.992 | vL 365.305 | ∇ 172.099\n",
      "U 239 | F 489472 | FPS 3167 | D 49 | rR:μσmM 0.45 0.33 0.00 0.94 | F:μσmM 188.4 105.7 22.0 324.0 | H 1.321 | V -40.501 | pL 7.584 | vL 320.668 | ∇ 226.755\n",
      "U 240 | F 491520 | FPS 3135 | D 49 | rR:μσmM 0.51 0.35 0.00 0.94 | F:μσmM 170.5 117.8 22.0 324.0 | H 1.364 | V -40.126 | pL 9.176 | vL 321.880 | ∇ 149.389\n",
      "Status saved\n",
      "U 241 | F 493568 | FPS 3084 | D 50 | rR:μσmM 0.51 0.36 0.00 0.91 | F:μσmM 165.8 114.6 34.0 324.0 | H 1.308 | V -40.343 | pL 4.825 | vL 304.648 | ∇ 80.232\n",
      "U 242 | F 495616 | FPS 3107 | D 50 | rR:μσmM 0.63 0.33 0.00 0.95 | F:μσmM 126.8 107.6 19.0 324.0 | H 1.276 | V -37.853 | pL 11.135 | vL 405.445 | ∇ 134.503\n",
      "U 243 | F 497664 | FPS 2877 | D 51 | rR:μσmM 0.61 0.32 0.00 0.95 | F:μσmM 134.2 103.2 18.0 324.0 | H 1.283 | V -39.593 | pL 6.878 | vL 331.638 | ∇ 219.795\n",
      "U 244 | F 499712 | FPS 3076 | D 52 | rR:μσmM 0.53 0.38 0.00 0.94 | F:μσmM 158.7 122.5 21.0 324.0 | H 1.291 | V -39.675 | pL 4.294 | vL 321.800 | ∇ 157.743\n",
      "U 245 | F 501760 | FPS 3117 | D 53 | rR:μσmM 0.66 0.27 0.00 0.95 | F:μσmM 118.8 87.8 19.0 324.0 | H 1.266 | V -38.915 | pL 8.880 | vL 364.472 | ∇ 151.582\n",
      "U 246 | F 503808 | FPS 2935 | D 53 | rR:μσmM 0.55 0.34 0.00 0.93 | F:μσmM 157.2 112.9 25.0 324.0 | H 1.245 | V -39.200 | pL 4.785 | vL 312.542 | ∇ 157.340\n",
      "U 247 | F 505856 | FPS 3036 | D 54 | rR:μσmM 0.77 0.15 0.34 0.94 | F:μσmM 81.8 54.0 23.0 237.0 | H 1.217 | V -38.097 | pL 4.703 | vL 304.311 | ∇ 111.604\n",
      "U 248 | F 507904 | FPS 3101 | D 55 | rR:μσmM 0.59 0.35 0.00 0.91 | F:μσmM 139.9 112.0 32.0 324.0 | H 1.225 | V -39.132 | pL 11.463 | vL 404.763 | ∇ 140.823\n",
      "U 249 | F 509952 | FPS 2753 | D 55 | rR:μσmM 0.44 0.37 0.00 0.95 | F:μσmM 188.1 115.5 19.0 324.0 | H 1.236 | V -40.791 | pL 8.082 | vL 319.821 | ∇ 107.898\n",
      "U 250 | F 512000 | FPS 2549 | D 56 | rR:μσmM 0.47 0.36 0.00 0.95 | F:μσmM 177.9 115.8 19.0 324.0 | H 1.228 | V -42.238 | pL 10.572 | vL 353.285 | ∇ 84.359\n",
      "Status saved\n",
      "U 251 | F 514048 | FPS 2737 | D 57 | rR:μσmM 0.64 0.30 0.00 0.94 | F:μσmM 123.9 97.9 21.0 324.0 | H 1.179 | V -39.621 | pL 5.162 | vL 334.801 | ∇ 173.172\n",
      "U 252 | F 516096 | FPS 3107 | D 58 | rR:μσmM 0.60 0.39 0.00 0.91 | F:μσmM 133.7 125.8 32.0 324.0 | H 1.164 | V -40.143 | pL 6.630 | vL 362.958 | ∇ 172.058\n",
      "U 253 | F 518144 | FPS 2730 | D 58 | rR:μσmM 0.71 0.26 0.00 0.96 | F:μσmM 100.0 83.5 16.0 324.0 | H 1.122 | V -37.959 | pL 6.179 | vL 356.573 | ∇ 120.993\n",
      "U 254 | F 520192 | FPS 3092 | D 59 | rR:μσmM 0.64 0.35 0.00 0.95 | F:μσmM 124.2 114.2 17.0 324.0 | H 1.096 | V -37.836 | pL 4.905 | vL 364.527 | ∇ 112.519\n",
      "U 255 | F 522240 | FPS 2147 | D 60 | rR:μσmM 0.64 0.31 0.00 0.91 | F:μσmM 125.5 100.9 34.0 324.0 | H 1.141 | V -38.436 | pL 9.628 | vL 351.459 | ∇ 125.206\n",
      "U 256 | F 524288 | FPS 1705 | D 61 | rR:μσmM 0.65 0.29 0.00 0.96 | F:μσmM 123.9 98.2 15.0 324.0 | H 1.110 | V -39.962 | pL 7.343 | vL 357.752 | ∇ 187.113\n",
      "U 257 | F 526336 | FPS 1838 | D 62 | rR:μσmM 0.57 0.38 0.00 0.95 | F:μσmM 145.2 123.8 18.0 324.0 | H 1.174 | V -38.500 | pL 6.659 | vL 353.861 | ∇ 122.100\n",
      "U 258 | F 528384 | FPS 2214 | D 63 | rR:μσmM 0.55 0.37 0.00 0.95 | F:μσmM 153.9 120.1 18.0 324.0 | H 1.235 | V -39.222 | pL 12.744 | vL 399.367 | ∇ 104.248\n",
      "U 259 | F 530432 | FPS 2262 | D 64 | rR:μσmM 0.55 0.38 0.00 0.93 | F:μσmM 154.0 124.1 27.0 324.0 | H 1.248 | V -39.677 | pL 6.422 | vL 346.334 | ∇ 144.656\n",
      "U 260 | F 532480 | FPS 2361 | D 65 | rR:μσmM 0.63 0.35 0.00 0.95 | F:μσmM 126.5 115.3 19.0 324.0 | H 1.170 | V -38.942 | pL 5.731 | vL 335.529 | ∇ 159.364\n",
      "Status saved\n",
      "U 261 | F 534528 | FPS 2446 | D 66 | rR:μσmM 0.61 0.35 0.00 0.95 | F:μσmM 134.1 114.1 18.0 324.0 | H 1.212 | V -38.222 | pL 12.273 | vL 417.518 | ∇ 91.870\n",
      "U 262 | F 536576 | FPS 2432 | D 67 | rR:μσmM 0.67 0.29 0.00 0.94 | F:μσmM 114.9 99.0 20.0 324.0 | H 1.261 | V -39.745 | pL 9.168 | vL 355.672 | ∇ 115.480\n",
      "U 263 | F 538624 | FPS 2316 | D 68 | rR:μσmM 0.61 0.38 0.00 0.96 | F:μσmM 130.8 122.7 15.0 324.0 | H 1.221 | V -38.167 | pL 2.217 | vL 338.396 | ∇ 184.625\n",
      "U 264 | F 540672 | FPS 2502 | D 68 | rR:μσmM 0.65 0.35 0.00 0.94 | F:μσmM 119.7 112.5 21.0 324.0 | H 1.198 | V -38.207 | pL 10.301 | vL 380.629 | ∇ 129.618\n",
      "U 265 | F 542720 | FPS 2520 | D 69 | rR:μσmM 0.55 0.38 0.00 0.96 | F:μσmM 154.4 125.7 16.0 324.0 | H 1.181 | V -37.696 | pL 7.078 | vL 378.267 | ∇ 196.691\n",
      "U 266 | F 544768 | FPS 2570 | D 70 | rR:μσmM 0.57 0.35 0.00 0.95 | F:μσmM 149.3 114.9 19.0 324.0 | H 1.256 | V -37.994 | pL 7.470 | vL 319.086 | ∇ 131.100\n",
      "U 267 | F 546816 | FPS 2600 | D 71 | rR:μσmM 0.71 0.21 0.14 0.94 | F:μσmM 104.8 74.7 22.0 310.0 | H 1.299 | V -37.614 | pL 4.534 | vL 292.501 | ∇ 169.336\n",
      "U 268 | F 548864 | FPS 2571 | D 72 | rR:μσmM 0.72 0.25 0.00 0.95 | F:μσmM 98.8 84.9 17.0 324.0 | H 1.295 | V -38.742 | pL 7.853 | vL 332.605 | ∇ 156.540\n",
      "U 269 | F 550912 | FPS 2587 | D 72 | rR:μσmM 0.66 0.32 0.00 0.96 | F:μσmM 116.3 104.1 16.0 324.0 | H 1.290 | V -39.067 | pL 3.983 | vL 354.548 | ∇ 169.476\n",
      "U 270 | F 552960 | FPS 2603 | D 73 | rR:μσmM 0.66 0.32 0.00 0.94 | F:μσmM 116.3 103.5 20.0 324.0 | H 1.281 | V -37.688 | pL 2.400 | vL 296.224 | ∇ 153.620\n",
      "Status saved\n",
      "U 271 | F 555008 | FPS 2599 | D 74 | rR:μσmM 0.69 0.30 0.00 0.96 | F:μσmM 106.2 98.3 16.0 324.0 | H 1.327 | V -37.620 | pL 5.952 | vL 343.250 | ∇ 195.965\n",
      "U 272 | F 557056 | FPS 2558 | D 75 | rR:μσmM 0.61 0.28 0.00 0.96 | F:μσmM 137.3 92.4 16.0 324.0 | H 1.330 | V -39.231 | pL 13.528 | vL 396.100 | ∇ 146.916\n",
      "U 273 | F 559104 | FPS 2327 | D 76 | rR:μσmM 0.51 0.32 0.00 0.94 | F:μσmM 169.0 106.6 20.0 324.0 | H 1.330 | V -37.732 | pL 10.493 | vL 342.398 | ∇ 121.372\n",
      "U 274 | F 561152 | FPS 2391 | D 77 | rR:μσmM 0.50 0.35 0.00 0.93 | F:μσmM 172.5 115.1 24.0 324.0 | H 1.386 | V -38.671 | pL 7.461 | vL 339.086 | ∇ 96.464\n",
      "U 275 | F 563200 | FPS 2420 | D 77 | rR:μσmM 0.59 0.37 0.00 0.94 | F:μσmM 138.1 119.4 22.0 324.0 | H 1.367 | V -39.845 | pL 9.342 | vL 346.089 | ∇ 122.114\n",
      "U 276 | F 565248 | FPS 2347 | D 78 | rR:μσmM 0.61 0.33 0.00 0.96 | F:μσmM 132.1 105.1 16.0 324.0 | H 1.318 | V -37.530 | pL 3.368 | vL 303.996 | ∇ 130.582\n",
      "U 277 | F 567296 | FPS 2449 | D 79 | rR:μσmM 0.72 0.28 0.00 0.96 | F:μσmM 98.2 93.5 16.0 324.0 | H 1.345 | V -37.873 | pL 3.371 | vL 301.117 | ∇ 126.876\n",
      "U 278 | F 569344 | FPS 2212 | D 80 | rR:μσmM 0.75 0.24 0.00 0.95 | F:μσmM 86.7 80.7 17.0 324.0 | H 1.332 | V -36.729 | pL 5.140 | vL 305.192 | ∇ 153.027\n",
      "U 279 | F 571392 | FPS 2329 | D 81 | rR:μσmM 0.70 0.27 0.00 0.94 | F:μσmM 104.4 90.0 23.0 324.0 | H 1.335 | V -37.016 | pL 3.132 | vL 290.564 | ∇ 136.628\n",
      "U 280 | F 573440 | FPS 2255 | D 82 | rR:μσmM 0.73 0.22 0.19 0.96 | F:μσmM 96.6 78.6 16.0 291.0 | H 1.370 | V -37.240 | pL 8.045 | vL 320.681 | ∇ 158.323\n",
      "Status saved\n",
      "U 281 | F 575488 | FPS 2369 | D 83 | rR:μσmM 0.71 0.29 0.00 0.95 | F:μσmM 99.6 97.1 19.0 324.0 | H 1.368 | V -37.796 | pL 7.257 | vL 361.375 | ∇ 171.828\n",
      "U 282 | F 577536 | FPS 2460 | D 84 | rR:μσmM 0.63 0.35 0.00 0.96 | F:μσmM 126.1 115.2 14.0 324.0 | H 1.360 | V -39.010 | pL 8.320 | vL 352.676 | ∇ 127.806\n",
      "U 283 | F 579584 | FPS 2537 | D 84 | rR:μσmM 0.63 0.34 0.00 0.96 | F:μσmM 126.2 111.1 15.0 324.0 | H 1.270 | V -36.473 | pL 5.028 | vL 328.831 | ∇ 145.388\n",
      "U 284 | F 581632 | FPS 2315 | D 85 | rR:μσmM 0.65 0.29 0.00 0.95 | F:μσmM 123.3 97.3 19.0 324.0 | H 1.274 | V -37.038 | pL 3.433 | vL 285.657 | ∇ 143.019\n",
      "U 285 | F 583680 | FPS 2263 | D 86 | rR:μσmM 0.77 0.20 0.16 0.95 | F:μσmM 84.2 71.7 17.0 301.0 | H 1.210 | V -33.555 | pL 5.830 | vL 337.635 | ∇ 121.936\n",
      "U 286 | F 585728 | FPS 2113 | D 87 | rR:μσmM 0.76 0.19 0.31 0.95 | F:μσmM 87.0 67.1 17.0 249.0 | H 1.155 | V -34.294 | pL 1.653 | vL 308.921 | ∇ 127.554\n",
      "U 287 | F 587776 | FPS 2530 | D 88 | rR:μσmM 0.71 0.30 0.00 0.96 | F:μσmM 99.2 99.4 16.0 324.0 | H 1.164 | V -37.973 | pL 7.382 | vL 329.006 | ∇ 136.174\n",
      "U 288 | F 589824 | FPS 2814 | D 89 | rR:μσmM 0.70 0.21 0.22 0.94 | F:μσmM 106.8 74.3 20.0 281.0 | H 1.177 | V -37.933 | pL 10.768 | vL 364.799 | ∇ 97.582\n",
      "U 289 | F 591872 | FPS 2999 | D 89 | rR:μσmM 0.64 0.31 0.00 0.94 | F:μσmM 123.4 101.9 20.0 324.0 | H 1.175 | V -38.858 | pL 10.377 | vL 382.175 | ∇ 136.084\n",
      "U 290 | F 593920 | FPS 3064 | D 90 | rR:μσmM 0.62 0.37 0.00 0.96 | F:μσmM 128.5 119.2 14.0 324.0 | H 1.120 | V -37.113 | pL 1.184 | vL 329.147 | ∇ 144.088\n",
      "Status saved\n",
      "U 291 | F 595968 | FPS 3079 | D 91 | rR:μσmM 0.79 0.25 0.00 0.96 | F:μσmM 74.4 82.4 15.0 324.0 | H 1.079 | V -35.724 | pL 6.782 | vL 427.730 | ∇ 154.586\n",
      "U 292 | F 598016 | FPS 3038 | D 91 | rR:μσmM 0.76 0.25 0.00 0.96 | F:μσmM 85.5 86.5 14.0 324.0 | H 1.031 | V -33.886 | pL -0.023 | vL 276.676 | ∇ 172.709\n",
      "U 293 | F 600064 | FPS 3004 | D 92 | rR:μσmM 0.80 0.18 0.17 0.96 | F:μσmM 71.0 63.7 14.0 299.0 | H 1.009 | V -34.124 | pL 5.820 | vL 356.074 | ∇ 139.267\n",
      "U 294 | F 602112 | FPS 2955 | D 93 | rR:μσmM 0.73 0.21 0.17 0.95 | F:μσmM 95.8 76.4 17.0 298.0 | H 1.074 | V -36.144 | pL 5.932 | vL 298.830 | ∇ 163.325\n",
      "U 295 | F 604160 | FPS 3006 | D 94 | rR:μσmM 0.75 0.25 0.00 0.96 | F:μσmM 88.2 82.7 14.0 324.0 | H 1.023 | V -35.593 | pL 4.277 | vL 301.158 | ∇ 127.085\n",
      "U 296 | F 606208 | FPS 2998 | D 94 | rR:μσmM 0.73 0.22 0.00 0.95 | F:μσmM 94.7 71.7 19.0 324.0 | H 1.032 | V -37.424 | pL 12.794 | vL 403.334 | ∇ 122.544\n",
      "U 297 | F 608256 | FPS 2902 | D 95 | rR:μσmM 0.66 0.37 0.00 0.96 | F:μσmM 116.7 118.9 14.0 324.0 | H 0.998 | V -38.058 | pL 1.382 | vL 308.556 | ∇ 123.971\n",
      "U 298 | F 610304 | FPS 3033 | D 96 | rR:μσmM 0.75 0.26 0.00 0.95 | F:μσmM 85.6 86.2 19.0 324.0 | H 1.021 | V -36.494 | pL 1.724 | vL 304.076 | ∇ 129.489\n",
      "U 299 | F 612352 | FPS 2961 | D 96 | rR:μσmM 0.78 0.23 0.00 0.96 | F:μσmM 78.4 78.7 13.0 324.0 | H 0.925 | V -35.414 | pL 3.852 | vL 309.132 | ∇ 133.056\n",
      "U 300 | F 614400 | FPS 2962 | D 97 | rR:μσmM 0.78 0.21 0.33 0.96 | F:μσmM 79.1 75.8 15.0 241.0 | H 0.967 | V -36.937 | pL 9.689 | vL 368.419 | ∇ 153.128\n",
      "Status saved\n",
      "U 301 | F 616448 | FPS 3008 | D 98 | rR:μσmM 0.69 0.31 0.00 0.96 | F:μσmM 109.4 104.4 14.0 324.0 | H 0.918 | V -36.825 | pL 5.407 | vL 327.766 | ∇ 138.630\n",
      "U 302 | F 618496 | FPS 3098 | D 98 | rR:μσmM 0.70 0.30 0.00 0.96 | F:μσmM 103.9 98.8 16.0 324.0 | H 0.930 | V -35.866 | pL 5.033 | vL 347.870 | ∇ 144.326\n",
      "U 303 | F 620544 | FPS 3081 | D 99 | rR:μσmM 0.77 0.26 0.00 0.96 | F:μσmM 82.5 89.2 15.0 324.0 | H 0.939 | V -34.145 | pL 5.732 | vL 314.973 | ∇ 156.264\n",
      "U 304 | F 622592 | FPS 2836 | D 100 | rR:μσmM 0.80 0.17 0.29 0.96 | F:μσmM 71.5 61.8 15.0 256.0 | H 0.947 | V -33.582 | pL 1.490 | vL 292.156 | ∇ 130.789\n",
      "U 305 | F 624640 | FPS 3022 | D 100 | rR:μσmM 0.79 0.16 0.38 0.96 | F:μσmM 74.5 58.1 16.0 225.0 | H 1.002 | V -35.542 | pL 7.566 | vL 316.710 | ∇ 108.944\n",
      "U 306 | F 626688 | FPS 3034 | D 101 | rR:μσmM 0.75 0.27 0.00 0.96 | F:μσmM 88.4 91.4 14.0 324.0 | H 0.936 | V -34.919 | pL 4.108 | vL 330.181 | ∇ 180.940\n",
      "U 307 | F 628736 | FPS 2931 | D 102 | rR:μσmM 0.81 0.24 0.00 0.96 | F:μσmM 65.2 77.6 15.0 324.0 | H 0.954 | V -33.848 | pL 1.272 | vL 302.395 | ∇ 139.076\n",
      "U 308 | F 630784 | FPS 2823 | D 103 | rR:μσmM 0.75 0.24 0.00 0.95 | F:μσmM 89.2 83.5 17.0 324.0 | H 0.956 | V -35.050 | pL 4.514 | vL 308.859 | ∇ 135.301\n",
      "U 309 | F 632832 | FPS 3049 | D 103 | rR:μσmM 0.82 0.20 0.00 0.96 | F:μσmM 64.6 68.7 14.0 324.0 | H 0.904 | V -32.538 | pL 3.285 | vL 311.281 | ∇ 152.155\n",
      "U 310 | F 634880 | FPS 3018 | D 104 | rR:μσmM 0.82 0.21 0.00 0.96 | F:μσmM 62.6 71.9 13.0 324.0 | H 0.884 | V -34.708 | pL 5.384 | vL 372.424 | ∇ 105.323\n",
      "Status saved\n",
      "U 311 | F 636928 | FPS 3081 | D 105 | rR:μσmM 0.75 0.23 0.15 0.96 | F:μσmM 90.7 82.1 14.0 305.0 | H 0.952 | V -35.468 | pL 3.128 | vL 261.653 | ∇ 119.480\n",
      "U 312 | F 638976 | FPS 3106 | D 105 | rR:μσmM 0.83 0.18 0.16 0.95 | F:μσmM 62.5 65.9 17.0 304.0 | H 0.928 | V -34.302 | pL 3.318 | vL 324.393 | ∇ 125.061\n",
      "U 313 | F 641024 | FPS 3124 | D 106 | rR:μσmM 0.72 0.32 0.00 0.96 | F:μσmM 97.6 107.5 15.0 324.0 | H 0.969 | V -35.719 | pL 8.190 | vL 379.897 | ∇ 131.980\n",
      "U 314 | F 643072 | FPS 2828 | D 107 | rR:μσmM 0.70 0.31 0.00 0.96 | F:μσmM 104.8 100.9 16.0 324.0 | H 0.912 | V -35.523 | pL 3.361 | vL 324.817 | ∇ 90.828\n",
      "U 315 | F 645120 | FPS 3124 | D 107 | rR:μσmM 0.78 0.25 0.00 0.96 | F:μσmM 76.4 84.7 14.0 324.0 | H 0.874 | V -33.823 | pL 2.066 | vL 289.279 | ∇ 119.455\n",
      "U 316 | F 647168 | FPS 3000 | D 108 | rR:μσmM 0.79 0.20 0.22 0.95 | F:μσmM 74.9 71.1 17.0 280.0 | H 0.924 | V -34.872 | pL 4.873 | vL 276.009 | ∇ 116.476\n",
      "U 317 | F 649216 | FPS 2384 | D 109 | rR:μσmM 0.79 0.23 0.00 0.96 | F:μσmM 73.9 78.0 16.0 324.0 | H 0.916 | V -35.145 | pL 3.764 | vL 294.040 | ∇ 117.128\n",
      "U 318 | F 651264 | FPS 3041 | D 110 | rR:μσmM 0.77 0.28 0.00 0.96 | F:μσmM 78.0 90.9 14.0 324.0 | H 0.901 | V -34.273 | pL 1.502 | vL 288.782 | ∇ 110.976\n",
      "U 319 | F 653312 | FPS 3081 | D 110 | rR:μσmM 0.81 0.21 0.00 0.96 | F:μσmM 67.0 68.8 15.0 324.0 | H 0.902 | V -33.668 | pL 5.255 | vL 312.083 | ∇ 133.799\n",
      "U 320 | F 655360 | FPS 3085 | D 111 | rR:μσmM 0.81 0.18 0.13 0.96 | F:μσmM 68.2 66.2 14.0 313.0 | H 0.822 | V -31.813 | pL -2.090 | vL 243.339 | ∇ 111.428\n",
      "Status saved\n",
      "U 321 | F 657408 | FPS 3126 | D 112 | rR:μσmM 0.83 0.18 0.00 0.96 | F:μσmM 58.8 59.6 14.0 324.0 | H 0.864 | V -33.901 | pL 0.763 | vL 294.229 | ∇ 144.221\n",
      "U 322 | F 659456 | FPS 3141 | D 112 | rR:μσmM 0.88 0.09 0.54 0.96 | F:μσmM 41.5 31.6 13.0 166.0 | H 0.823 | V -32.741 | pL 1.737 | vL 324.191 | ∇ 99.514\n",
      "U 323 | F 661504 | FPS 3097 | D 113 | rR:μσmM 0.82 0.23 0.00 0.96 | F:μσmM 63.3 74.1 13.0 324.0 | H 0.765 | V -33.727 | pL 0.065 | vL 277.471 | ∇ 113.450\n",
      "U 324 | F 663552 | FPS 3187 | D 113 | rR:μσmM 0.84 0.21 0.00 0.96 | F:μσmM 57.3 70.6 14.0 324.0 | H 0.756 | V -34.370 | pL 5.812 | vL 365.435 | ∇ 97.379\n",
      "U 325 | F 665600 | FPS 3186 | D 114 | rR:μσmM 0.85 0.16 0.37 0.96 | F:μσmM 52.5 59.2 14.0 226.0 | H 0.794 | V -34.989 | pL 9.735 | vL 383.224 | ∇ 130.251\n",
      "U 326 | F 667648 | FPS 3119 | D 115 | rR:μσmM 0.69 0.33 0.00 0.96 | F:μσmM 107.2 111.4 14.0 324.0 | H 0.792 | V -34.650 | pL 3.642 | vL 314.068 | ∇ 144.206\n",
      "U 327 | F 669696 | FPS 3096 | D 115 | rR:μσmM 0.79 0.25 0.00 0.96 | F:μσmM 73.8 83.2 14.0 324.0 | H 0.748 | V -32.647 | pL 5.458 | vL 355.117 | ∇ 137.977\n",
      "U 328 | F 671744 | FPS 3080 | D 116 | rR:μσmM 0.84 0.21 0.00 0.96 | F:μσmM 58.2 72.7 13.0 324.0 | H 0.720 | V -30.860 | pL -3.447 | vL 258.702 | ∇ 109.880\n",
      "U 329 | F 673792 | FPS 2984 | D 117 | rR:μσmM 0.88 0.10 0.52 0.96 | F:μσmM 44.9 34.7 14.0 171.0 | H 0.747 | V -31.471 | pL -2.733 | vL 263.726 | ∇ 131.398\n",
      "U 330 | F 675840 | FPS 2713 | D 118 | rR:μσmM 0.87 0.09 0.66 0.96 | F:μσmM 45.8 30.6 14.0 124.0 | H 0.756 | V -34.895 | pL 4.277 | vL 329.712 | ∇ 120.397\n",
      "Status saved\n",
      "U 331 | F 677888 | FPS 2989 | D 118 | rR:μσmM 0.71 0.35 0.00 0.96 | F:μσmM 99.6 115.0 16.0 324.0 | H 0.775 | V -36.011 | pL 5.244 | vL 320.411 | ∇ 121.961\n",
      "U 332 | F 679936 | FPS 2995 | D 119 | rR:μσmM 0.84 0.20 0.00 0.96 | F:μσmM 57.8 68.6 14.0 324.0 | H 0.768 | V -34.231 | pL 5.943 | vL 357.251 | ∇ 123.106\n",
      "U 333 | F 681984 | FPS 3015 | D 120 | rR:μσmM 0.76 0.29 0.00 0.96 | F:μσmM 84.7 97.3 14.0 324.0 | H 0.747 | V -35.815 | pL 2.524 | vL 313.338 | ∇ 94.073\n",
      "U 334 | F 684032 | FPS 2997 | D 120 | rR:μσmM 0.83 0.24 0.00 0.96 | F:μσmM 60.3 79.4 13.0 324.0 | H 0.664 | V -34.788 | pL 3.414 | vL 356.226 | ∇ 126.929\n",
      "U 335 | F 686080 | FPS 2956 | D 121 | rR:μσmM 0.82 0.22 0.00 0.96 | F:μσmM 62.7 74.0 13.0 324.0 | H 0.732 | V -32.061 | pL 0.511 | vL 295.930 | ∇ 150.492\n",
      "U 336 | F 688128 | FPS 3088 | D 122 | rR:μσmM 0.85 0.19 0.00 0.96 | F:μσmM 54.5 63.7 14.0 324.0 | H 0.729 | V -34.932 | pL 3.625 | vL 333.221 | ∇ 110.583\n",
      "U 337 | F 690176 | FPS 2916 | D 122 | rR:μσmM 0.81 0.18 0.29 0.96 | F:μσmM 69.4 65.3 14.0 256.0 | H 0.757 | V -34.565 | pL 2.212 | vL 324.107 | ∇ 125.780\n",
      "U 338 | F 692224 | FPS 3057 | D 123 | rR:μσmM 0.85 0.21 0.00 0.96 | F:μσmM 54.9 71.6 13.0 324.0 | H 0.683 | V -32.073 | pL 2.403 | vL 310.443 | ∇ 134.817\n",
      "U 339 | F 694272 | FPS 3055 | D 124 | rR:μσmM 0.80 0.22 0.00 0.96 | F:μσmM 69.1 75.3 15.0 324.0 | H 0.730 | V -32.922 | pL 4.485 | vL 308.269 | ∇ 110.776\n",
      "U 340 | F 696320 | FPS 3029 | D 124 | rR:μσmM 0.83 0.20 0.12 0.96 | F:μσmM 60.3 73.3 14.0 317.0 | H 0.692 | V -31.140 | pL -1.977 | vL 265.569 | ∇ 129.501\n",
      "Status saved\n",
      "U 341 | F 698368 | FPS 3064 | D 125 | rR:μσmM 0.89 0.08 0.63 0.96 | F:μσmM 38.4 29.0 14.0 132.0 | H 0.697 | V -33.507 | pL 4.164 | vL 343.504 | ∇ 131.899\n",
      "U 342 | F 700416 | FPS 2952 | D 126 | rR:μσmM 0.80 0.27 0.00 0.96 | F:μσmM 71.0 90.5 13.0 324.0 | H 0.720 | V -32.148 | pL 1.243 | vL 296.645 | ∇ 110.849\n",
      "U 343 | F 702464 | FPS 2943 | D 127 | rR:μσmM 0.84 0.18 0.14 0.96 | F:μσmM 58.3 65.9 13.0 311.0 | H 0.703 | V -32.748 | pL 2.229 | vL 302.758 | ∇ 135.397\n",
      "U 344 | F 704512 | FPS 2965 | D 127 | rR:μσmM 0.87 0.14 0.32 0.96 | F:μσmM 46.9 49.9 14.0 245.0 | H 0.696 | V -30.240 | pL 0.920 | vL 320.211 | ∇ 110.536\n",
      "U 345 | F 706560 | FPS 2667 | D 128 | rR:μσmM 0.83 0.20 0.00 0.96 | F:μσmM 60.8 67.9 14.0 324.0 | H 0.748 | V -30.532 | pL 0.010 | vL 308.001 | ∇ 92.461\n",
      "U 346 | F 708608 | FPS 2654 | D 129 | rR:μσmM 0.85 0.21 0.00 0.96 | F:μσmM 54.7 72.9 13.0 324.0 | H 0.707 | V -32.471 | pL 0.952 | vL 272.475 | ∇ 80.661\n",
      "U 347 | F 710656 | FPS 2897 | D 129 | rR:μσmM 0.80 0.17 0.39 0.96 | F:μσmM 72.2 60.7 13.0 221.0 | H 0.694 | V -32.460 | pL 3.639 | vL 295.187 | ∇ 125.520\n",
      "U 348 | F 712704 | FPS 2454 | D 130 | rR:μσmM 0.86 0.20 0.00 0.96 | F:μσmM 49.0 64.6 14.0 324.0 | H 0.632 | V -32.185 | pL -0.625 | vL 313.031 | ∇ 120.931\n",
      "U 349 | F 714752 | FPS 1597 | D 132 | rR:μσmM 0.84 0.18 0.13 0.96 | F:μσmM 57.9 64.4 13.0 312.0 | H 0.610 | V -32.415 | pL 2.615 | vL 276.077 | ∇ 132.139\n",
      "U 350 | F 716800 | FPS 2422 | D 132 | rR:μσmM 0.85 0.16 0.33 0.96 | F:μσmM 52.3 56.9 13.0 240.0 | H 0.618 | V -30.978 | pL -0.505 | vL 279.403 | ∇ 132.155\n",
      "Status saved\n",
      "U 351 | F 718848 | FPS 2745 | D 133 | rR:μσmM 0.85 0.14 0.28 0.96 | F:μσmM 52.6 51.0 13.0 260.0 | H 0.599 | V -29.467 | pL -2.528 | vL 233.371 | ∇ 113.004\n",
      "U 352 | F 720896 | FPS 2198 | D 134 | rR:μσmM 0.85 0.11 0.60 0.96 | F:μσmM 52.9 41.1 14.0 144.0 | H 0.587 | V -30.392 | pL 2.717 | vL 310.128 | ∇ 107.361\n",
      "U 353 | F 722944 | FPS 3109 | D 135 | rR:μσmM 0.88 0.17 0.00 0.96 | F:μσmM 43.7 58.2 13.0 324.0 | H 0.602 | V -28.849 | pL 0.206 | vL 288.045 | ∇ 117.345\n",
      "U 354 | F 724992 | FPS 3153 | D 135 | rR:μσmM 0.84 0.20 0.00 0.96 | F:μσmM 56.8 66.5 14.0 324.0 | H 0.626 | V -31.922 | pL 4.577 | vL 332.437 | ∇ 137.134\n",
      "U 355 | F 727040 | FPS 3006 | D 136 | rR:μσmM 0.84 0.21 0.17 0.96 | F:μσmM 59.3 75.0 14.0 297.0 | H 0.690 | V -32.170 | pL 2.720 | vL 273.966 | ∇ 126.320\n",
      "U 356 | F 729088 | FPS 2929 | D 137 | rR:μσmM 0.83 0.21 0.00 0.96 | F:μσmM 60.0 73.0 14.0 324.0 | H 0.655 | V -30.321 | pL 3.829 | vL 307.194 | ∇ 118.839\n",
      "U 357 | F 731136 | FPS 2791 | D 138 | rR:μσmM 0.85 0.19 0.00 0.96 | F:μσmM 51.7 63.6 13.0 324.0 | H 0.641 | V -28.877 | pL 0.091 | vL 285.695 | ∇ 141.944\n",
      "U 358 | F 733184 | FPS 2539 | D 138 | rR:μσmM 0.86 0.16 0.17 0.96 | F:μσmM 50.7 57.3 13.0 300.0 | H 0.624 | V -29.611 | pL 4.648 | vL 307.862 | ∇ 162.476\n",
      "U 359 | F 735232 | FPS 2748 | D 139 | rR:μσmM 0.82 0.18 0.31 0.96 | F:μσmM 65.7 63.7 14.0 249.0 | H 0.670 | V -30.620 | pL 5.005 | vL 307.398 | ∇ 159.932\n",
      "U 360 | F 737280 | FPS 2666 | D 140 | rR:μσmM 0.86 0.19 0.00 0.96 | F:μσmM 51.0 65.1 13.0 324.0 | H 0.599 | V -29.869 | pL -0.065 | vL 273.818 | ∇ 137.573\n",
      "Status saved\n",
      "U 361 | F 739328 | FPS 2699 | D 141 | rR:μσmM 0.82 0.22 0.00 0.96 | F:μσmM 63.9 71.5 13.0 324.0 | H 0.620 | V -29.340 | pL 2.664 | vL 268.282 | ∇ 103.013\n",
      "U 362 | F 741376 | FPS 2730 | D 141 | rR:μσmM 0.88 0.11 0.40 0.96 | F:μσmM 42.7 39.6 13.0 217.0 | H 0.604 | V -28.952 | pL 4.074 | vL 306.821 | ∇ 154.672\n",
      "U 363 | F 743424 | FPS 2638 | D 142 | rR:μσmM 0.82 0.21 0.00 0.96 | F:μσmM 64.0 73.0 13.0 324.0 | H 0.672 | V -29.317 | pL 3.849 | vL 268.136 | ∇ 119.026\n",
      "U 364 | F 745472 | FPS 2869 | D 143 | rR:μσmM 0.85 0.18 0.00 0.96 | F:μσmM 53.5 60.1 14.0 324.0 | H 0.668 | V -30.253 | pL 5.289 | vL 327.276 | ∇ 112.191\n",
      "U 365 | F 747520 | FPS 2605 | D 144 | rR:μσmM 0.81 0.22 0.00 0.96 | F:μσmM 67.8 74.5 15.0 324.0 | H 0.626 | V -30.220 | pL 6.042 | vL 306.687 | ∇ 124.354\n",
      "U 366 | F 749568 | FPS 2694 | D 145 | rR:μσmM 0.81 0.22 0.00 0.96 | F:μσmM 65.0 73.9 13.0 324.0 | H 0.639 | V -27.177 | pL -0.175 | vL 239.266 | ∇ 127.596\n",
      "U 367 | F 751616 | FPS 2854 | D 145 | rR:μσmM 0.89 0.12 0.16 0.96 | F:μσmM 39.5 43.0 13.0 302.0 | H 0.535 | V -27.047 | pL -1.006 | vL 221.095 | ∇ 119.055\n",
      "U 368 | F 753664 | FPS 2845 | D 146 | rR:μσmM 0.88 0.12 0.49 0.96 | F:μσmM 44.8 44.2 14.0 184.0 | H 0.559 | V -29.341 | pL 6.795 | vL 332.083 | ∇ 108.764\n",
      "U 369 | F 755712 | FPS 2824 | D 147 | rR:μσmM 0.82 0.19 0.24 0.96 | F:μσmM 65.5 68.7 13.0 275.0 | H 0.524 | V -28.077 | pL 6.630 | vL 333.864 | ∇ 114.531\n",
      "U 370 | F 757760 | FPS 2795 | D 147 | rR:μσmM 0.84 0.24 0.00 0.96 | F:μσmM 57.5 80.8 13.0 324.0 | H 0.564 | V -26.834 | pL -0.447 | vL 239.616 | ∇ 103.904\n",
      "Status saved\n",
      "U 371 | F 759808 | FPS 2783 | D 148 | rR:μσmM 0.89 0.11 0.45 0.96 | F:μσmM 40.7 37.9 13.0 197.0 | H 0.569 | V -26.938 | pL 0.121 | vL 245.081 | ∇ 131.352\n",
      "U 372 | F 761856 | FPS 2771 | D 149 | rR:μσmM 0.88 0.14 0.00 0.96 | F:μσmM 41.2 47.6 13.0 324.0 | H 0.554 | V -26.124 | pL 0.547 | vL 238.539 | ∇ 121.981\n",
      "U 373 | F 763904 | FPS 2281 | D 150 | rR:μσmM 0.88 0.15 0.00 0.96 | F:μσmM 43.4 51.3 13.0 324.0 | H 0.556 | V -26.475 | pL -0.287 | vL 251.422 | ∇ 113.939\n",
      "U 374 | F 765952 | FPS 2000 | D 151 | rR:μσmM 0.89 0.13 0.17 0.96 | F:μσmM 40.4 48.2 13.0 298.0 | H 0.554 | V -26.705 | pL -0.184 | vL 236.541 | ∇ 96.672\n",
      "U 375 | F 768000 | FPS 2611 | D 152 | rR:μσmM 0.90 0.09 0.47 0.96 | F:μσmM 36.8 31.3 13.0 191.0 | H 0.528 | V -26.080 | pL -0.340 | vL 271.712 | ∇ 110.511\n",
      "U 376 | F 770048 | FPS 2584 | D 153 | rR:μσmM 0.88 0.15 0.18 0.96 | F:μσmM 42.1 55.1 13.0 295.0 | H 0.540 | V -25.954 | pL -0.390 | vL 225.512 | ∇ 97.093\n",
      "U 377 | F 772096 | FPS 2463 | D 153 | rR:μσmM 0.89 0.11 0.35 0.96 | F:μσmM 40.3 38.8 13.0 235.0 | H 0.547 | V -25.720 | pL -2.390 | vL 194.404 | ∇ 102.760\n",
      "U 378 | F 774144 | FPS 2109 | D 154 | rR:μσmM 0.90 0.08 0.62 0.96 | F:μσmM 35.4 29.7 13.0 136.0 | H 0.520 | V -27.101 | pL 0.929 | vL 238.674 | ∇ 121.015\n",
      "U 379 | F 776192 | FPS 2391 | D 155 | rR:μσmM 0.88 0.17 0.00 0.96 | F:μσmM 42.4 56.3 13.0 324.0 | H 0.527 | V -27.938 | pL 2.330 | vL 261.697 | ∇ 111.514\n",
      "U 380 | F 778240 | FPS 2561 | D 156 | rR:μσmM 0.88 0.13 0.40 0.96 | F:μσmM 44.7 48.0 13.0 215.0 | H 0.471 | V -25.369 | pL -4.506 | vL 189.149 | ∇ 97.336\n",
      "Status saved\n",
      "U 381 | F 780288 | FPS 2818 | D 157 | rR:μσmM 0.90 0.09 0.60 0.96 | F:μσmM 35.5 30.7 13.0 145.0 | H 0.503 | V -26.338 | pL -0.360 | vL 201.157 | ∇ 97.355\n",
      "U 382 | F 782336 | FPS 2957 | D 157 | rR:μσmM 0.90 0.09 0.59 0.96 | F:μσmM 36.5 30.9 13.0 148.0 | H 0.530 | V -28.087 | pL 2.737 | vL 273.675 | ∇ 116.627\n",
      "U 383 | F 784384 | FPS 2974 | D 158 | rR:μσmM 0.84 0.14 0.31 0.96 | F:μσmM 57.0 50.7 13.0 249.0 | H 0.530 | V -26.080 | pL -1.307 | vL 219.767 | ∇ 121.688\n",
      "U 384 | F 786432 | FPS 2935 | D 159 | rR:μσmM 0.90 0.10 0.44 0.96 | F:μσmM 34.4 35.5 13.0 200.0 | H 0.564 | V -24.487 | pL 0.828 | vL 248.966 | ∇ 115.521\n",
      "U 385 | F 788480 | FPS 2598 | D 160 | rR:μσmM 0.91 0.08 0.54 0.96 | F:μσmM 31.2 30.0 13.0 164.0 | H 0.527 | V -23.173 | pL 0.353 | vL 284.159 | ∇ 89.791\n",
      "U 386 | F 790528 | FPS 2760 | D 160 | rR:μσmM 0.88 0.12 0.37 0.96 | F:μσmM 42.2 44.5 14.0 227.0 | H 0.565 | V -26.019 | pL 3.494 | vL 254.017 | ∇ 104.462\n",
      "U 387 | F 792576 | FPS 3131 | D 161 | rR:μσmM 0.84 0.16 0.12 0.96 | F:μσmM 57.1 56.9 13.0 315.0 | H 0.554 | V -26.921 | pL 2.064 | vL 253.939 | ∇ 116.772\n",
      "U 388 | F 794624 | FPS 3206 | D 162 | rR:μσmM 0.87 0.17 0.00 0.96 | F:μσmM 45.4 56.0 13.0 324.0 | H 0.522 | V -23.188 | pL -0.501 | vL 194.775 | ∇ 94.310\n",
      "U 389 | F 796672 | FPS 3209 | D 162 | rR:μσmM 0.89 0.08 0.60 0.96 | F:μσmM 37.9 28.1 13.0 144.0 | H 0.553 | V -24.666 | pL 3.611 | vL 241.474 | ∇ 121.746\n",
      "U 390 | F 798720 | FPS 3220 | D 163 | rR:μσmM 0.86 0.11 0.57 0.96 | F:μσmM 51.3 40.1 14.0 155.0 | H 0.571 | V -25.017 | pL 2.379 | vL 251.880 | ∇ 111.880\n",
      "Status saved\n",
      "U 391 | F 800768 | FPS 3205 | D 164 | rR:μσmM 0.89 0.12 0.46 0.96 | F:μσmM 38.4 41.7 13.0 195.0 | H 0.589 | V -24.609 | pL 2.982 | vL 270.854 | ∇ 122.905\n",
      "U 392 | F 802816 | FPS 3130 | D 164 | rR:μσmM 0.90 0.15 0.00 0.96 | F:μσmM 36.4 49.2 13.0 324.0 | H 0.539 | V -23.400 | pL 5.664 | vL 308.810 | ∇ 130.663\n",
      "U 393 | F 804864 | FPS 3168 | D 165 | rR:μσmM 0.87 0.18 0.00 0.96 | F:μσmM 46.0 62.0 13.0 324.0 | H 0.521 | V -21.451 | pL 0.535 | vL 206.127 | ∇ 91.500\n",
      "U 394 | F 806912 | FPS 3114 | D 166 | rR:μσmM 0.90 0.10 0.56 0.96 | F:μσmM 37.4 35.2 13.0 159.0 | H 0.626 | V -22.922 | pL 6.383 | vL 307.868 | ∇ 133.276\n",
      "U 395 | F 808960 | FPS 3146 | D 166 | rR:μσmM 0.88 0.16 0.00 0.96 | F:μσmM 43.6 54.5 13.0 324.0 | H 0.656 | V -22.799 | pL 2.345 | vL 234.690 | ∇ 100.580\n",
      "U 396 | F 811008 | FPS 3196 | D 167 | rR:μσmM 0.88 0.16 0.20 0.96 | F:μσmM 41.7 56.2 14.0 288.0 | H 0.625 | V -23.816 | pL 5.034 | vL 273.139 | ∇ 140.197\n",
      "U 397 | F 813056 | FPS 3165 | D 168 | rR:μσmM 0.87 0.16 0.00 0.96 | F:μσmM 44.8 54.4 14.0 324.0 | H 0.558 | V -22.304 | pL -3.044 | vL 150.266 | ∇ 88.170\n",
      "U 398 | F 815104 | FPS 3211 | D 168 | rR:μσmM 0.92 0.05 0.74 0.96 | F:μσmM 29.1 17.6 13.0 92.0 | H 0.593 | V -21.864 | pL 1.309 | vL 196.846 | ∇ 104.388\n",
      "U 399 | F 817152 | FPS 3181 | D 169 | rR:μσmM 0.90 0.12 0.24 0.96 | F:μσmM 37.6 41.6 13.0 274.0 | H 0.583 | V -21.375 | pL -2.196 | vL 147.920 | ∇ 92.122\n",
      "U 400 | F 819200 | FPS 3190 | D 169 | rR:μσmM 0.92 0.07 0.54 0.96 | F:μσmM 29.4 23.5 14.0 165.0 | H 0.539 | V -20.858 | pL -0.117 | vL 183.639 | ∇ 97.643\n",
      "Status saved\n",
      "U 401 | F 821248 | FPS 3215 | D 170 | rR:μσmM 0.92 0.07 0.45 0.96 | F:μσmM 30.2 27.0 13.0 198.0 | H 0.417 | V -18.279 | pL -4.056 | vL 110.529 | ∇ 59.757\n",
      "U 402 | F 823296 | FPS 3147 | D 171 | rR:μσmM 0.93 0.06 0.57 0.96 | F:μσmM 25.1 21.3 13.0 156.0 | H 0.472 | V -20.009 | pL 0.862 | vL 171.605 | ∇ 82.564\n",
      "U 403 | F 825344 | FPS 3024 | D 171 | rR:μσmM 0.90 0.08 0.56 0.96 | F:μσmM 35.5 29.0 13.0 157.0 | H 0.506 | V -19.392 | pL -0.860 | vL 157.025 | ∇ 76.268\n",
      "U 404 | F 827392 | FPS 3200 | D 172 | rR:μσmM 0.92 0.07 0.57 0.96 | F:μσmM 29.9 26.4 13.0 155.0 | H 0.462 | V -18.707 | pL 0.410 | vL 186.191 | ∇ 85.247\n",
      "U 405 | F 829440 | FPS 2846 | D 173 | rR:μσmM 0.91 0.09 0.37 0.96 | F:μσmM 31.9 31.7 13.0 227.0 | H 0.443 | V -18.608 | pL 0.037 | vL 150.273 | ∇ 92.192\n",
      "U 406 | F 831488 | FPS 2545 | D 174 | rR:μσmM 0.93 0.04 0.74 0.96 | F:μσmM 24.8 14.4 13.0 93.0 | H 0.425 | V -17.787 | pL 1.954 | vL 174.348 | ∇ 102.265\n",
      "U 407 | F 833536 | FPS 2862 | D 174 | rR:μσmM 0.89 0.12 0.22 0.96 | F:μσmM 40.1 44.9 13.0 282.0 | H 0.460 | V -18.790 | pL 0.795 | vL 161.881 | ∇ 80.093\n",
      "U 408 | F 835584 | FPS 2797 | D 175 | rR:μσmM 0.92 0.06 0.56 0.96 | F:μσmM 28.5 23.2 13.0 158.0 | H 0.428 | V -17.841 | pL -1.422 | vL 116.231 | ∇ 85.138\n",
      "U 409 | F 837632 | FPS 2986 | D 176 | rR:μσmM 0.92 0.05 0.64 0.96 | F:μσmM 29.3 19.6 13.0 130.0 | H 0.421 | V -17.302 | pL -0.654 | vL 111.581 | ∇ 78.429\n",
      "Number of frames:  839680\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "num_frames = status[\"num_frames\"]\n",
    "update = status[\"update\"]\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving average parameters\n",
    "threshold = 0.90\n",
    "window = 10\n",
    "rreturn_total = 0\n",
    "i = 0\n",
    "\n",
    "while num_frames < args.frames:\n",
    "    # Update model parameters\n",
    "\n",
    "    update_start_time = time.time()\n",
    "    exps, logs1 = algo.collect_experiences()\n",
    "    logs2 = algo.update_parameters(exps)\n",
    "    logs = {**logs1, **logs2}\n",
    "    update_end_time = time.time()\n",
    "\n",
    "    num_frames += logs[\"num_frames\"]\n",
    "    update += 1\n",
    "\n",
    "    # Print logs\n",
    "\n",
    "    if update % args.log_interval == 0:\n",
    "        fps = logs[\"num_frames\"]/(update_end_time - update_start_time)\n",
    "        duration = int(time.time() - start_time)\n",
    "        return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "        rreturn_per_episode = utils.synthesize(logs[\"reshaped_return_per_episode\"])\n",
    "        num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "        # Moving average to break loop if mean reward threshold reached\n",
    "        rreturn_total +=return_per_episode['mean']\n",
    "        i+=1\n",
    "        if i >= window:\n",
    "            rreturn_mavg = rreturn_total / i\n",
    "            if rreturn_mavg >= threshold:\n",
    "                break_flag = True \n",
    "                break\n",
    "            else:\n",
    "                i = 0\n",
    "                rreturn_total = 0\n",
    "\n",
    "        header = [\"update\", \"frames\", \"FPS\", \"duration\"]\n",
    "        data = [update, num_frames, fps, duration]\n",
    "        #header += [\"rreturn_\" + key for key in rreturn_per_episode.keys()]\n",
    "        #data += rreturn_per_episode.values()\n",
    "        header += [\"rreturn_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "        header += [\"num_frames_\" + key for key in num_frames_per_episode.keys()]\n",
    "        data += num_frames_per_episode.values()\n",
    "        header += [\"entropy\", \"value\", \"policy_loss\", \"value_loss\", \"grad_norm\"]\n",
    "        data += [logs[\"entropy\"], logs[\"value\"], logs[\"policy_loss\"], logs[\"value_loss\"], logs[\"grad_norm\"]]\n",
    "\n",
    "        txt_logger.info(\n",
    "            \"U {} | F {:06} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}\"\n",
    "            .format(*data))\n",
    "\n",
    "        header += [\"return_\" + key for key in return_per_episode.keys()]\n",
    "        data += return_per_episode.values()\n",
    "\n",
    "        if status[\"num_frames\"] == 0:\n",
    "            csv_logger.writerow(header)\n",
    "        csv_logger.writerow(data)\n",
    "        csv_file.flush()\n",
    "\n",
    "        for field, value in zip(header, data):\n",
    "            tb_writer.add_scalar(field, value, num_frames)\n",
    "\n",
    "    # Save status\n",
    "\n",
    "    if args.save_interval > 0 and update % args.save_interval == 0:\n",
    "        status = {\"num_frames\": num_frames, \"update\": update,\n",
    "                  \"model_state\": acmodel.state_dict(), \"optimizer_state\": algo.optimizer.state_dict()}\n",
    "        if hasattr(preprocess_obss, \"vocab\"):\n",
    "            status[\"vocab\"] = preprocess_obss.vocab.vocab\n",
    "        utils.save_status(status, model_dir)\n",
    "        txt_logger.info(\"Status saved\")\n",
    "\n",
    "print(\"Number of frames: \", num_frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate 3rd environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-SimpleCrossingS9N2-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped', 'seed': 2, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': True, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-RedBlueDoors-6x6-v0'\n",
    "env_id = 'MiniGrid-SimpleCrossingS9N2-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 2\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-SimpleCrossingS9N2-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 2894.0 | FPS 3630 | D 0.0 | R:μσmM 0.93 0.05 0.64 0.96 | F:μσmM 26.2 17.5 13.0 130.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 1st environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-WallGapS6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': True, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "#env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-WallGapS6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 1063.0 | FPS 2728 | D 0.0 | R:μσmM 0.93 0.03 0.82 0.99 | F:μσmM 10.5 5.6 2.0 28.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-evaluate 2nd environment and test CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'ppo', 'env': 'MiniGrid-DoorKey-6x6-v0', 'model': 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped', 'seed': 3, 'log_interval': 1, 'save_interval': 10, 'procs': 16, 'frames': 900000, 'epochs': 4, 'batch_size': 256, 'frames_per_proc': 128, 'discount': 0.99, 'lr': 0.0007, 'gae_lambda': 0.99, 'entropy_coef': 0.01, 'value_loss_coef': 0.5, 'max_grad_norm': 0.5, 'optim_eps': 1e-08, 'optim_alpha': 0.99, 'clip_eps': 0.2, 'recurrence': 1, 'text': False, 'reshape_reward': True, 'mem': False, 'episodes': 100, 'argmax': False, 'worst_episodes_to_show': None}\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#env_id = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env_id = 'MiniGrid-DoorKey-6x6-v0'\n",
    "#env_id = 'MiniGrid-Empty-8x8-v0'\n",
    "#env_id = 'MiniGrid-LavaGapS5-v0'\n",
    "#env_id = 'MiniGrid-WallGapS6-v0'\n",
    "\n",
    "args.model = 'test_ppo_frames_128_wallgap_doorkey_crossing_reshaped'\n",
    "## Hyper-parameters\n",
    "args.env = env_id\n",
    "args.episodes = 100\n",
    "args.seed = 3\n",
    "args.argmax = False\n",
    "args.worst_episodes_to_show = None\n",
    "print(args)\n",
    "\n",
    "\n",
    "# Set seed for all randomness sources\n",
    "utils.seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: MiniGrid-DoorKey-6x6-v0 \n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_1 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_2 completed\n",
      "\n",
      "Environments loaded\n",
      "Agent loaded\n",
      "Agent run_3 completed\n",
      "\n",
      "F 18418.0 | FPS 4135 | D 4.0 | R:μσmM 0.47 0.33 0.00 0.96 | F:μσmM 200.6 119.6 16.0 360.0\n"
     ]
    }
   ],
   "source": [
    "num_frames_list = []\n",
    "fps_list = []\n",
    "duration_list = []\n",
    "return_per_episode_list = []\n",
    "num_frames_per_episode_list = []\n",
    "seed_list = [10, 20, 30]\n",
    "\n",
    "print(\"Env:\", args.env, \"\\n\")\n",
    "\n",
    "for n, seed in enumerate(seed_list):\n",
    "\n",
    "    # Load environments\n",
    "\n",
    "    envs = []\n",
    "    for i in range(args.procs):\n",
    "        env = utils.make_env(args.env, seed + 10000 * i)\n",
    "        envs.append(env)\n",
    "    env = ParallelEnv(envs)\n",
    "    print(\"Environments loaded\")\n",
    "\n",
    "    # Load agent\n",
    "\n",
    "    model_dir = utils.get_model_dir(args.model)\n",
    "    agent = utils.Agent(obs_space=env.observation_space, action_space=env.action_space, model_dir=model_dir, device=device, argmax=args.argmax)\n",
    "    print(\"Agent loaded\")\n",
    "\n",
    "    # Initialize logs\n",
    "\n",
    "    logs = {\"num_frames_per_episode\": [], \"return_per_episode\": []}\n",
    "\n",
    "    # Run agent\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obss = env.reset()\n",
    "\n",
    "    log_done_counter = 0\n",
    "    log_episode_return = torch.zeros(args.procs, device=device)\n",
    "    log_episode_num_frames = torch.zeros(args.procs, device=device)\n",
    "\n",
    "    while log_done_counter < args.episodes:\n",
    "        actions = agent.get_actions(obss)\n",
    "        obss, rewards, dones, _ = env.step(actions)\n",
    "        agent.analyze_feedbacks(rewards, dones)\n",
    "\n",
    "        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n",
    "        log_episode_num_frames += torch.ones(args.procs, device=device)\n",
    "\n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                log_done_counter += 1\n",
    "                logs[\"return_per_episode\"].append(log_episode_return[i].item())\n",
    "                logs[\"num_frames_per_episode\"].append(log_episode_num_frames[i].item())\n",
    "\n",
    "        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n",
    "        log_episode_return *= mask\n",
    "        log_episode_num_frames *= mask\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Agent run_{} completed\\n\" .format(n+1))\n",
    "\n",
    "    num_frames = sum(logs[\"num_frames_per_episode\"])\n",
    "    fps = num_frames/(end_time - start_time)\n",
    "    duration = int(end_time - start_time)\n",
    "    return_per_episode = utils.synthesize(logs[\"return_per_episode\"])\n",
    "    num_frames_per_episode = utils.synthesize(logs[\"num_frames_per_episode\"])\n",
    "\n",
    "    # Acumulate logs per agent\n",
    "\n",
    "    num_frames_list.append(num_frames)\n",
    "    fps_list.append(fps)\n",
    "    duration_list.append(duration)\n",
    "    return_per_episode_list.append(np.fromiter(return_per_episode.values(), float))\n",
    "    num_frames_per_episode_list.append(np.fromiter(num_frames_per_episode.values(), float))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "num_frames_tot = np.array(num_frames_list, ndmin=2)\n",
    "fps_tot = np.array(fps_list, ndmin=2)\n",
    "duration_tot = np.array(duration_list, ndmin=2)\n",
    "return_per_episode_tot = np.array(return_per_episode_list, ndmin=2)\n",
    "num_frames_per_episode_tot = np.array(num_frames_per_episode_list, ndmin=2)\n",
    "\n",
    "# Print logs\n",
    "\n",
    "print(\"F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}\"\n",
    "      .format(np.median(num_frames_tot, axis=0)[0], np.median(fps_tot, axis=0)[0], np.median(duration_tot, axis=0)[0], *np.median(return_per_episode_tot, axis=0), *np.median(num_frames_per_episode_tot, axis=0)))\n",
    "\n",
    "#return_per_episode_tot = np.array(return_per_episode_tot, ndim=2)\n",
    "\n",
    "# Print worst episodes\n",
    "if args.worst_episodes_to_show:\n",
    "    n = args.worst_episodes_to_show\n",
    "    if n > 0:\n",
    "        print(\"\\n{} worst episodes:\".format(n))\n",
    "\n",
    "        indexes = sorted(range(len(logs[\"return_per_episode\"])), key=lambda k: logs[\"return_per_episode\"][k])\n",
    "        for i in indexes[:n]:\n",
    "            print(\"- episode {}: R={}, F={}\".format(i, logs[\"return_per_episode\"][i], logs[\"num_frames_per_episode\"][i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_minigrid_sb3_curriculum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm-experiments",
   "language": "python",
   "name": "tfm-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d78c29e5a106d8e5aff5a2dd98f2f1ce9953cb30dd1c8e42e77397bf33d62cb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
